{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lw_Kk4FAtr6W"
   },
   "source": [
    "**Basic ItemKNN recommender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ybQSYdHvb_CB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple,Callable,Dict,Optional,List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "import random\n",
    "#from scipy.sparse import csr_matrix\n",
    "\n",
    "#----Recommenders----\n",
    "from SLIM.SLIM_BPR_Cython import SLIM_BPR_Cython\n",
    "from SLIM.SlimElasticNet import SLIMElasticNetRecommender\n",
    "from cf.item_cf import ItemBasedCollaborativeFiltering\n",
    "from cf.user_cf import UserBasedCollaborativeFiltering\n",
    "#---------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyPCmUzVedBh"
   },
   "source": [
    "**Dataset loading with pandas**\n",
    "\n",
    "The function read_csv from pandas provides a wonderful and fast interface to load tabular data like this. For better results and performance we provide the separator ::, the column names [\"user_id\", \"item_id\", \"ratings\", \"timestamp\"], and the types of each attribute in the dtype parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "96AUQmIlcAr2"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "  return pd.read_csv(\"./data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vMaAYCCksV82"
   },
   "outputs": [],
   "source": [
    "ratings=load_data()\n",
    "d ={'user_id': ratings['row'],'item_id':ratings['col'],'ratings':ratings['data']}\n",
    "ratings=pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "enpGAp964Y5a",
    "outputId": "c436ac0a-ab96-4e87-8990-dea6db1076a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id      int64\n",
       "item_id      int64\n",
       "ratings    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8dj1UlZkbiJd"
   },
   "outputs": [],
   "source": [
    "userList=list(d['user_id'])\n",
    "itemList=list(d['item_id'])\n",
    "ratingList=list(d['ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EuTgqT-1biJd"
   },
   "outputs": [],
   "source": [
    "URM_all = sp.coo_matrix((ratingList,(userList,itemList)))\n",
    "URM_all = URM_all.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "r4kLvs-TbiJd",
    "outputId": "547ba2f6-8e3d-4fda-9dc3-08577d183c47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7947x25975 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 113268 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FSE7ic-VbiJd"
   },
   "outputs": [],
   "source": [
    "def load_data_ICM():\n",
    "  return pd.read_csv(\"./data_ICM_title_abstract.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-d-NVkEZbiJd"
   },
   "outputs": [],
   "source": [
    "features=load_data_ICM()\n",
    "d ={'item_id': features['row'],'feature_id':features['col'],'value':features['data']}\n",
    "features=pd.DataFrame(data=d)\n",
    "itemList=list(d['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hJs6hZ8obiJd"
   },
   "outputs": [],
   "source": [
    "featureList=list(d['feature_id'])\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(featureList)\n",
    "\n",
    "featureList = le.transform(featureList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kR-oPdRtbiJd"
   },
   "outputs": [],
   "source": [
    "valueList=list(d['value'])\n",
    "ICM_all = sp.coo_matrix((valueList,(itemList,featureList)))\n",
    "ICM_all = ICM_all.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_PXL-kG4biJd",
    "outputId": "163614e6-32e7-451c-b1b2-0de16719dea1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25975x19998 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 490691 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICM_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qeu8vW1mnmMG"
   },
   "source": [
    "This section wors with the previously-loaded ratings dataset and extracts the number of users, number of items, and min/max user/item identifiers. Exploring and understanding the data is an essential step prior fitting any recommender/algorithm.\n",
    "\n",
    "In this specific case, we discover that item identifiers go between 1 and 25974, however, there are only 24896 different items. To ease further calculations, we create new contiguous user/item identifiers, we then assign each user/item only one of these new identifiers. To keep track of these new mappings, we add them into the original dataframe using the pd.merge function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "opRzVXAweyTi"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(ratings: pd.DataFrame):\n",
    "    unique_users = ratings.user_id.unique()\n",
    "    unique_items = ratings.item_id.unique()\n",
    "    \n",
    "    num_users, min_user_id, max_user_id = unique_users.size, unique_users.min(), unique_users.max()\n",
    "    num_items, min_item_id, max_item_id = unique_items.size, unique_items.min(), unique_items.max()\n",
    "    \n",
    "    print(num_users, min_user_id, max_user_id)\n",
    "    print(num_items, min_item_id, max_item_id)\n",
    "    \n",
    "    mapping_user_id = pd.DataFrame({\"mapped_user_id\": np.arange(num_users), \"user_id\": unique_users})\n",
    "    mapping_item_id = pd.DataFrame({\"mapped_item_id\": np.arange(num_items), \"item_id\": unique_items})\n",
    "    \n",
    "    ratings = pd.merge(left=ratings, \n",
    "                       right=mapping_user_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"user_id\")\n",
    "    \n",
    "    ratings = pd.merge(left=ratings, \n",
    "                       right=mapping_item_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"item_id\")\n",
    "    \n",
    "    return ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXImqe5r-Oz7",
    "outputId": "10f3c684-9b54-4210-c96b-cabbe631fe64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7947 0 7946\n",
      "24896 0 25974\n"
     ]
    }
   ],
   "source": [
    "ratings=preprocess_data(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "LcbCQRZU-myg",
    "outputId": "d34c0dda-ace9-40f3-f751-769bed3a0201"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>ratings</th>\n",
       "      <th>mapped_user_id</th>\n",
       "      <th>mapped_item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4342</td>\n",
       "      <td>10080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5526</td>\n",
       "      <td>10080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5923</td>\n",
       "      <td>10080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>19467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>149</td>\n",
       "      <td>19467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4072</td>\n",
       "      <td>19467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6193</td>\n",
       "      <td>19467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7105</td>\n",
       "      <td>19467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>150</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>183</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>183</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>249</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>296</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>436</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>436</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>487</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>722</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>722</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>776</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>776</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>880</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>962</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>962</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1020</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1099</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1099</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1292</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1368</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1368</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1514</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1514</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1590</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1590</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1760</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1760</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1789</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1789</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1863</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1863</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1894</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113238</th>\n",
       "      <td>7905</td>\n",
       "      <td>11286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7905</td>\n",
       "      <td>24866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113239</th>\n",
       "      <td>7910</td>\n",
       "      <td>21388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7910</td>\n",
       "      <td>24867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113240</th>\n",
       "      <td>7910</td>\n",
       "      <td>22986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7910</td>\n",
       "      <td>24868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113241</th>\n",
       "      <td>7912</td>\n",
       "      <td>23124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7912</td>\n",
       "      <td>24869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113242</th>\n",
       "      <td>7917</td>\n",
       "      <td>16567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>24870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113243</th>\n",
       "      <td>7924</td>\n",
       "      <td>16469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7924</td>\n",
       "      <td>24871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113244</th>\n",
       "      <td>7924</td>\n",
       "      <td>19472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7924</td>\n",
       "      <td>24872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113245</th>\n",
       "      <td>7928</td>\n",
       "      <td>6259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7928</td>\n",
       "      <td>24873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113246</th>\n",
       "      <td>7928</td>\n",
       "      <td>8405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7928</td>\n",
       "      <td>24874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113247</th>\n",
       "      <td>7930</td>\n",
       "      <td>13453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7930</td>\n",
       "      <td>24875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113248</th>\n",
       "      <td>7930</td>\n",
       "      <td>19070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7930</td>\n",
       "      <td>24876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113249</th>\n",
       "      <td>7943</td>\n",
       "      <td>11754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7943</td>\n",
       "      <td>24877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113250</th>\n",
       "      <td>7944</td>\n",
       "      <td>426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113251</th>\n",
       "      <td>7944</td>\n",
       "      <td>1509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113252</th>\n",
       "      <td>7944</td>\n",
       "      <td>2357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113253</th>\n",
       "      <td>7944</td>\n",
       "      <td>3802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113254</th>\n",
       "      <td>7944</td>\n",
       "      <td>4170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113255</th>\n",
       "      <td>7944</td>\n",
       "      <td>6778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113256</th>\n",
       "      <td>7944</td>\n",
       "      <td>9373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113257</th>\n",
       "      <td>7944</td>\n",
       "      <td>14346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113258</th>\n",
       "      <td>7944</td>\n",
       "      <td>17483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113259</th>\n",
       "      <td>7944</td>\n",
       "      <td>18543</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113260</th>\n",
       "      <td>7944</td>\n",
       "      <td>18806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113261</th>\n",
       "      <td>7944</td>\n",
       "      <td>20450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113262</th>\n",
       "      <td>7944</td>\n",
       "      <td>21103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113263</th>\n",
       "      <td>7944</td>\n",
       "      <td>22542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113264</th>\n",
       "      <td>7944</td>\n",
       "      <td>24806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113265</th>\n",
       "      <td>7944</td>\n",
       "      <td>24912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113266</th>\n",
       "      <td>7944</td>\n",
       "      <td>24990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113267</th>\n",
       "      <td>7944</td>\n",
       "      <td>25953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113268 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  ratings  mapped_user_id  mapped_item_id\n",
       "0             0    10080      1.0               0               0\n",
       "1          4342    10080      1.0            4342               0\n",
       "2          5526    10080      1.0            5526               0\n",
       "3          5923    10080      1.0            5923               0\n",
       "4             0    19467      1.0               0               1\n",
       "5           149    19467      1.0             149               1\n",
       "6          4072    19467      1.0            4072               1\n",
       "7          6193    19467      1.0            6193               1\n",
       "8          7105    19467      1.0            7105               1\n",
       "9             1     2665      1.0               1               2\n",
       "10          150     2665      1.0             150               2\n",
       "11          183     2665      1.0             183               2\n",
       "12          249     2665      1.0             249               2\n",
       "13          296     2665      1.0             296               2\n",
       "14          436     2665      1.0             436               2\n",
       "15          487     2665      1.0             487               2\n",
       "16          722     2665      1.0             722               2\n",
       "17          776     2665      1.0             776               2\n",
       "18          880     2665      1.0             880               2\n",
       "19          962     2665      1.0             962               2\n",
       "20         1020     2665      1.0            1020               2\n",
       "21         1099     2665      1.0            1099               2\n",
       "22         1292     2665      1.0            1292               2\n",
       "23         1368     2665      1.0            1368               2\n",
       "24         1514     2665      1.0            1514               2\n",
       "25         1590     2665      1.0            1590               2\n",
       "26         1760     2665      1.0            1760               2\n",
       "27         1789     2665      1.0            1789               2\n",
       "28         1863     2665      1.0            1863               2\n",
       "29         1894     2665      1.0            1894               2\n",
       "...         ...      ...      ...             ...             ...\n",
       "113238     7905    11286      1.0            7905           24866\n",
       "113239     7910    21388      1.0            7910           24867\n",
       "113240     7910    22986      1.0            7910           24868\n",
       "113241     7912    23124      1.0            7912           24869\n",
       "113242     7917    16567      1.0            7917           24870\n",
       "113243     7924    16469      1.0            7924           24871\n",
       "113244     7924    19472      1.0            7924           24872\n",
       "113245     7928     6259      1.0            7928           24873\n",
       "113246     7928     8405      1.0            7928           24874\n",
       "113247     7930    13453      1.0            7930           24875\n",
       "113248     7930    19070      1.0            7930           24876\n",
       "113249     7943    11754      1.0            7943           24877\n",
       "113250     7944      426      1.0            7944           24878\n",
       "113251     7944     1509      1.0            7944           24879\n",
       "113252     7944     2357      1.0            7944           24880\n",
       "113253     7944     3802      1.0            7944           24881\n",
       "113254     7944     4170      1.0            7944           24882\n",
       "113255     7944     6778      1.0            7944           24883\n",
       "113256     7944     9373      1.0            7944           24884\n",
       "113257     7944    14346      1.0            7944           24885\n",
       "113258     7944    17483      1.0            7944           24886\n",
       "113259     7944    18543      1.0            7944           24887\n",
       "113260     7944    18806      1.0            7944           24888\n",
       "113261     7944    20450      1.0            7944           24889\n",
       "113262     7944    21103      1.0            7944           24890\n",
       "113263     7944    22542      1.0            7944           24891\n",
       "113264     7944    24806      1.0            7944           24892\n",
       "113265     7944    24912      1.0            7944           24893\n",
       "113266     7944    24990      1.0            7944           24894\n",
       "113267     7944    25953      1.0            7944           24895\n",
       "\n",
       "[113268 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1nF1b-IxETlQ"
   },
   "outputs": [],
   "source": [
    "unique_users = ratings.mapped_user_id.unique()\n",
    "unique_items = ratings.mapped_item_id.unique()\n",
    "num_users=unique_users.size\n",
    "num_items=unique_items.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WM9qAWrsErrh",
    "outputId": "90ab2706-8653-493f-add7-34a01078629b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7947"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BL44FpZ7EtJT",
    "outputId": "d2f5551a-0d20-4cfe-8b24-33608d561661"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24896"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLb4ij1thWhs"
   },
   "source": [
    "**Dataset splitting into train,validation and test**\n",
    "\n",
    "This is the last part before creating the recommender. However, this step is super important, as it is the base for the training, parameters optimization, and evaluation of the recommender(s).\n",
    "\n",
    "In here we read the ratings (which we loaded and preprocessed before) and create the train, validation, and test User-Rating Matrices (URM). It's important that these are disjoint to avoid information leakage from the train into the validation/test set, in our case, we are safe to use the train_test_split function from scikit-learn as the dataset only contains one datapoint for every (user,item) pair. On another topic, we first create the test set and then we create the validation by splitting again the train set.\n",
    "\n",
    "train_test_split takes an array (or several arrays) and divides it into train and test according to a given size (in our case testing_percentage and validation_percentage, which need to be a float between 0 and 1).\n",
    "\n",
    "After we have our different splits, we create the sparse URMs by using the csr_matrix function from scipy.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "O6NH1KqRhgiq"
   },
   "outputs": [],
   "source": [
    "def dataset_splits(ratings, num_users, num_items, validation_percentage: float, testing_percentage: float):\n",
    "    seed = 1234\n",
    "    \n",
    "    (user_ids_training, user_ids_test,\n",
    "     item_ids_training, item_ids_test,\n",
    "     ratings_training, ratings_test) = train_test_split(ratings.mapped_user_id,\n",
    "                                                        ratings.mapped_item_id,\n",
    "                                                        ratings.ratings,\n",
    "                                                        test_size=testing_percentage,\n",
    "                                                        shuffle=True,\n",
    "                                                        random_state=seed)\n",
    "    \n",
    "    (user_ids_training, user_ids_validation,\n",
    "     item_ids_training, item_ids_validation,\n",
    "     ratings_training, ratings_validation) = train_test_split(user_ids_training,\n",
    "                                                              item_ids_training,\n",
    "                                                              ratings_training,\n",
    "                                                              test_size=validation_percentage,\n",
    "                                                             )\n",
    "    \n",
    "    urm_train = sp.csr_matrix((ratings_training, (user_ids_training, item_ids_training)), \n",
    "                              shape=(num_users, num_items))\n",
    "    \n",
    "    \n",
    "    urm_validation = sp.csr_matrix((ratings_validation, (user_ids_validation, item_ids_validation)), \n",
    "                              shape=(num_users, num_items))\n",
    "    \n",
    "    urm_test = sp.csr_matrix((ratings_test, (user_ids_test, item_ids_test)), \n",
    "                              shape=(num_users, num_items))\n",
    "    \n",
    "\n",
    "    \n",
    "    return urm_train, urm_validation, urm_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dr3cbAKMDyb7"
   },
   "outputs": [],
   "source": [
    "urm_train, urm_validation, urm_test = dataset_splits(ratings, \n",
    "                                                     num_users, \n",
    "                                                     num_items, \n",
    "                                                     validation_percentage=0.10, \n",
    "                                                     testing_percentage=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm_train_validation = urm_train + urm_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Metrics**\n",
    "\n",
    "In this practice session we will be using the same evaluation metrics defined in the Practice session 2, i.e., precision, recall and mean average precision (MAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(recommendations: np.array, relevant_items: np.array) -> float:\n",
    "    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n",
    "    \n",
    "    recall_score = np.sum(is_relevant) / relevant_items.shape[0]\n",
    "    \n",
    "    return recall_score\n",
    "    \n",
    "    \n",
    "def precision(recommendations: np.array, relevant_items: np.array) -> float:\n",
    "    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_score = np.sum(is_relevant) / recommendations.shape[0]\n",
    "\n",
    "    return precision_score\n",
    "\n",
    "def mean_average_precision(recommendations: np.array, relevant_items: np.array) -> float:\n",
    "    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "\n",
    "    map_score = np.sum(precision_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return map_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Procedure**\n",
    "\n",
    "The evaluation procedure returns the averaged accuracy scores (in terms of precision, recall and MAP) for all users (that have at least 1 rating in the test set). It also calculates the number of evaluated and skipped users. It receives a recommender instance, and the train and test URMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(recommender: object, urm_train: sp.csr_matrix, urm_test: sp.csr_matrix):\n",
    "    recommendation_length = 10\n",
    "    accum_precision = 0\n",
    "    accum_recall = 0\n",
    "    accum_map = 0\n",
    "    \n",
    "    num_users = urm_train.shape[0]\n",
    "    \n",
    "    num_users_evaluated = 0\n",
    "    num_users_skipped = 0\n",
    "    for user_id in range(num_users):\n",
    "        user_profile_start = urm_test.indptr[user_id]\n",
    "        user_profile_end = urm_test.indptr[user_id+1]\n",
    "        \n",
    "        relevant_items = urm_test.indices[user_profile_start:user_profile_end]\n",
    "        \n",
    "        if relevant_items.size == 0:\n",
    "            num_users_skipped += 1\n",
    "            continue\n",
    "            \n",
    "        recommendations = recommender.recommend(user_id=user_id,\n",
    "                                               urm_train = urm_train,\n",
    "                                               at=recommendation_length\n",
    "                                               #remove_seen=True)\n",
    "                                               )\n",
    "        \n",
    "        accum_precision += precision(recommendations, relevant_items)\n",
    "        accum_recall += recall(recommendations, relevant_items)\n",
    "        accum_map += mean_average_precision(recommendations, relevant_items)\n",
    "        \n",
    "        num_users_evaluated += 1\n",
    "        \n",
    "    \n",
    "    accum_precision /= max(num_users_evaluated, 1)\n",
    "    accum_recall /= max(num_users_evaluated, 1)\n",
    "    accum_map /=  max(num_users_evaluated, 1)\n",
    "    \n",
    "    return accum_precision, accum_recall, accum_map, num_users_evaluated, num_users_skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hybrid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRecommender(object):\n",
    "    def __init__(self, w, user_cf_param, item_cf_param, slim_param):\n",
    "\n",
    "        self.w=w\n",
    "        ###### USER CF #####\n",
    "        self.userCF = UserBasedCollaborativeFiltering(knn=user_cf_param[\"knn\"], shrink=user_cf_param[\"shrink\"])\n",
    "    \n",
    "        ###### ITEM_CF #####\n",
    "        self.itemCF = ItemBasedCollaborativeFiltering(knn=item_cf_param[\"knn\"], shrink=item_cf_param[\"shrink\"])\n",
    "        \n",
    "        self.slim_random = SLIM_BPR_Cython(epochs=slim_param[\"epochs\"], topK=slim_param[\"topK\"])\n",
    "        \n",
    "        #self.slim_elastic = SLIMElasticNetRecommender()\n",
    "    \n",
    "\n",
    "    def fit(self, URM):\n",
    "        self.URM = URM\n",
    "\n",
    "        ### SUB-FITTING ###\n",
    "        print(\"Fitting user cf...\")\n",
    "        self.userCF.fit(URM.copy())\n",
    "\n",
    "        print(\"Fitting item cf...\")\n",
    "        self.itemCF.fit(URM.copy())\n",
    "        \n",
    "        print(\"Fitting slim bpr...\")\n",
    "        self.slim_random.fit(URM.copy())\n",
    "        \n",
    "        print(\"Fitting slim elastic...\")\n",
    "        #self.slim_elastic.fit(URM.copy())\n",
    "\n",
    "\n",
    "    def recommend(self,user_id,urm_train: sp.csr_matrix,at=10):\n",
    "\n",
    "\n",
    "        ### DUE TO TIME CONSTRAINT THE CODE STRUCTURE HERE IS REDUNTANT\n",
    "        ### TODO exploit inheritance to reduce code duplications and simple extract ratings, combine them, simply by iterate over a list of recommenders\n",
    "        self.userCF_ratings = self.userCF.get_expected_ratings(user_id)\n",
    "        self.itemCF_ratings = self.itemCF.get_expected_ratings(user_id)\n",
    "        self.slim_ratings = self.slim_random.get_expected_ratings(user_id)\n",
    "        #self.slim_elastic_ratings = self.slim_elastic.get_expected_ratings(user_id)\n",
    "\n",
    "        ### COMMON CODE ###\n",
    "        self.hybrid_ratings = None #BE CAREFUL, MAGIC INSIDE :)\n",
    "\n",
    "\n",
    "        self.hybrid_ratings = self.userCF_ratings * w[\"user_cf\"]\n",
    "        self.hybrid_ratings += self.itemCF_ratings * w[\"item_cf\"]\n",
    "        #self.hybrid_ratings += self.cbf_ratings * w_right[\"cbf\"]\n",
    "        self.hybrid_ratings += self.slim_ratings * w[\"slim\"]\n",
    "        #self.hybrid_ratings += self.ALS_ratings * w_right[\"als\"]\n",
    "        #self.hybrid_ratings += self.slim_elastic_ratings * w[\"elastic\"]\n",
    "\n",
    "        recommended_items = np.flip(np.argsort(self.hybrid_ratings), 0)\n",
    "\n",
    "        # REMOVING SEEN\n",
    "        unseen_items_mask = np.in1d(recommended_items,urm_train[user_id].indices,\n",
    "                                    assume_unique=True, invert=True)\n",
    "        recommended_items = recommended_items[unseen_items_mask]\n",
    "\n",
    "        return recommended_items[0:at]\n",
    "\n",
    "\n",
    "\n",
    "################################ PARAMETERS #################################\n",
    "#################### Value for best sumbissions, MAP@10 on Kaggle = 0.1 ###########################\n",
    "\n",
    "w = {\n",
    "    \"user_cf\": 0.03,\n",
    "    \"item_cf\": 0.35,\n",
    "    \"cbf\": 0.15,\n",
    "    \"icm_svd\": 0,\n",
    "    \"als\": 0.3,\n",
    "    \"slim\": 0.6,\n",
    "    \"elastic\": 1.5\n",
    "}\n",
    "\n",
    "user_cf_param = {\n",
    "    \"knn\": 140,\n",
    "    \"shrink\": 0\n",
    "}\n",
    "\n",
    "item_cf_param = {\n",
    "    \"knn\": 310,\n",
    "    \"shrink\": 0\n",
    "}\n",
    "\n",
    "slim_param = {\n",
    "    \"epochs\": 40,\n",
    "    \"topK\": 200\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = HybridRecommender(w=w,user_cf_param=user_cf_param,item_cf_param=item_cf_param,slim_param=slim_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting user cf...\n",
      "Similarity column 7947 ( 100 % ), 3723.71 column/sec, elapsed time 0.04 min\n",
      "Fitting item cf...\n",
      "Similarity column 24896 ( 100 % ), 2834.04 column/sec, elapsed time 0.15 min\n",
      "Fitting slim bpr...\n",
      "SLIM_BPR_Cython: Estimated memory required for similarity matrix of 24896 items is 2479.24 MB\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Buffer dtype mismatch, expected 'long' but got 'long long'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-03bb3a15a545>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecommender\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murm_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-cff0bbcf3513>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, URM)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting slim bpr...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslim_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mURM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting slim elastic...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\GitHub\\Recommender\\SLIM\\SLIM_BPR_Cython.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, URM_train)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_incremental_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mcurrentEpoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\GitHub\\Recommender\\SLIM\\SLIM_BPR_Cython.py\u001b[0m in \u001b[0;36m_initialize_incremental_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_initialize_incremental_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS_incremental\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcythonEpoch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_S\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mS_incremental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mSLIM_BPR_Cython_Epoch.pyx\u001b[0m in \u001b[0;36mSLIM_BPR_Cython_Epoch.SLIM_BPR_Cython_Epoch.get_S\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mSLIM_BPR_Cython_Epoch.pyx\u001b[0m in \u001b[0;36mSLIM_BPR_Cython_Epoch.Triangular_Matrix.get_scipy_csr\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'long' but got 'long long'"
     ]
    }
   ],
   "source": [
    "recommender.fit(urm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_precision, accum_recall, accum_map, num_user_evaluated, num_users_skipped = evaluator(recommender, \n",
    "                                                                                            urm_train_validation, \n",
    "                                                                                            urm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_precision, accum_recall, accum_map, num_user_evaluated, num_users_skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Vi-dduXaj46"
   },
   "source": [
    "**Submission to competition**\n",
    "\n",
    "This step serves as a similar step that you will perform when preparing a submission to the competition. Specially after you have chosen and trained your recommender.\n",
    "\n",
    "For this step the best suggestion is to select the most-performing configuration obtained in the hyperparameter tuning step and to train the recommender using both the train and validation set. Remember that in the competition you do not have access to the test set.\n",
    "\n",
    "Another consideration is that, due to easier and faster calculations, we replaced the user/item identifiers with new ones in the preprocessing step. For the competition, you are required to generate recommendations using the dataset's original identifiers. Due to this, this step also reverts back the newer identifiers with the ones originally found in the dataset.\n",
    "\n",
    "Last, this step creates a function that writes the recommendations for each user in the same file in a tabular format following this format:\n",
    "\n",
    "csv\n",
    "<user_id>,<item_id_1> <item_id_2> <item_id_3> <item_id_4> <item_id_5> <item_id_6> <item_id_7> <item_id_8> <item_id_9> <item_id_10>\n",
    "Always verify the competitions' submission file model as it might vary from the one we presented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcSDk9aMtW4k"
   },
   "outputs": [],
   "source": [
    "def load_goodguys():\n",
    "  return pd.read_csv(\"./data_target_users_test.csv\")\n",
    "goodguys=load_goodguys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHzsuFiqtW4k",
    "outputId": "bc36c459-1cc6-460a-b403-95482cf1508d"
   },
   "outputs": [],
   "source": [
    "goodguys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0b3DwuXrayTA",
    "outputId": "27c6d557-b304-427c-bf2c-8fdc090efe64"
   },
   "outputs": [],
   "source": [
    "users_to_recommend = np.random.choice(goodguys.user_id,size=goodguys.size, replace=False)\n",
    "users_to_recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzOneO7sa1N9"
   },
   "outputs": [],
   "source": [
    "mapping_to_item_id = dict(zip(ratings.mapped_item_id, ratings.item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUd6VsfPa4I7",
    "outputId": "7438e193-183d-40f2-c196-628d900aadce"
   },
   "outputs": [],
   "source": [
    "mapping_to_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RurxNTttbI-i"
   },
   "outputs": [],
   "source": [
    "def prepare_submission(ratings: pd.DataFrame, users_to_recommend: np.array, urm_train: sp.csr_matrix, recommender: object):\n",
    "    users_ids_and_mappings = ratings[ratings.user_id.isin(users_to_recommend)][[\"user_id\", \"mapped_user_id\"]].drop_duplicates()\n",
    "    items_ids_and_mappings = ratings[[\"item_id\", \"mapped_item_id\"]].drop_duplicates()\n",
    "    \n",
    "    mapping_to_item_id = dict(zip(ratings.mapped_item_id, ratings.item_id))\n",
    "    \n",
    "    \n",
    "    recommendation_length = 10\n",
    "    submission = []\n",
    "    for idx, row in users_ids_and_mappings.iterrows():\n",
    "        user_id = row.user_id\n",
    "        mapped_user_id = row.mapped_user_id\n",
    "        \n",
    "        recommendations = recommender.recommend(user_id=mapped_user_id,\n",
    "                                                urm_train=urm_train,\n",
    "                                                at=recommendation_length,\n",
    "                                                #remove_seen=True)\n",
    "                                               )\n",
    "        \n",
    "        submission.append((user_id, [mapping_to_item_id[item_id] for item_id in recommendations]))\n",
    "        \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KYlvMDVbLxo"
   },
   "outputs": [],
   "source": [
    "submission = prepare_submission(ratings, users_to_recommend, urm_train_validation,rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJZEjE3CbQTp",
    "outputId": "8e2faf6b-144c-4ba3-ee1a-692290e15d3c"
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hCawP60bVm3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "csv_fname = './submission'\n",
    "csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "def write_submission(submissions):\n",
    "    with open(csv_fname, \"w\") as f:\n",
    "        f.write(f\"user_id,item_list\\n\")\n",
    "        for user_id, items in submissions:\n",
    "            f.write(f\"{user_id},{' '.join([str(item) for item in items])}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ov91al-UbXAQ"
   },
   "outputs": [],
   "source": [
    "write_submission(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmnDxjbObe32"
   },
   "source": [
    "In this lecture we saw the most simple version of Cosine Similarity, where it just includes a shrink factor. There are different optimizations that we can do to it.\n",
    "\n",
    "Implement TopK Neighbors\n",
    "When calculating the cosine similarity we used urm.T.dot(urm) to calculate the enumerator. However, depending of the dataset and the number of items, this matrix could not fit in memory. Implemenent a block version, faster than our vector version but that does not use urm.T.dot(urm) beforehand.\n",
    "\n",
    "Implement Adjusted Cosine \n",
    "\n",
    "Implement Dice Similarity\n",
    "\n",
    "Implement an implicit CF ItemKNN.\n",
    "\n",
    "Implement a CF UserKNN model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RecommenderChallenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
