{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ybQSYdHvb_CB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "#----Recommenders----\n",
    "from SLIM.SLIM_BPR_Python import SLIM_BPR_Python\n",
    "from SLIM.SlimElasticNet import SLIMElasticNetRecommender\n",
    "from cf.item_cf import ItemBasedCollaborativeFiltering\n",
    "from cf.user_cf import UserBasedCollaborativeFiltering\n",
    "from MF.ALS import AlternatingLeastSquare\n",
    "from cbf.cbf import ContentBasedFiltering\n",
    "#---------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyPCmUzVedBh"
   },
   "source": [
    "**Dataset loading with pandas**\n",
    "\n",
    "The function read_csv from pandas provides a wonderful and fast interface to load tabular data like this. For better results and performance we provide the separator ::, the column names [\"user_id\", \"item_id\", \"ratings\", \"timestamp\"], and the types of each attribute in the dtype parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "96AUQmIlcAr2"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "  return pd.read_csv(\"./data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vMaAYCCksV82"
   },
   "outputs": [],
   "source": [
    "ratings=load_data()\n",
    "d ={'user_id': ratings['row'],'item_id':ratings['col'],'ratings':ratings['data']}\n",
    "ratings=pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "enpGAp964Y5a",
    "outputId": "c436ac0a-ab96-4e87-8990-dea6db1076a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id      int64\n",
       "item_id      int64\n",
       "ratings    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8dj1UlZkbiJd"
   },
   "outputs": [],
   "source": [
    "userList=list(d['user_id'])\n",
    "itemList=list(d['item_id'])\n",
    "ratingList=list(d['ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EuTgqT-1biJd"
   },
   "outputs": [],
   "source": [
    "URM_all = sp.coo_matrix((ratingList,(userList,itemList)))\n",
    "URM_all = URM_all.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "r4kLvs-TbiJd",
    "outputId": "547ba2f6-8e3d-4fda-9dc3-08577d183c47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7947x25975 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 113268 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FSE7ic-VbiJd"
   },
   "outputs": [],
   "source": [
    "def load_data_ICM():\n",
    "  return pd.read_csv(\"./data_ICM_title_abstract.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-d-NVkEZbiJd"
   },
   "outputs": [],
   "source": [
    "features=load_data_ICM()\n",
    "d ={'item_id': features['row'],'feature_id':features['col'],'value':features['data']}\n",
    "features=pd.DataFrame(data=d)\n",
    "itemList=list(d['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hJs6hZ8obiJd"
   },
   "outputs": [],
   "source": [
    "featureList=list(d['feature_id'])\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(featureList)\n",
    "\n",
    "featureList = le.transform(featureList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kR-oPdRtbiJd"
   },
   "outputs": [],
   "source": [
    "valueList=list(d['value'])\n",
    "ICM_all = sp.coo_matrix((valueList,(itemList,featureList)))\n",
    "ICM_all = ICM_all.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_PXL-kG4biJd",
    "outputId": "163614e6-32e7-451c-b1b2-0de16719dea1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25975x19998 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 490691 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICM_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qeu8vW1mnmMG"
   },
   "source": [
    "This section wors with the previously-loaded ratings dataset and extracts the number of users, number of items, and min/max user/item identifiers. Exploring and understanding the data is an essential step prior fitting any recommender/algorithm.\n",
    "\n",
    "In this specific case, we discover that item identifiers go between 1 and 25974, however, there are only 24896 different items. To ease further calculations, we create new contiguous user/item identifiers, we then assign each user/item only one of these new identifiers. To keep track of these new mappings, we add them into the original dataframe using the pd.merge function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "opRzVXAweyTi"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(ratings: pd.DataFrame):\n",
    "    unique_users = ratings.user_id.unique()\n",
    "    unique_items = ratings.item_id.unique()\n",
    "    \n",
    "    num_users, min_user_id, max_user_id = unique_users.size, unique_users.min(), unique_users.max()\n",
    "    num_items, min_item_id, max_item_id = unique_items.size, unique_items.min(), unique_items.max()\n",
    "    \n",
    "    print(num_users, min_user_id, max_user_id)\n",
    "    print(num_items, min_item_id, max_item_id)\n",
    "    \n",
    "    mapping_user_id = pd.DataFrame({\"mapped_user_id\": np.arange(num_users), \"user_id\": unique_users})\n",
    "    mapping_item_id = pd.DataFrame({\"mapped_item_id\": np.arange(num_items), \"item_id\": unique_items})\n",
    "    \n",
    "    ratings = pd.merge(left=ratings, \n",
    "                       right=mapping_user_id,\n",
    "                       how=\"inner\",#inner\n",
    "                       on=\"user_id\")\n",
    "    \n",
    "    ratings = pd.merge(left=ratings, \n",
    "                       right=mapping_item_id,\n",
    "                       how=\"inner\",#inner\n",
    "                       on=\"item_id\")\n",
    "    \n",
    "    return ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXImqe5r-Oz7",
    "outputId": "10f3c684-9b54-4210-c96b-cabbe631fe64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7947 0 7946\n",
      "24896 0 25974\n"
     ]
    }
   ],
   "source": [
    "ratings=preprocess_data(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "1nF1b-IxETlQ"
   },
   "outputs": [],
   "source": [
    "unique_users = ratings.mapped_user_id.unique()\n",
    "unique_items = ratings.mapped_item_id.unique()\n",
    "num_users=unique_users.size\n",
    "num_items=unique_items.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLb4ij1thWhs"
   },
   "source": [
    "**Dataset splitting into train,validation and test**\n",
    "\n",
    "This is the last part before creating the recommender. However, this step is super important, as it is the base for the training, parameters optimization, and evaluation of the recommender(s).\n",
    "\n",
    "In here we read the ratings (which we loaded and preprocessed before) and create the train, validation, and test User-Rating Matrices (URM). It's important that these are disjoint to avoid information leakage from the train into the validation/test set, in our case, we are safe to use the train_test_split function from scikit-learn as the dataset only contains one datapoint for every (user,item) pair. On another topic, we first create the test set and then we create the validation by splitting again the train set.\n",
    "\n",
    "train_test_split takes an array (or several arrays) and divides it into train and test according to a given size (in our case testing_percentage and validation_percentage, which need to be a float between 0 and 1).\n",
    "\n",
    "After we have our different splits, we create the sparse URMs by using the csr_matrix function from scipy.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "O6NH1KqRhgiq"
   },
   "outputs": [],
   "source": [
    "def dataset_splits(ratings, num_users, num_items, validation_percentage: float, testing_percentage: float):\n",
    "    seed = 1234\n",
    "    \n",
    "    (user_ids_training, user_ids_test,\n",
    "     item_ids_training, item_ids_test,\n",
    "     ratings_training, ratings_test) = train_test_split(ratings.mapped_user_id,\n",
    "                                                        ratings.mapped_item_id,\n",
    "                                                        ratings.ratings,\n",
    "                                                        test_size=testing_percentage,\n",
    "                                                        shuffle=True,\n",
    "                                                        random_state=seed)\n",
    "    \n",
    "    (user_ids_training, user_ids_validation,\n",
    "     item_ids_training, item_ids_validation,\n",
    "     ratings_training, ratings_validation) = train_test_split(user_ids_training,\n",
    "                                                              item_ids_training,\n",
    "                                                              ratings_training,\n",
    "                                                              test_size=validation_percentage,\n",
    "                                                             )\n",
    "    \n",
    "    urm_train = sp.csr_matrix((ratings_training, (user_ids_training, item_ids_training)), \n",
    "                              shape=(num_users, num_items))\n",
    "    \n",
    "    \n",
    "    urm_validation = sp.csr_matrix((ratings_validation, (user_ids_validation, item_ids_validation)), \n",
    "                              shape=(num_users, num_items))\n",
    "    \n",
    "    urm_test = sp.csr_matrix((ratings_test, (user_ids_test, item_ids_test)), \n",
    "                              shape=(num_users, num_items))\n",
    "    \n",
    "\n",
    "    \n",
    "    return urm_train, urm_validation, urm_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dr3cbAKMDyb7"
   },
   "outputs": [],
   "source": [
    "urm_train, urm_validation, urm_test = dataset_splits(ratings, \n",
    "                                                     num_users, \n",
    "                                                     num_items, \n",
    "                                                     validation_percentage=0.10, \n",
    "                                                     testing_percentage=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm_train_validation = urm_train + urm_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7947x24896 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 96277 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urm_train_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(recommendations: np.array, relevant_items: np.array) -> float:\n",
    "    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n",
    "    \n",
    "    recall_score = np.sum(is_relevant) / relevant_items.shape[0]\n",
    "    \n",
    "    return recall_score\n",
    "    \n",
    "    \n",
    "def precision(recommendations: np.array, relevant_items: np.array) -> float:\n",
    "    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_score = np.sum(is_relevant) / recommendations.shape[0]\n",
    "\n",
    "    return precision_score\n",
    "\n",
    "def mean_average_precision(recommendations: np.array, relevant_items: np.array) -> float:\n",
    "    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "\n",
    "    map_score = np.sum(precision_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return map_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Procedure**\n",
    "\n",
    "The evaluation procedure returns the averaged accuracy scores (in terms of precision, recall and MAP) for all users (that have at least 1 rating in the test set). It also calculates the number of evaluated and skipped users. It receives a recommender instance, and the train and test URMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(recommender: object, urm_train: sp.csr_matrix, urm_test: sp.csr_matrix):\n",
    "    recommendation_length = 10\n",
    "    accum_precision = 0\n",
    "    accum_recall = 0\n",
    "    accum_map = 0\n",
    "    \n",
    "    num_users = urm_train.shape[0]\n",
    "    \n",
    "    num_users_evaluated = 0\n",
    "    num_users_skipped = 0\n",
    "    for user_id in range(num_users):\n",
    "        user_profile_start = urm_test.indptr[user_id]\n",
    "        user_profile_end = urm_test.indptr[user_id+1]\n",
    "        \n",
    "        relevant_items = urm_test.indices[user_profile_start:user_profile_end]\n",
    "        \n",
    "        if relevant_items.size == 0:\n",
    "            num_users_skipped += 1\n",
    "            continue\n",
    "            \n",
    "        recommendations = recommender.recommend(user_id=user_id,\n",
    "                                               urm_train = urm_train,\n",
    "                                               at=recommendation_length\n",
    "                                               #remove_seen=True)\n",
    "                                               )\n",
    "        \n",
    "        accum_precision += precision(recommendations, relevant_items)\n",
    "        accum_recall += recall(recommendations, relevant_items)\n",
    "        accum_map += mean_average_precision(recommendations, relevant_items)\n",
    "        \n",
    "        num_users_evaluated += 1\n",
    "        \n",
    "    \n",
    "    accum_precision /= max(num_users_evaluated, 1)\n",
    "    accum_recall /= max(num_users_evaluated, 1)\n",
    "    accum_map /=  max(num_users_evaluated, 1)\n",
    "    \n",
    "    return accum_precision, accum_recall, accum_map, num_users_evaluated, num_users_skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hybrid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRecommender(object):\n",
    "    def __init__(self, w, user_cf_param, item_cf_param, cbf_param, slim_param, als_param):\n",
    "\n",
    "        self.w=w\n",
    "\n",
    "        self.userCF = UserBasedCollaborativeFiltering(knn=user_cf_param[\"knn\"], shrink=user_cf_param[\"shrink\"])\n",
    "\n",
    "        self.itemCF = ItemBasedCollaborativeFiltering(knn=item_cf_param[\"knn\"], shrink=item_cf_param[\"shrink\"])\n",
    "        \n",
    "        #self.cbf = ContentBasedFiltering(knn=cbf_param[\"knn\"],shrink=cbf_param[\"shrink\"])\n",
    "        \n",
    "        self.slim_random = SLIM_BPR_Python(topK=slim_param[\"topK\"],epochs=slim_param[\"epochs\"])\n",
    "        \n",
    "        self.slim_elastic = SLIMElasticNetRecommender()\n",
    "        \n",
    "        self.ALS = AlternatingLeastSquare(n_factors=als_param[\"n_factors\"], regularization=als_param[\"regularization\"],iterations=als_param[\"iterations\"])\n",
    "    \n",
    "\n",
    "    def fit(self, URM, ICM):\n",
    "        self.URM = URM\n",
    "\n",
    "        ### SUB-FITTING ###\n",
    "        print(\"Fitting user cf...\")\n",
    "        self.userCF.fit(URM.copy())\n",
    "\n",
    "        print(\"Fitting item cf...\")\n",
    "        self.itemCF.fit(URM.copy())\n",
    "        \n",
    "        #print(\"Fitting cbf...\")\n",
    "        #self.cbf.fit(URM.copy(),ICM.copy())\n",
    "        \n",
    "        print(\"Fitting slim bpr...\")\n",
    "        self.slim_random.fit(URM.copy())\n",
    "        \n",
    "        print(\"Fitting slim elastic...\")\n",
    "        self.slim_elastic.fit(URM.copy())\n",
    "        \n",
    "        print(\"Fitting ALS...\")\n",
    "        self.ALS.fit(URM.copy())\n",
    "\n",
    "\n",
    "    def recommend(self,user_id,urm_train: sp.csr_matrix,at=10):\n",
    "     \n",
    "        self.userCF_ratings = self.userCF.get_expected_ratings(user_id)\n",
    "        self.itemCF_ratings = self.itemCF.get_expected_ratings(user_id)\n",
    "        #self.cbf_ratings = self.cbf.get_expected_ratings(user_id)\n",
    "        self.slim_ratings = self.slim_random.get_expected_ratings(user_id)\n",
    "        self.slim_elastic_ratings = self.slim_elastic.get_expected_ratings(user_id)\n",
    "        self.ALS_ratings = self.ALS.get_expected_ratings(user_id)\n",
    "\n",
    "        self.hybrid_ratings = None \n",
    "\n",
    "        self.hybrid_ratings = self.userCF_ratings * w[\"user_cf\"]\n",
    "        self.hybrid_ratings += self.itemCF_ratings * w[\"item_cf\"]\n",
    "        #self.hybrid_ratings += self.cbf_ratings * w_right[\"cbf\"]\n",
    "        self.hybrid_ratings += self.slim_ratings * w[\"slim\"]\n",
    "        self.hybrid_ratings += self.ALS_ratings * w[\"als\"]\n",
    "        self.hybrid_ratings += self.slim_elastic_ratings * w[\"elastic\"]\n",
    "\n",
    "        recommended_items = np.flip(np.argsort(self.hybrid_ratings), 0)\n",
    "\n",
    "        # REMOVING SEEN\n",
    "        unseen_items_mask = np.in1d(recommended_items,urm_train[user_id].indices,\n",
    "                                    assume_unique=True, invert=True)\n",
    "        recommended_items = recommended_items[unseen_items_mask]\n",
    "\n",
    "        return recommended_items[0:at]\n",
    "\n",
    "w = {\n",
    "    \"user_cf\": 0.03,\n",
    "    \"item_cf\": 0.35,\n",
    "    \"cbf\": 0.15,\n",
    "    \"icm_svd\": 0,\n",
    "    \"als\": 0.3,\n",
    "    \"slim\": 0.6,\n",
    "    \"elastic\": 1.5\n",
    "}\n",
    "\n",
    "cbf_param = {\n",
    "    \"knn\": 140,\n",
    "    \"shrink\": 0\n",
    "}\n",
    "\n",
    "user_cf_param = {\n",
    "    \"knn\": 140,\n",
    "    \"shrink\": 0\n",
    "}\n",
    "\n",
    "item_cf_param = {\n",
    "    \"knn\": 310,\n",
    "    \"shrink\": 0\n",
    "}\n",
    "\n",
    "slim_param = {\n",
    "    \"epochs\": 40,\n",
    "    \"topK\": 200\n",
    "}\n",
    "\n",
    "als_param = {\n",
    "    \"n_factors\": 300,\n",
    "    \"regularization\": 0.15,\n",
    "    \"iterations\": 30\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = HybridRecommender(w=w,user_cf_param=user_cf_param,item_cf_param=item_cf_param,cbf_param=cbf_param,slim_param=slim_param,als_param=als_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting user cf...\n",
      "Similarity column 7947 ( 100 % ), 3743.09 column/sec, elapsed time 0.04 min\n",
      "Fitting item cf...\n",
      "Similarity column 24896 ( 100 % ), 2982.05 column/sec, elapsed time 0.14 min\n",
      "Fitting slim bpr...\n",
      "Epoch 1, Iteration 7947 in 0.56 seconds. Samples per second 14089.37\n",
      "Epoch 2, Iteration 7947 in 0.58 seconds. Samples per second 13795.89\n",
      "Epoch 3, Iteration 7947 in 0.57 seconds. Samples per second 13892.36\n",
      "Epoch 4, Iteration 7947 in 0.54 seconds. Samples per second 14661.30\n",
      "Epoch 5, Iteration 7947 in 0.54 seconds. Samples per second 14825.41\n",
      "Epoch 6, Iteration 7947 in 0.53 seconds. Samples per second 14993.18\n",
      "Epoch 7, Iteration 7947 in 0.54 seconds. Samples per second 14825.42\n",
      "Epoch 8, Iteration 7947 in 0.53 seconds. Samples per second 14908.78\n",
      "Epoch 9, Iteration 7947 in 0.51 seconds. Samples per second 15490.09\n",
      "Epoch 10, Iteration 7947 in 0.53 seconds. Samples per second 14880.84\n",
      "Epoch 11, Iteration 7947 in 0.53 seconds. Samples per second 15136.03\n",
      "Epoch 12, Iteration 7947 in 0.52 seconds. Samples per second 15223.07\n",
      "Epoch 13, Iteration 7947 in 0.59 seconds. Samples per second 13422.97\n",
      "Epoch 14, Iteration 7947 in 0.55 seconds. Samples per second 14553.86\n",
      "Epoch 15, Iteration 7947 in 0.53 seconds. Samples per second 14908.82\n",
      "Epoch 16, Iteration 7947 in 0.51 seconds. Samples per second 15520.33\n",
      "Epoch 17, Iteration 7947 in 0.51 seconds. Samples per second 15611.74\n",
      "Epoch 18, Iteration 7947 in 0.51 seconds. Samples per second 15550.74\n",
      "Epoch 19, Iteration 7947 in 0.52 seconds. Samples per second 15223.00\n",
      "Epoch 20, Iteration 7947 in 0.50 seconds. Samples per second 15798.07\n",
      "Epoch 21, Iteration 7947 in 0.52 seconds. Samples per second 15370.24\n",
      "Epoch 22, Iteration 7947 in 0.51 seconds. Samples per second 15611.75\n",
      "Epoch 23, Iteration 7947 in 0.52 seconds. Samples per second 15400.04\n",
      "Epoch 24, Iteration 7947 in 0.51 seconds. Samples per second 15642.48\n",
      "Epoch 25, Iteration 7947 in 0.50 seconds. Samples per second 16021.07\n",
      "Epoch 26, Iteration 7947 in 0.52 seconds. Samples per second 15252.22\n",
      "Epoch 27, Iteration 7947 in 0.51 seconds. Samples per second 15642.57\n",
      "Epoch 28, Iteration 7947 in 0.50 seconds. Samples per second 15892.87\n",
      "Epoch 29, Iteration 7947 in 0.52 seconds. Samples per second 15370.24\n",
      "Epoch 30, Iteration 7947 in 0.53 seconds. Samples per second 15136.03\n",
      "Epoch 31, Iteration 7947 in 0.50 seconds. Samples per second 15956.66\n",
      "Epoch 32, Iteration 7947 in 0.52 seconds. Samples per second 15281.55\n",
      "Epoch 33, Iteration 7947 in 0.51 seconds. Samples per second 15735.41\n",
      "Epoch 34, Iteration 7947 in 0.51 seconds. Samples per second 15459.97\n",
      "Epoch 35, Iteration 7947 in 0.50 seconds. Samples per second 15829.07\n",
      "Epoch 36, Iteration 7947 in 0.50 seconds. Samples per second 15956.63\n",
      "Epoch 37, Iteration 7947 in 0.53 seconds. Samples per second 14964.96\n",
      "Epoch 38, Iteration 7947 in 0.52 seconds. Samples per second 15429.92\n",
      "Epoch 39, Iteration 7947 in 0.50 seconds. Samples per second 15798.01\n",
      "Epoch 40, Iteration 7947 in 0.51 seconds. Samples per second 15550.66\n",
      "Train completed in 0.35 minutes\n",
      "Fitting slim elastic...\n",
      "Fitting ALS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dfe23c638448e68ed767fe50f44661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recommender.fit(urm_train,ICM_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_precision, accum_recall, accum_map, num_user_evaluated, num_users_skipped = evaluator(recommender, \n",
    "                                                                                            urm_train_validation, \n",
    "                                                                                            urm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.018200120797261826, 0.07801696885187408, 0.0336238303249925, 4967, 2980)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum_precision, accum_recall, accum_map, num_user_evaluated, num_users_skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Vi-dduXaj46"
   },
   "source": [
    "**Submission to competition**\n",
    "\n",
    "This step serves as a similar step that you will perform when preparing a submission to the competition. Specially after you have chosen and trained your recommender.\n",
    "\n",
    "For this step the best suggestion is to select the most-performing configuration obtained in the hyperparameter tuning step and to train the recommender using both the train and validation set. Remember that in the competition you do not have access to the test set.\n",
    "\n",
    "Another consideration is that, due to easier and faster calculations, we replaced the user/item identifiers with new ones in the preprocessing step. For the competition, you are required to generate recommendations using the dataset's original identifiers. Due to this, this step also reverts back the newer identifiers with the ones originally found in the dataset.\n",
    "\n",
    "Last, this step creates a function that writes the recommendations for each user in the same file in a tabular format following this format:\n",
    "\n",
    "csv\n",
    "<user_id>,<item_id_1> <item_id_2> <item_id_3> <item_id_4> <item_id_5> <item_id_6> <item_id_7> <item_id_8> <item_id_9> <item_id_10>\n",
    "Always verify the competitions' submission file model as it might vary from the one we presented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcSDk9aMtW4k"
   },
   "outputs": [],
   "source": [
    "def load_goodguys():\n",
    "  return pd.read_csv(\"./data_target_users_test.csv\")\n",
    "goodguys=load_goodguys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHzsuFiqtW4k",
    "outputId": "bc36c459-1cc6-460a-b403-95482cf1508d"
   },
   "outputs": [],
   "source": [
    "goodguys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0b3DwuXrayTA",
    "outputId": "27c6d557-b304-427c-bf2c-8fdc090efe64"
   },
   "outputs": [],
   "source": [
    "users_to_recommend = np.random.choice(goodguys.user_id,size=goodguys.size, replace=False)\n",
    "users_to_recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gzOneO7sa1N9"
   },
   "outputs": [],
   "source": [
    "mapping_to_item_id = dict(zip(ratings.mapped_item_id, ratings.item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUd6VsfPa4I7",
    "outputId": "7438e193-183d-40f2-c196-628d900aadce"
   },
   "outputs": [],
   "source": [
    "mapping_to_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RurxNTttbI-i"
   },
   "outputs": [],
   "source": [
    "def prepare_submission(ratings: pd.DataFrame, users_to_recommend: np.array, urm_train: sp.csr_matrix, recommender: object):\n",
    "    users_ids_and_mappings = ratings[ratings.user_id.isin(users_to_recommend)][[\"user_id\", \"mapped_user_id\"]].drop_duplicates()\n",
    "    items_ids_and_mappings = ratings[[\"item_id\", \"mapped_item_id\"]].drop_duplicates()\n",
    "    \n",
    "    mapping_to_item_id = dict(zip(ratings.mapped_item_id, ratings.item_id))\n",
    "    \n",
    "    \n",
    "    recommendation_length = 10\n",
    "    submission = []\n",
    "    for idx, row in users_ids_and_mappings.iterrows():\n",
    "        user_id = row.user_id\n",
    "        mapped_user_id = row.mapped_user_id\n",
    "        \n",
    "        recommendations = recommender.recommend(user_id=mapped_user_id,\n",
    "                                                urm_train=urm_train,\n",
    "                                                at=recommendation_length,\n",
    "                                                #remove_seen=True)\n",
    "                                               )\n",
    "        \n",
    "        submission.append((user_id, [mapping_to_item_id[item_id] for item_id in recommendations]))\n",
    "        \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KYlvMDVbLxo"
   },
   "outputs": [],
   "source": [
    "submission = prepare_submission(ratings, users_to_recommend, urm_train_validation,rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJZEjE3CbQTp",
    "outputId": "8e2faf6b-144c-4ba3-ee1a-692290e15d3c"
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hCawP60bVm3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "csv_fname = './submission'\n",
    "csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "def write_submission(submissions):\n",
    "    with open(csv_fname, \"w\") as f:\n",
    "        f.write(f\"user_id,item_list\\n\")\n",
    "        for user_id, items in submissions:\n",
    "            f.write(f\"{user_id},{' '.join([str(item) for item in items])}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ov91al-UbXAQ"
   },
   "outputs": [],
   "source": [
    "write_submission(submission)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RecommenderChallenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
