{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lw_Kk4FAtr6W"
   },
   "source": [
    "**Basic ItemKNN recommender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ybQSYdHvb_CB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Tuple,Callable,Dict,Optional,List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyPCmUzVedBh"
   },
   "source": [
    "**Dataset loading with pandas**\n",
    "\n",
    "The function read_csv from pandas provides a wonderful and fast interface to load tabular data like this. For better results and performance we provide the separator ::, the column names [\"user_id\", \"item_id\", \"ratings\", \"timestamp\"], and the types of each attribute in the dtype parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "96AUQmIlcAr2"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "  return pd.read_csv(\"./data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vMaAYCCksV82"
   },
   "outputs": [],
   "source": [
    "ratings=load_data()\n",
    "d ={'user_id': ratings['row'],'item_id':ratings['col'],'ratings':ratings['data']}\n",
    "ratings=pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "enpGAp964Y5a",
    "outputId": "c436ac0a-ab96-4e87-8990-dea6db1076a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id      int64\n",
       "item_id      int64\n",
       "ratings    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8dj1UlZkbiJd"
   },
   "outputs": [],
   "source": [
    "userList=list(d['user_id'])\n",
    "itemList=list(d['item_id'])\n",
    "ratingList=list(d['ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EuTgqT-1biJd"
   },
   "outputs": [],
   "source": [
    "URM_all = sp.coo_matrix((ratingList,(userList,itemList)))\n",
    "URM_all = URM_all.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "r4kLvs-TbiJd",
    "outputId": "547ba2f6-8e3d-4fda-9dc3-08577d183c47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7947x25975 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 113268 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FSE7ic-VbiJd"
   },
   "outputs": [],
   "source": [
    "def load_data_ICM():\n",
    "  return pd.read_csv(\"./data_ICM_title_abstract.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-d-NVkEZbiJd"
   },
   "outputs": [],
   "source": [
    "features=load_data()\n",
    "d ={'item_id': features['row'],'feature_id':features['col'],'value':features['data']}\n",
    "features=pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hJs6hZ8obiJd"
   },
   "outputs": [],
   "source": [
    "featureList=list(d['feature_id'])\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(featureList)\n",
    "\n",
    "featureList = le.transform(featureList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kR-oPdRtbiJd"
   },
   "outputs": [],
   "source": [
    "ones = np.ones(len(featureList))\n",
    "ICM_all = sp.coo_matrix((ones, (itemList,featureList)), shape=(URM_all.shape[1],featureList.max()+1))\n",
    "ICM_all = ICM_all.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7947x25975 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 113268 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_PXL-kG4biJd",
    "outputId": "163614e6-32e7-451c-b1b2-0de16719dea1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25975x24896 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 24896 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICM_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qeu8vW1mnmMG"
   },
   "source": [
    "This section wors with the previously-loaded ratings dataset and extracts the number of users, number of items, and min/max user/item identifiers. Exploring and understanding the data is an essential step prior fitting any recommender/algorithm.\n",
    "\n",
    "In this specific case, we discover that item identifiers go between 1 and 25974, however, there are only 24896 different items. To ease further calculations, we create new contiguous user/item identifiers, we then assign each user/item only one of these new identifiers. To keep track of these new mappings, we add them into the original dataframe using the pd.merge function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "opRzVXAweyTi"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(ratings: pd.DataFrame):\n",
    "    unique_users = ratings.user_id.unique()\n",
    "    unique_items = ratings.item_id.unique()\n",
    "    \n",
    "    num_users, min_user_id, max_user_id = unique_users.size, unique_users.min(), unique_users.max()\n",
    "    num_items, min_item_id, max_item_id = unique_items.size, unique_items.min(), unique_items.max()\n",
    "    \n",
    "    print(num_users, min_user_id, max_user_id)\n",
    "    print(num_items, min_item_id, max_item_id)\n",
    "    \n",
    "    mapping_user_id = pd.DataFrame({\"mapped_user_id\": np.arange(num_users), \"user_id\": unique_users})\n",
    "    mapping_item_id = pd.DataFrame({\"mapped_item_id\": np.arange(num_items), \"item_id\": unique_items})\n",
    "    \n",
    "    ratings = pd.merge(left=ratings, \n",
    "                       right=mapping_user_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"user_id\")\n",
    "    \n",
    "    ratings = pd.merge(left=ratings, \n",
    "                       right=mapping_item_id,\n",
    "                       how=\"inner\",\n",
    "                       on=\"item_id\")\n",
    "    \n",
    "    return ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXImqe5r-Oz7",
    "outputId": "10f3c684-9b54-4210-c96b-cabbe631fe64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7947 0 7946\n",
      "24896 0 25974\n"
     ]
    }
   ],
   "source": [
    "ratings=preprocess_data(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "LcbCQRZU-myg",
    "outputId": "d34c0dda-ace9-40f3-f751-769bed3a0201"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>ratings</th>\n",
       "      <th>mapped_user_id</th>\n",
       "      <th>mapped_item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4342</td>\n",
       "      <td>10080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5526</td>\n",
       "      <td>10080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5923</td>\n",
       "      <td>10080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>19467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>149</td>\n",
       "      <td>19467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4072</td>\n",
       "      <td>19467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6193</td>\n",
       "      <td>19467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6193</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7105</td>\n",
       "      <td>19467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>150</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>183</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>183</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>249</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>249</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>296</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>436</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>436</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>487</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>722</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>722</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>776</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>776</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>880</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>962</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>962</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1020</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1099</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1099</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1292</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1368</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1368</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1514</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1514</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1590</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1590</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1760</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1760</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1789</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1789</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1863</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1863</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1894</td>\n",
       "      <td>2665</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113238</th>\n",
       "      <td>7905</td>\n",
       "      <td>11286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7905</td>\n",
       "      <td>24866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113239</th>\n",
       "      <td>7910</td>\n",
       "      <td>21388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7910</td>\n",
       "      <td>24867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113240</th>\n",
       "      <td>7910</td>\n",
       "      <td>22986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7910</td>\n",
       "      <td>24868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113241</th>\n",
       "      <td>7912</td>\n",
       "      <td>23124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7912</td>\n",
       "      <td>24869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113242</th>\n",
       "      <td>7917</td>\n",
       "      <td>16567</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>24870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113243</th>\n",
       "      <td>7924</td>\n",
       "      <td>16469</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7924</td>\n",
       "      <td>24871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113244</th>\n",
       "      <td>7924</td>\n",
       "      <td>19472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7924</td>\n",
       "      <td>24872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113245</th>\n",
       "      <td>7928</td>\n",
       "      <td>6259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7928</td>\n",
       "      <td>24873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113246</th>\n",
       "      <td>7928</td>\n",
       "      <td>8405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7928</td>\n",
       "      <td>24874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113247</th>\n",
       "      <td>7930</td>\n",
       "      <td>13453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7930</td>\n",
       "      <td>24875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113248</th>\n",
       "      <td>7930</td>\n",
       "      <td>19070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7930</td>\n",
       "      <td>24876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113249</th>\n",
       "      <td>7943</td>\n",
       "      <td>11754</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7943</td>\n",
       "      <td>24877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113250</th>\n",
       "      <td>7944</td>\n",
       "      <td>426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113251</th>\n",
       "      <td>7944</td>\n",
       "      <td>1509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113252</th>\n",
       "      <td>7944</td>\n",
       "      <td>2357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113253</th>\n",
       "      <td>7944</td>\n",
       "      <td>3802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113254</th>\n",
       "      <td>7944</td>\n",
       "      <td>4170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113255</th>\n",
       "      <td>7944</td>\n",
       "      <td>6778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113256</th>\n",
       "      <td>7944</td>\n",
       "      <td>9373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113257</th>\n",
       "      <td>7944</td>\n",
       "      <td>14346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113258</th>\n",
       "      <td>7944</td>\n",
       "      <td>17483</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113259</th>\n",
       "      <td>7944</td>\n",
       "      <td>18543</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113260</th>\n",
       "      <td>7944</td>\n",
       "      <td>18806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113261</th>\n",
       "      <td>7944</td>\n",
       "      <td>20450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113262</th>\n",
       "      <td>7944</td>\n",
       "      <td>21103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113263</th>\n",
       "      <td>7944</td>\n",
       "      <td>22542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113264</th>\n",
       "      <td>7944</td>\n",
       "      <td>24806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113265</th>\n",
       "      <td>7944</td>\n",
       "      <td>24912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113266</th>\n",
       "      <td>7944</td>\n",
       "      <td>24990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113267</th>\n",
       "      <td>7944</td>\n",
       "      <td>25953</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7944</td>\n",
       "      <td>24895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113268 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  ratings  mapped_user_id  mapped_item_id\n",
       "0             0    10080      1.0               0               0\n",
       "1          4342    10080      1.0            4342               0\n",
       "2          5526    10080      1.0            5526               0\n",
       "3          5923    10080      1.0            5923               0\n",
       "4             0    19467      1.0               0               1\n",
       "5           149    19467      1.0             149               1\n",
       "6          4072    19467      1.0            4072               1\n",
       "7          6193    19467      1.0            6193               1\n",
       "8          7105    19467      1.0            7105               1\n",
       "9             1     2665      1.0               1               2\n",
       "10          150     2665      1.0             150               2\n",
       "11          183     2665      1.0             183               2\n",
       "12          249     2665      1.0             249               2\n",
       "13          296     2665      1.0             296               2\n",
       "14          436     2665      1.0             436               2\n",
       "15          487     2665      1.0             487               2\n",
       "16          722     2665      1.0             722               2\n",
       "17          776     2665      1.0             776               2\n",
       "18          880     2665      1.0             880               2\n",
       "19          962     2665      1.0             962               2\n",
       "20         1020     2665      1.0            1020               2\n",
       "21         1099     2665      1.0            1099               2\n",
       "22         1292     2665      1.0            1292               2\n",
       "23         1368     2665      1.0            1368               2\n",
       "24         1514     2665      1.0            1514               2\n",
       "25         1590     2665      1.0            1590               2\n",
       "26         1760     2665      1.0            1760               2\n",
       "27         1789     2665      1.0            1789               2\n",
       "28         1863     2665      1.0            1863               2\n",
       "29         1894     2665      1.0            1894               2\n",
       "...         ...      ...      ...             ...             ...\n",
       "113238     7905    11286      1.0            7905           24866\n",
       "113239     7910    21388      1.0            7910           24867\n",
       "113240     7910    22986      1.0            7910           24868\n",
       "113241     7912    23124      1.0            7912           24869\n",
       "113242     7917    16567      1.0            7917           24870\n",
       "113243     7924    16469      1.0            7924           24871\n",
       "113244     7924    19472      1.0            7924           24872\n",
       "113245     7928     6259      1.0            7928           24873\n",
       "113246     7928     8405      1.0            7928           24874\n",
       "113247     7930    13453      1.0            7930           24875\n",
       "113248     7930    19070      1.0            7930           24876\n",
       "113249     7943    11754      1.0            7943           24877\n",
       "113250     7944      426      1.0            7944           24878\n",
       "113251     7944     1509      1.0            7944           24879\n",
       "113252     7944     2357      1.0            7944           24880\n",
       "113253     7944     3802      1.0            7944           24881\n",
       "113254     7944     4170      1.0            7944           24882\n",
       "113255     7944     6778      1.0            7944           24883\n",
       "113256     7944     9373      1.0            7944           24884\n",
       "113257     7944    14346      1.0            7944           24885\n",
       "113258     7944    17483      1.0            7944           24886\n",
       "113259     7944    18543      1.0            7944           24887\n",
       "113260     7944    18806      1.0            7944           24888\n",
       "113261     7944    20450      1.0            7944           24889\n",
       "113262     7944    21103      1.0            7944           24890\n",
       "113263     7944    22542      1.0            7944           24891\n",
       "113264     7944    24806      1.0            7944           24892\n",
       "113265     7944    24912      1.0            7944           24893\n",
       "113266     7944    24990      1.0            7944           24894\n",
       "113267     7944    25953      1.0            7944           24895\n",
       "\n",
       "[113268 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "1nF1b-IxETlQ"
   },
   "outputs": [],
   "source": [
    "unique_users = ratings.mapped_user_id.unique()\n",
    "unique_items = ratings.mapped_item_id.unique()\n",
    "num_users=unique_users.size\n",
    "num_items=unique_items.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WM9qAWrsErrh",
    "outputId": "90ab2706-8653-493f-add7-34a01078629b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7947"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BL44FpZ7EtJT",
    "outputId": "d2f5551a-0d20-4cfe-8b24-33608d561661"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24896"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLb4ij1thWhs"
   },
   "source": [
    "**Dataset splitting into train,validation and test**\n",
    "\n",
    "This is the last part before creating the recommender. However, this step is super important, as it is the base for the training, parameters optimization, and evaluation of the recommender(s).\n",
    "\n",
    "In here we read the ratings (which we loaded and preprocessed before) and create the train, validation, and test User-Rating Matrices (URM). It's important that these are disjoint to avoid information leakage from the train into the validation/test set, in our case, we are safe to use the train_test_split function from scikit-learn as the dataset only contains one datapoint for every (user,item) pair. On another topic, we first create the test set and then we create the validation by splitting again the train set.\n",
    "\n",
    "train_test_split takes an array (or several arrays) and divides it into train and test according to a given size (in our case testing_percentage and validation_percentage, which need to be a float between 0 and 1).\n",
    "\n",
    "After we have our different splits, we create the sparse URMs by using the csr_matrix function from scipy.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "O6NH1KqRhgiq"
   },
   "outputs": [],
   "source": [
    "def dataset_splits(ratings, num_users, num_items, validation_percentage: float, testing_percentage: float):\n",
    "    seed = 1234\n",
    "    \n",
    "    (user_ids_training, user_ids_test,\n",
    "     item_ids_training, item_ids_test,\n",
    "     ratings_training, ratings_test) = train_test_split(ratings.mapped_user_id,\n",
    "                                                        ratings.mapped_item_id,\n",
    "                                                        ratings.ratings,\n",
    "                                                        test_size=testing_percentage,\n",
    "                                                        shuffle=True,\n",
    "                                                        random_state=seed)\n",
    "    \n",
    "    (user_ids_training, user_ids_validation,\n",
    "     item_ids_training, item_ids_validation,\n",
    "     ratings_training, ratings_validation) = train_test_split(user_ids_training,\n",
    "                                                              item_ids_training,\n",
    "                                                              ratings_training,\n",
    "                                                              test_size=validation_percentage,\n",
    "                                                             )\n",
    "    \n",
    "    urm_train = sp.csr_matrix((ratings_training, (user_ids_training, item_ids_training)), \n",
    "                              shape=(num_users, num_items))\n",
    "    \n",
    "    urm_validation = sp.csr_matrix((ratings_validation, (user_ids_validation, item_ids_validation)), \n",
    "                              shape=(num_users, num_items))\n",
    "    \n",
    "    urm_test = sp.csr_matrix((ratings_test, (user_ids_test, item_ids_test)), \n",
    "                              shape=(num_users, num_items))\n",
    "    \n",
    "\n",
    "    \n",
    "    return urm_train, urm_validation, urm_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dr3cbAKMDyb7"
   },
   "outputs": [],
   "source": [
    "urm_train, urm_validation, urm_test = dataset_splits(ratings, \n",
    "                                                     num_users, \n",
    "                                                     num_items, \n",
    "                                                     validation_percentage=0.10, \n",
    "                                                     testing_percentage=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-qg8MVxuE5S"
   },
   "source": [
    "**SLIM MSE**\n",
    "\n",
    "Our objective is to minimize the MSE ( mean square error) by choosing the best similarity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y69AoF71ZJY_"
   },
   "source": [
    "**Collaborative Filtering ItemKNN Recommender**\n",
    "\n",
    "This step creates a CFItemKNN class that represents a Collaborative Filtering ItemKNN Recommender. As we have mentioned in previous practice sessions, our recommenders have two main functions: fit and recommend. In addition we added a filter_seen and the train_multiple_epochs_SLIM_MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "pLgzRovyZTih"
   },
   "outputs": [],
   "source": [
    "class CFItemKNN(object):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.similarity_matrix = None\n",
    "        \n",
    "    def fit(self,urm_train,learning_rate,epochs):\n",
    "        \n",
    "        #if not sp.isspmatrix_csc(urm_train):\n",
    "        #    raise TypeError(f\"We expected a CSC matrix, we got {type(urm_train)}\")\n",
    "        \n",
    "        self.similarity_matrix=self.train_multiple_epochs_SLIM_MSE(urm_train,learning_rate,epochs)\n",
    "        \n",
    "        \n",
    "    def recommend(self,user_id,urm_train: sp.csr_matrix,at=None,remove_seen=True):\n",
    "        # compute the scores using the dot product\n",
    "        user_profile = urm_train[user_id]\n",
    "        scores = user_profile.dot(self.similarity_matrix).ravel()\n",
    "\n",
    "        if remove_seen:\n",
    "            scores = self.filter_seen(urm_train,user_id,scores)\n",
    "\n",
    "        # rank items\n",
    "        ranking = scores.argsort()[::-1]\n",
    "            \n",
    "        return ranking[:at]\n",
    "    \n",
    "    \n",
    "    def filter_seen(self,urm_train,user_id,scores):\n",
    "\n",
    "        start_pos = urm_train.indptr[user_id]\n",
    "        end_pos = urm_train.indptr[user_id+1]\n",
    "\n",
    "        user_profile = urm_train.indices[start_pos:end_pos]\n",
    "        \n",
    "        scores[user_profile] = -np.inf\n",
    "\n",
    "        return scores  \n",
    "    \n",
    "    \n",
    "    def train_multiple_epochs_SLIM_MSE(self,URM_train, learning_rate_input, n_epochs):\n",
    "    \n",
    "        URM_train_coo = URM_train.tocoo()\n",
    "        n_items = URM_train.shape[1]\n",
    "        n_interactions = URM_train.nnz\n",
    "\n",
    "\n",
    "        URM_train_coo_row = URM_train_coo.row\n",
    "        URM_train_coo_col = URM_train_coo.col\n",
    "        URM_train_coo_data = URM_train_coo.data\n",
    "        URM_train_indices = URM_train.indices\n",
    "        URM_train_indptr = URM_train.indptr\n",
    "        URM_train_data = URM_train.data\n",
    "\n",
    "        # We create a dense similarity matrix, initialized as zero\n",
    "        item_item_S = np.zeros((n_items, n_items), dtype = np.float)\n",
    "\n",
    "        learning_rate = learning_rate_input\n",
    "        loss = 0.0\n",
    "\n",
    "        for n_epoch in range(n_epochs):\n",
    "\n",
    "            loss = 0.0\n",
    "            start_time = time.time()\n",
    "\n",
    "            for sample_num in range(n_interactions):\n",
    "\n",
    "                # Randomly pick sample\n",
    "                index = random.randrange(0,n_interactions)  #randrange(x,y) x included y not included\n",
    "                user_id = URM_train_coo_row[index]\n",
    "                item_id = URM_train_coo_col[index]\n",
    "                true_rating = URM_train_coo_data[index]\n",
    "\n",
    "                # Compute prediction\n",
    "                start_profile = URM_train_indptr[user_id]\n",
    "                end_profile = URM_train_indptr[user_id+1]\n",
    "                predicted_rating = 0.0\n",
    "\n",
    "                for index in range(start_profile, end_profile):\n",
    "                    profile_item_id = URM_train_indices[index]\n",
    "                    profile_rating = URM_train_data[index]\n",
    "                    predicted_rating += item_item_S[profile_item_id,item_id] * profile_rating\n",
    "\n",
    "                # Compute prediction error, or gradient.\n",
    "                prediction_error = true_rating - predicted_rating\n",
    "                loss += prediction_error**2\n",
    "\n",
    "                # Update model, in this case the similarity\n",
    "                for index in range(start_profile, end_profile):\n",
    "                    profile_item_id = URM_train_indices[index]\n",
    "                    profile_rating = URM_train_data[index]\n",
    "                    item_item_S[profile_item_id,item_id] += learning_rate * prediction_error * profile_rating\n",
    "\n",
    "    #             # Print some stats\n",
    "    #             if (sample_num +1)% 1000000 == 0:\n",
    "    #                 elapsed_time = time.time() - start_time\n",
    "    #                 samples_per_second = (sample_num+1)/elapsed_time\n",
    "    #                 print(\"Iteration {} in {:.2f} seconds, loss is {:.2f}. Samples per second {:.2f}\".format(sample_num+1, elapsed_time, loss/(sample_num+1), samples_per_second))\n",
    "\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            samples_per_second = (sample_num+1)/elapsed_time\n",
    "\n",
    "            print(\"Epoch {} complete in in {:.2f} seconds, loss is {:.3E}. Samples per second {:.2f}\".format(n_epoch+1, time.time() - start_time, loss/(sample_num+1), samples_per_second))\n",
    "            \n",
    "        return np.array(item_item_S) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation Metrics**\n",
    "\n",
    "In this practice session we will be using the same evaluation metrics defined in the Practice session 2, i.e., precision, recall and mean average precision (MAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recall(recommendations: np.array, relevant_items: np.array) -> float:\n",
    "    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n",
    "    \n",
    "    recall_score = np.sum(is_relevant) / relevant_items.shape[0]\n",
    "    \n",
    "    return recall_score\n",
    "    \n",
    "    \n",
    "def precision(recommendations: np.array, relevant_items: np.array) -> float:\n",
    "    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_score = np.sum(is_relevant) / recommendations.shape[0]\n",
    "\n",
    "    return precision_score\n",
    "\n",
    "def mean_average_precision(recommendations: np.array, relevant_items: np.array) -> float:\n",
    "    is_relevant = np.in1d(recommendations, relevant_items, assume_unique=True)\n",
    "    \n",
    "    precision_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "\n",
    "    map_score = np.sum(precision_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return map_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwr5yasbZ2jm"
   },
   "source": [
    "**Evaluation Procedure**\n",
    "\n",
    "The evaluation procedure returns the averaged accuracy scores (in terms of precision, recall and MAP) for all users (that have at least 1 rating in the test set). It also calculates the number of evaluated and skipped users. It receives a recommender instance, and the train and test URMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "2ogvo6EBZ55W"
   },
   "outputs": [],
   "source": [
    "def evaluator(recommender: object, urm_train: sp.csr_matrix, urm_test: sp.csr_matrix):\n",
    "    recommendation_length = 10\n",
    "    accum_precision = 0\n",
    "    accum_recall = 0\n",
    "    accum_map = 0\n",
    "    \n",
    "    num_users = urm_train.shape[0]\n",
    "    \n",
    "    num_users_evaluated = 0\n",
    "    num_users_skipped = 0\n",
    "    for user_id in range(num_users):\n",
    "        user_profile_start = urm_test.indptr[user_id]\n",
    "        user_profile_end = urm_test.indptr[user_id+1]\n",
    "        \n",
    "        relevant_items = urm_test.indices[user_profile_start:user_profile_end]\n",
    "        \n",
    "        if relevant_items.size == 0:\n",
    "            num_users_skipped += 1\n",
    "            continue\n",
    "            \n",
    "        recommendations = recommender.recommend(user_id=user_id,\n",
    "                                               urm_train = urm_train,\n",
    "                                               at=recommendation_length, \n",
    "                                               remove_seen=True)\n",
    "        \n",
    "        accum_precision += precision(recommendations, relevant_items)\n",
    "        accum_recall += recall(recommendations, relevant_items)\n",
    "        accum_map += mean_average_precision(recommendations, relevant_items)\n",
    "        \n",
    "        num_users_evaluated += 1\n",
    "        \n",
    "    \n",
    "    accum_precision /= max(num_users_evaluated, 1)\n",
    "    accum_recall /= max(num_users_evaluated, 1)\n",
    "    accum_map /=  max(num_users_evaluated, 1)\n",
    "    \n",
    "    return accum_precision, accum_recall, accum_map, num_users_evaluated, num_users_skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice 8 - Hybrid recommenders\n",
    "\n",
    "\n",
    "### The way to go to achieve the best recommendation quality\n",
    "\n",
    "## A few info about hybrids\n",
    "\n",
    "\n",
    "#### There are many different types of hibrids, in this practice we will see the following\n",
    "* Linear combination of item-based models\n",
    "* Linear combination of heterogeneous models\n",
    "* User-wise discrimination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 1: Import the evaluator objects\n",
    "\n",
    "from Base.Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "evaluator_validation = EvaluatorHoldout(urm_validation, cutoff_list=[5])\n",
    "evaluator_test = EvaluatorHoldout(urm_test, cutoff_list=[5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Base.Evaluation.Evaluator.EvaluatorHoldout at 0x2ba971426d8>,\n",
       " <Base.Evaluation.Evaluator.EvaluatorHoldout at 0x2ba96e77198>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator_validation,evaluator_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 2: Create BayesianSearch object\n",
    "import skopt\n",
    "import scipy.sparse as sps\n",
    "#from skopt import gp_minimize\n",
    "from KNN.ItemKNNCFRecommender import ItemKNNCFRecommender\n",
    "from ParameterTuning.SearchBayesianSkopt import SearchBayesianSkopt\n",
    "\n",
    "\n",
    "recommender_class = ItemKNNCFRecommender\n",
    "\n",
    "parameterSearch = SearchBayesianSkopt(recommender_class,\n",
    "                                 evaluator_validation=evaluator_validation,\n",
    "                                 evaluator_test=evaluator_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 3: Define parameters range\n",
    "\n",
    "from ParameterTuning.SearchAbstractClass import SearchInputRecommenderArgs\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "hyperparameters_range_dictionary = {}\n",
    "hyperparameters_range_dictionary[\"topK\"] = Integer(5, 1000)\n",
    "hyperparameters_range_dictionary[\"shrink\"] = Integer(0, 1000)\n",
    "hyperparameters_range_dictionary[\"similarity\"] = Categorical([\"cosine\"])\n",
    "hyperparameters_range_dictionary[\"normalize\"] = Categorical([True, False])\n",
    "    \n",
    "    \n",
    "recommender_input_args = SearchInputRecommenderArgs(\n",
    "    CONSTRUCTOR_POSITIONAL_ARGS = [urm_train],\n",
    "    CONSTRUCTOR_KEYWORD_ARGS = {},\n",
    "    FIT_POSITIONAL_ARGS = [],\n",
    "    FIT_KEYWORD_ARGS = {}\n",
    ")\n",
    "\n",
    "\n",
    "output_folder_path = \"result_experiments/\"\n",
    "\n",
    "import os\n",
    "\n",
    "# If directory does not exist, create\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "ItemKNNCFRecommender: URM Detected 143 (1.80 %) cold users.\n",
      "ItemKNNCFRecommender: URM Detected 2076 (8.34 %) cold items.\n",
      "SearchBayesianSkopt: Testing config: {'topK': 609, 'shrink': 578, 'similarity': 'cosine', 'normalize': False}\n",
      "Unable to load Cython Compute_Similarity, reverting to Python\n",
      "Similarity column 24896 ( 100 % ), 2800.76 column/sec, elapsed time 0.15 min\n",
      "EvaluatorHoldout: Processed 3654 ( 100.00% ) in 2.45 sec. Users per second: 1492\n",
      "SearchBayesianSkopt: New best config found. Config 0: {'topK': 609, 'shrink': 578, 'similarity': 'cosine', 'normalize': False} - results: ROC_AUC: 0.0600712, PRECISION: 0.0210728, PRECISION_RECALL_MIN_DEN: 0.0573162, RECALL: 0.0553876, MAP: 0.0325347, MRR: 0.0556468, NDCG: 0.0427990, F1: 0.0305301, HIT_RATE: 0.1053640, ARHR: 0.0578407, NOVELTY: 0.0023121, AVERAGE_POPULARITY: 0.1836063, DIVERSITY_MEAN_INTER_LIST: 0.9705516, DIVERSITY_HERFINDAHL: 0.9940572, COVERAGE_ITEM: 0.1611504, COVERAGE_ITEM_CORRECT: 0.0082343, COVERAGE_USER: 0.4597961, COVERAGE_USER_CORRECT: 0.0450484, DIVERSITY_GINI: 0.0449582, SHANNON_ENTROPY: 9.4824169, \n",
      "\n",
      "EvaluatorHoldout: Processed 5638 ( 100.00% ) in 5.24 sec. Users per second: 1075\n",
      "SearchBayesianSkopt: Best config evaluated with evaluator_test. Config: {'topK': 609, 'shrink': 578, 'similarity': 'cosine', 'normalize': False} - results:\n",
      "CUTOFF: 5 - ROC_AUC: 0.0872059, PRECISION: 0.0333097, PRECISION_RECALL_MIN_DEN: 0.0630720, RECALL: 0.0556337, MAP: 0.0370648, MRR: 0.0845128, NDCG: 0.0486356, F1: 0.0416701, HIT_RATE: 0.1665484, ARHR: 0.0923170, NOVELTY: 0.0023467, AVERAGE_POPULARITY: 0.1665970, DIVERSITY_MEAN_INTER_LIST: 0.9761035, DIVERSITY_HERFINDAHL: 0.9951861, COVERAGE_ITEM: 0.2300370, COVERAGE_ITEM_CORRECT: 0.0168702, COVERAGE_USER: 0.7094501, COVERAGE_USER_CORRECT: 0.0999119, DIVERSITY_GINI: 0.0627673, SHANNON_ENTROPY: 9.9257493, \n",
      "CUTOFF: 10 - ROC_AUC: 0.1224189, PRECISION: 0.0257183, PRECISION_RECALL_MIN_DEN: 0.0851476, RECALL: 0.0822022, MAP: 0.0383293, MRR: 0.0916141, NDCG: 0.0601121, F1: 0.0391789, HIT_RATE: 0.2571834, ARHR: 0.1041185, NOVELTY: 0.0048222, AVERAGE_POPULARITY: 0.1412762, DIVERSITY_MEAN_INTER_LIST: 0.9700373, DIVERSITY_HERFINDAHL: 0.9969865, COVERAGE_ITEM: 0.3626285, COVERAGE_ITEM_CORRECT: 0.0260684, COVERAGE_USER: 0.7094501, COVERAGE_USER_CORRECT: 0.1384170, DIVERSITY_GINI: 0.0901450, SHANNON_ENTROPY: 10.5310543, \n",
      "\n",
      "\n",
      "DataIO: Json dumps supports only 'str' as dictionary keys. Transforming keys to string, note that this will alter the mapper content.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 19.7669\n",
      "Function value obtained: -0.0325\n",
      "Current minimum: -0.0325\n",
      "Iteration No: 2 started. Searching for the next optimal point.\n",
      "ItemKNNCFRecommender: URM Detected 143 (1.80 %) cold users.\n",
      "ItemKNNCFRecommender: URM Detected 2076 (8.34 %) cold items.\n",
      "SearchBayesianSkopt: Testing config: {'topK': 5, 'shrink': 0, 'similarity': 'cosine', 'normalize': True}\n",
      "Unable to load Cython Compute_Similarity, reverting to Python\n",
      "Similarity column 24896 ( 100 % ), 3033.51 column/sec, elapsed time 0.14 min\n",
      "EvaluatorHoldout: Processed 3654 ( 100.00% ) in 1.95 sec. Users per second: 1872\n",
      "SearchBayesianSkopt: Config 1 is suboptimal. Config: {'topK': 5, 'shrink': 0, 'similarity': 'cosine', 'normalize': True} - results: ROC_AUC: 0.0361476, PRECISION: 0.0124795, PRECISION_RECALL_MIN_DEN: 0.0337210, RECALL: 0.0326434, MAP: 0.0195975, MRR: 0.0335979, NDCG: 0.0256276, F1: 0.0180561, HIT_RATE: 0.0623974, ARHR: 0.0345147, NOVELTY: 0.0028231, AVERAGE_POPULARITY: 0.0251946, DIVERSITY_MEAN_INTER_LIST: 0.9778192, DIVERSITY_HERFINDAHL: 0.9955103, COVERAGE_ITEM: 0.3141469, COVERAGE_ITEM_CORRECT: 0.0081539, COVERAGE_USER: 0.4597961, COVERAGE_USER_CORRECT: 0.0274317, DIVERSITY_GINI: 0.1700010, SHANNON_ENTROPY: 11.5732496, \n",
      "\n",
      "Iteration No: 2 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.5582\n",
      "Function value obtained: -0.0196\n",
      "Current minimum: -0.0325\n",
      "SearchBayesianSkopt: Search complete. Best config is 0: {'topK': 609, 'shrink': 578, 'similarity': 'cosine', 'normalize': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Step 4: Run!    --- error\n",
    "\n",
    "n_cases = 2\n",
    "metric_to_optimize = \"MAP\"\n",
    "\n",
    "parameterSearch.search(recommender_input_args,\n",
    "                       parameter_search_space = hyperparameters_range_dictionary,\n",
    "                       n_cases = n_cases,\n",
    "                       n_random_starts = 1,\n",
    "                       save_model = \"no\",\n",
    "                       output_folder_path = output_folder_path,\n",
    "                       output_file_name_root = recommender_class.RECOMMENDER_NAME,\n",
    "                       metric_to_optimize = metric_to_optimize\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemKNNCFRecommender: URM Detected 143 (1.80 %) cold users.\n",
      "ItemKNNCFRecommender: URM Detected 2076 (8.34 %) cold items.\n",
      "Unable to load Cython Compute_Similarity, reverting to Python\n",
      "Similarity column 24896 ( 100 % ), 2880.66 column/sec, elapsed time 0.14 min\n"
     ]
    }
   ],
   "source": [
    "### Step 4: Run!\n",
    "from Base.DataIO import DataIO\n",
    "\n",
    "data_loader = DataIO(folder_path = output_folder_path)\n",
    "search_metadata = data_loader.load_data(recommender_class.RECOMMENDER_NAME + \"_metadata.zip\")\n",
    "\n",
    "search_metadata\n",
    "\n",
    "best_parameters = search_metadata[\"hyperparameters_best\"]\n",
    "best_parameters\n",
    "\n",
    "# Linear combination of item-based models\n",
    "\n",
    "#### Let's use an ItemKNNCF with the parameters we just learned and a graph based model\n",
    "\n",
    "itemKNNCF = ItemKNNCFRecommender(urm_train)\n",
    "itemKNNCF.fit(**best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P3alphaRecommender: URM Detected 143 (1.80 %) cold users.\n",
      "P3alphaRecommender: URM Detected 2076 (8.34 %) cold items.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<24896x24896 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 1046288 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from GraphBased.P3alphaRecommender import P3alphaRecommender\n",
    "\n",
    "P3alpha = P3alphaRecommender(urm_train)\n",
    "P3alpha.fit()\n",
    "\n",
    "itemKNNCF.W_sparse\n",
    "\n",
    "P3alpha.W_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ItemKNNSimilarityHybridRecommender: URM Detected 143 (1.80 %) cold users.\n",
      "ItemKNNSimilarityHybridRecommender: URM Detected 2076 (8.34 %) cold items.\n",
      "EvaluatorHoldout: Processed 3654 ( 100.00% ) in 2.24 sec. Users per second: 1630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({5: {'ROC_AUC': 0.057562488596971356,\n",
       "   'PRECISION': 0.020032840722496014,\n",
       "   'PRECISION_RECALL_MIN_DEN': 0.05327494982667399,\n",
       "   'RECALL': 0.05113925505296939,\n",
       "   'MAP': 0.031164249224594053,\n",
       "   'MRR': 0.05328407224958948,\n",
       "   'NDCG': 0.04035084964794152,\n",
       "   'F1': 0.028788376679962563,\n",
       "   'HIT_RATE': 0.10016420361247948,\n",
       "   'ARHR': 0.05527276044517422,\n",
       "   'NOVELTY': 0.002671600520724747,\n",
       "   'AVERAGE_POPULARITY': 0.05604018021492563,\n",
       "   'DIVERSITY_MEAN_INTER_LIST': 0.997042806663619,\n",
       "   'DIVERSITY_HERFINDAHL': 0.9993539886558402,\n",
       "   'COVERAGE_ITEM': 0.3088849614395887,\n",
       "   'COVERAGE_ITEM_CORRECT': 0.012090295629820051,\n",
       "   'COVERAGE_USER': 0.45979614949037373,\n",
       "   'COVERAGE_USER_CORRECT': 0.04303510758776897,\n",
       "   'DIVERSITY_GINI': 0.16760618499174454,\n",
       "   'SHANNON_ENTROPY': 12.104265680684037}},\n",
       " 'CUTOFF: 5 - ROC_AUC: 0.0575625, PRECISION: 0.0200328, PRECISION_RECALL_MIN_DEN: 0.0532749, RECALL: 0.0511393, MAP: 0.0311642, MRR: 0.0532841, NDCG: 0.0403508, F1: 0.0287884, HIT_RATE: 0.1001642, ARHR: 0.0552728, NOVELTY: 0.0026716, AVERAGE_POPULARITY: 0.0560402, DIVERSITY_MEAN_INTER_LIST: 0.9970428, DIVERSITY_HERFINDAHL: 0.9993540, COVERAGE_ITEM: 0.3088850, COVERAGE_ITEM_CORRECT: 0.0120903, COVERAGE_USER: 0.4597961, COVERAGE_USER_CORRECT: 0.0430351, DIVERSITY_GINI: 0.1676062, SHANNON_ENTROPY: 12.1042657, \\n')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Base.Recommender_utils import check_matrix, similarityMatrixTopK\n",
    "from Base.BaseSimilarityMatrixRecommender import BaseItemSimilarityMatrixRecommender\n",
    "\n",
    "\n",
    "class ItemKNNSimilarityHybridRecommender(BaseItemSimilarityMatrixRecommender):\n",
    "    \"\"\" ItemKNNSimilarityHybridRecommender\n",
    "    Hybrid of two similarities S = S1*alpha + S2*(1-alpha)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"ItemKNNSimilarityHybridRecommender\"\n",
    "\n",
    "\n",
    "    def __init__(self, URM_train, Similarity_1, Similarity_2, sparse_weights=True):\n",
    "        super(ItemKNNSimilarityHybridRecommender, self).__init__(urm_train)\n",
    "\n",
    "        if Similarity_1.shape != Similarity_2.shape:\n",
    "            raise ValueError(\"ItemKNNSimilarityHybridRecommender: similarities have different size, S1 is {}, S2 is {}\".format(\n",
    "                Similarity_1.shape, Similarity_2.shape\n",
    "            ))\n",
    "\n",
    "        # CSR is faster during evaluation\n",
    "        self.Similarity_1 = check_matrix(Similarity_1.copy(), 'csr')\n",
    "        self.Similarity_2 = check_matrix(Similarity_2.copy(), 'csr')\n",
    "\n",
    "\n",
    "    def fit(self, topK=100, alpha = 0.5):\n",
    "\n",
    "        self.topK = topK\n",
    "        self.alpha = alpha\n",
    "\n",
    "        W = self.Similarity_1*self.alpha + self.Similarity_2*(1-self.alpha)\n",
    "        self.W_sparse = similarityMatrixTopK(W, k=self.topK).tocsr()\n",
    "       \n",
    "\n",
    "hybridrecommender = ItemKNNSimilarityHybridRecommender(urm_train, itemKNNCF.W_sparse, P3alpha.W_sparse)\n",
    "hybridrecommender.fit(alpha = 0.5)\n",
    "\n",
    "evaluator_validation.evaluateRecommender(hybridrecommender)\n",
    "\n",
    "### In this case the alpha coefficient is too a parameter to be tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureSVDRecommender: URM Detected 143 (1.80 %) cold users.\n",
      "PureSVDRecommender: URM Detected 2076 (8.34 %) cold items.\n",
      "PureSVDRecommender: Computing SVD decomposition...\n",
      "PureSVDRecommender: Computing SVD decomposition... Done!\n",
      "ItemKNNScoresHybridRecommender: URM Detected 143 (1.80 %) cold users.\n",
      "ItemKNNScoresHybridRecommender: URM Detected 2076 (8.34 %) cold items.\n",
      "EvaluatorHoldout: Processed 3654 ( 100.00% ) in 3.83 sec. Users per second: 955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({5: {'ROC_AUC': 0.054118773946360145,\n",
       "   'PRECISION': 0.019321291735084938,\n",
       "   'PRECISION_RECALL_MIN_DEN': 0.0502234993614304,\n",
       "   'RECALL': 0.04795149149475847,\n",
       "   'MAP': 0.028793863650185502,\n",
       "   'MRR': 0.05136380222587122,\n",
       "   'NDCG': 0.037607580177143385,\n",
       "   'F1': 0.02754411849253376,\n",
       "   'HIT_RATE': 0.0966064586754242,\n",
       "   'ARHR': 0.05391351943076084,\n",
       "   'NOVELTY': 0.002240175101101491,\n",
       "   'AVERAGE_POPULARITY': 0.1817397012390264,\n",
       "   'DIVERSITY_MEAN_INTER_LIST': 0.9714196412932454,\n",
       "   'DIVERSITY_HERFINDAHL': 0.9942307580538712,\n",
       "   'COVERAGE_ITEM': 0.09543701799485861,\n",
       "   'COVERAGE_ITEM_CORRECT': 0.007350578406169666,\n",
       "   'COVERAGE_USER': 0.45979614949037373,\n",
       "   'COVERAGE_USER_CORRECT': 0.04077010192525481,\n",
       "   'DIVERSITY_GINI': 0.020004942530714227,\n",
       "   'SHANNON_ENTROPY': 8.754445816575611}},\n",
       " 'CUTOFF: 5 - ROC_AUC: 0.0541188, PRECISION: 0.0193213, PRECISION_RECALL_MIN_DEN: 0.0502235, RECALL: 0.0479515, MAP: 0.0287939, MRR: 0.0513638, NDCG: 0.0376076, F1: 0.0275441, HIT_RATE: 0.0966065, ARHR: 0.0539135, NOVELTY: 0.0022402, AVERAGE_POPULARITY: 0.1817397, DIVERSITY_MEAN_INTER_LIST: 0.9714196, DIVERSITY_HERFINDAHL: 0.9942308, COVERAGE_ITEM: 0.0954370, COVERAGE_ITEM_CORRECT: 0.0073506, COVERAGE_USER: 0.4597961, COVERAGE_USER_CORRECT: 0.0407701, DIVERSITY_GINI: 0.0200049, SHANNON_ENTROPY: 8.7544458, \\n')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MatrixFactorization.PureSVDRecommender import PureSVDRecommender\n",
    "\n",
    "pureSVD = PureSVDRecommender(urm_train)\n",
    "pureSVD.fit()\n",
    "\n",
    "class ItemKNNScoresHybridRecommender(BaseItemSimilarityMatrixRecommender):\n",
    "    \"\"\" ItemKNNScoresHybridRecommender\n",
    "    Hybrid of two prediction scores R = R1*alpha + R2*(1-alpha)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"ItemKNNScoresHybridRecommender\"\n",
    "\n",
    "\n",
    "    def __init__(self, URM_train, Recommender_1, Recommender_2):\n",
    "        super(ItemKNNScoresHybridRecommender, self).__init__(urm_train)\n",
    "\n",
    "        self.URM_train = check_matrix(URM_train.copy(), 'csr')\n",
    "        self.Recommender_1 = Recommender_1\n",
    "        self.Recommender_2 = Recommender_2\n",
    "        \n",
    "        \n",
    "    def fit(self, alpha = 0.5):\n",
    "\n",
    "        self.alpha = alpha      \n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "        \n",
    "        item_weights_1 = self.Recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.Recommender_2._compute_item_score(user_id_array)\n",
    "\n",
    "        item_weights = item_weights_1*self.alpha + item_weights_2*(1-self.alpha)\n",
    "\n",
    "        return item_weights\n",
    "\n",
    "\n",
    "hybridrecommender = ItemKNNScoresHybridRecommender(urm_train, itemKNNCF, pureSVD)\n",
    "hybridrecommender.fit(alpha = 0.5)\n",
    "\n",
    "evaluator_validation.evaluateRecommender(hybridrecommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0, average p.len 0.64, min 0, max 1\n",
      "Group 1, average p.len 1.00, min 1, max 1\n",
      "Group 2, average p.len 1.83, min 1, max 2\n",
      "Group 3, average p.len 2.00, min 2, max 2\n",
      "Group 4, average p.len 2.00, min 2, max 2\n",
      "Group 5, average p.len 2.39, min 2, max 3\n",
      "Group 6, average p.len 3.00, min 3, max 3\n",
      "Group 7, average p.len 3.00, min 3, max 3\n",
      "Group 8, average p.len 3.55, min 3, max 4\n",
      "Group 9, average p.len 4.00, min 4, max 4\n",
      "TopPopRecommender: URM Detected 143 (1.80 %) cold users.\n",
      "TopPopRecommender: URM Detected 2076 (8.34 %) cold items.\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "ItemKNNCBFRecommender: URM Detected 143 (1.80 %) cold users.\n",
      "ItemKNNCBFRecommender: URM Detected 2076 (8.34 %) cold items.\n",
      "SearchBayesianSkopt: Testing config: {'topK': 83, 'shrink': 499, 'similarity': 'cosine', 'normalize': True}\n",
      "Unable to load Cython Compute_Similarity, reverting to Python\n",
      "Similarity column 25975 ( 100 % ), 2541.33 column/sec, elapsed time 0.17 min\n",
      "SearchBayesianSkopt: Config 0 Exception. Config: {'topK': 83, 'shrink': 499, 'similarity': 'cosine', 'normalize': True} - Exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\ParameterTuning\\SearchAbstractClass.py\", line 362, in _objective_function\n",
      "    result_dict, result_string, recommender_instance, train_time, evaluation_time = self._evaluate_on_validation(current_fit_parameters_dict)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\ParameterTuning\\SearchAbstractClass.py\", line 272, in _evaluate_on_validation\n",
      "    result_dict, _ = self.evaluator_validation.evaluateRecommender(recommender_instance)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\Evaluation\\Evaluator.py\", line 245, in evaluateRecommender\n",
      "    results_dict = self._run_evaluation_on_selected_users(recommender_object, self.users_to_evaluate)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\Evaluation\\Evaluator.py\", line 449, in _run_evaluation_on_selected_users\n",
      "    return_scores = True\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\BaseRecommender.py\", line 128, in recommend\n",
      "    scores_batch = self._compute_item_score(user_id_array, items_to_compute=items_to_compute)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\BaseSimilarityMatrixRecommender.py\", line 90, in _compute_item_score\n",
      "    item_scores = user_profile_array.dot(self.W_sparse).toarray()\n",
      "  File \"C:\\Users\\matte\\anaconda3\\envs\\RecSysFramework\\lib\\site-packages\\scipy\\sparse\\base.py\", line 364, in dot\n",
      "    return self * other\n",
      "  File \"C:\\Users\\matte\\anaconda3\\envs\\RecSysFramework\\lib\\site-packages\\scipy\\sparse\\base.py\", line 481, in __mul__\n",
      "    raise ValueError('dimension mismatch')\n",
      "ValueError: dimension mismatch\n",
      "\n",
      "\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 10.4170\n",
      "Function value obtained: 65504.0000\n",
      "Current minimum: 65504.0000\n",
      "Iteration No: 2 started. Searching for the next optimal point.\n",
      "ItemKNNCBFRecommender: URM Detected 143 (1.80 %) cold users.\n",
      "ItemKNNCBFRecommender: URM Detected 2076 (8.34 %) cold items.\n",
      "SearchBayesianSkopt: Testing config: {'topK': 1000, 'shrink': 1000, 'similarity': 'cosine', 'normalize': False}\n",
      "Unable to load Cython Compute_Similarity, reverting to Python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\ParameterTuning\\SearchAbstractClass.py\", line 362, in _objective_function\n",
      "    result_dict, result_string, recommender_instance, train_time, evaluation_time = self._evaluate_on_validation(current_fit_parameters_dict)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\ParameterTuning\\SearchAbstractClass.py\", line 272, in _evaluate_on_validation\n",
      "    result_dict, _ = self.evaluator_validation.evaluateRecommender(recommender_instance)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\Evaluation\\Evaluator.py\", line 245, in evaluateRecommender\n",
      "    results_dict = self._run_evaluation_on_selected_users(recommender_object, self.users_to_evaluate)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\Evaluation\\Evaluator.py\", line 449, in _run_evaluation_on_selected_users\n",
      "    return_scores = True\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\BaseRecommender.py\", line 128, in recommend\n",
      "    scores_batch = self._compute_item_score(user_id_array, items_to_compute=items_to_compute)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\BaseSimilarityMatrixRecommender.py\", line 90, in _compute_item_score\n",
      "    item_scores = user_profile_array.dot(self.W_sparse).toarray()\n",
      "  File \"C:\\Users\\matte\\anaconda3\\envs\\RecSysFramework\\lib\\site-packages\\scipy\\sparse\\base.py\", line 364, in dot\n",
      "    return self * other\n",
      "  File \"C:\\Users\\matte\\anaconda3\\envs\\RecSysFramework\\lib\\site-packages\\scipy\\sparse\\base.py\", line 481, in __mul__\n",
      "    raise ValueError('dimension mismatch')\n",
      "ValueError: dimension mismatch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 25975 ( 100 % ), 2621.95 column/sec, elapsed time 0.17 min\n",
      "SearchBayesianSkopt: Config 1 Exception. Config: {'topK': 1000, 'shrink': 1000, 'similarity': 'cosine', 'normalize': False} - Exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\ParameterTuning\\SearchAbstractClass.py\", line 362, in _objective_function\n",
      "    result_dict, result_string, recommender_instance, train_time, evaluation_time = self._evaluate_on_validation(current_fit_parameters_dict)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\ParameterTuning\\SearchAbstractClass.py\", line 272, in _evaluate_on_validation\n",
      "    result_dict, _ = self.evaluator_validation.evaluateRecommender(recommender_instance)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\Evaluation\\Evaluator.py\", line 245, in evaluateRecommender\n",
      "    results_dict = self._run_evaluation_on_selected_users(recommender_object, self.users_to_evaluate)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\Evaluation\\Evaluator.py\", line 449, in _run_evaluation_on_selected_users\n",
      "    return_scores = True\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\BaseRecommender.py\", line 128, in recommend\n",
      "    scores_batch = self._compute_item_score(user_id_array, items_to_compute=items_to_compute)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\BaseSimilarityMatrixRecommender.py\", line 90, in _compute_item_score\n",
      "    item_scores = user_profile_array.dot(self.W_sparse).toarray()\n",
      "  File \"C:\\Users\\matte\\anaconda3\\envs\\RecSysFramework\\lib\\site-packages\\scipy\\sparse\\base.py\", line 364, in dot\n",
      "    return self * other\n",
      "  File \"C:\\Users\\matte\\anaconda3\\envs\\RecSysFramework\\lib\\site-packages\\scipy\\sparse\\base.py\", line 481, in __mul__\n",
      "    raise ValueError('dimension mismatch')\n",
      "ValueError: dimension mismatch\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\ParameterTuning\\SearchAbstractClass.py\", line 362, in _objective_function\n",
      "    result_dict, result_string, recommender_instance, train_time, evaluation_time = self._evaluate_on_validation(current_fit_parameters_dict)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\ParameterTuning\\SearchAbstractClass.py\", line 272, in _evaluate_on_validation\n",
      "    result_dict, _ = self.evaluator_validation.evaluateRecommender(recommender_instance)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\Evaluation\\Evaluator.py\", line 245, in evaluateRecommender\n",
      "    results_dict = self._run_evaluation_on_selected_users(recommender_object, self.users_to_evaluate)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\Evaluation\\Evaluator.py\", line 449, in _run_evaluation_on_selected_users\n",
      "    return_scores = True\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\BaseRecommender.py\", line 128, in recommend\n",
      "    scores_batch = self._compute_item_score(user_id_array, items_to_compute=items_to_compute)\n",
      "  File \"C:\\Users\\matte\\OneDrive\\Desktop\\recommender\\RecSys_Course_AT_PoliMi\\Base\\BaseSimilarityMatrixRecommender.py\", line 90, in _compute_item_score\n",
      "    item_scores = user_profile_array.dot(self.W_sparse).toarray()\n",
      "  File \"C:\\Users\\matte\\anaconda3\\envs\\RecSysFramework\\lib\\site-packages\\scipy\\sparse\\base.py\", line 364, in dot\n",
      "    return self * other\n",
      "  File \"C:\\Users\\matte\\anaconda3\\envs\\RecSysFramework\\lib\\site-packages\\scipy\\sparse\\base.py\", line 481, in __mul__\n",
      "    raise ValueError('dimension mismatch')\n",
      "ValueError: dimension mismatch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 2 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.1748\n",
      "Function value obtained: 65504.0000\n",
      "Current minimum: 65504.0000\n",
      "SearchBayesianSkopt: Search complete. Best config is None: None\n",
      "\n",
      "ItemKNNCBFRecommender: URM Detected 143 (1.80 %) cold users.\n",
      "ItemKNNCBFRecommender: URM Detected 2076 (8.34 %) cold items.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit() argument after ** must be a mapping, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-dd3e80815f79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[0mitemKNNCBF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mItemKNNCBFRecommender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mURM_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mICM_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m \u001b[0mitemKNNCBF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbest_parameters_ItemKNNCBF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[0murm_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() argument after ** must be a mapping, not NoneType"
     ]
    }
   ],
   "source": [
    "# User-wise hybrid   -- ICM missing\n",
    "\n",
    "### Models do not have the same accuracy for different user types. Let's divide the users according to their profile length and then compare the recommendation quality we get from a CF model\n",
    "\n",
    "\n",
    "\n",
    "URM_train = sps.csr_matrix(urm_train)\n",
    "\n",
    "profile_length = np.ediff1d(urm_train.indptr)\n",
    "\n",
    "### Let's select a few groups of 5% of the users with the least number of interactions\n",
    "\n",
    "block_size = int(len(profile_length)*0.05)\n",
    "block_size\n",
    "\n",
    "sorted_users = np.argsort(profile_length)\n",
    "\n",
    "for group_id in range(0, 10):\n",
    "    \n",
    "    start_pos = group_id*block_size\n",
    "    end_pos = min((group_id+1)*block_size, len(profile_length))\n",
    "    \n",
    "    users_in_group = sorted_users[start_pos:end_pos]\n",
    "    \n",
    "    users_in_group_p_len = profile_length[users_in_group]\n",
    "    \n",
    "    print(\"Group {}, average p.len {:.2f}, min {}, max {}\".format(group_id, \n",
    "        users_in_group_p_len.mean(), users_in_group_p_len.min(), users_in_group_p_len.max()))\n",
    "\n",
    "### Now we plot the recommendation quality of TopPop and ItemKNNCF\n",
    "\n",
    "from Base.NonPersonalizedRecommender import TopPop\n",
    "\n",
    "topPop = TopPop(URM_train)\n",
    "topPop.fit()\n",
    "\n",
    "\n",
    "from KNN.ItemKNNCBFRecommender import ItemKNNCBFRecommender\n",
    "\n",
    "recommender_class = ItemKNNCBFRecommender\n",
    "\n",
    "parameterSearch = SearchBayesianSkopt(recommender_class,\n",
    "                                 evaluator_validation=evaluator_validation,\n",
    "                                 evaluator_test=evaluator_test)\n",
    "\n",
    "\n",
    "hyperparameters_range_dictionary = {}\n",
    "hyperparameters_range_dictionary[\"topK\"] = Integer(5, 1000)\n",
    "hyperparameters_range_dictionary[\"shrink\"] = Integer(0, 1000)\n",
    "hyperparameters_range_dictionary[\"similarity\"] = Categorical([\"cosine\"])\n",
    "hyperparameters_range_dictionary[\"normalize\"] = Categorical([True, False])\n",
    "    \n",
    "    \n",
    "recommender_input_args = SearchInputRecommenderArgs(\n",
    "    CONSTRUCTOR_POSITIONAL_ARGS = [urm_train, ICM_all],\n",
    "    CONSTRUCTOR_KEYWORD_ARGS = {},\n",
    "    FIT_POSITIONAL_ARGS = [],\n",
    "    FIT_KEYWORD_ARGS = {}\n",
    ")\n",
    "\n",
    "\n",
    "output_folder_path = \"result_experiments/\"\n",
    "\n",
    "import os\n",
    "\n",
    "# If directory does not exist, create\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "n_cases = 2\n",
    "metric_to_optimize = \"MAP\"\n",
    "\n",
    "parameterSearch.search(recommender_input_args,\n",
    "                       parameter_search_space = hyperparameters_range_dictionary,\n",
    "                       n_cases = n_cases,\n",
    "                       n_random_starts = 1,\n",
    "                       save_model = \"no\",\n",
    "                       output_folder_path = output_folder_path,\n",
    "                       output_file_name_root = recommender_class.RECOMMENDER_NAME,\n",
    "                       metric_to_optimize = metric_to_optimize\n",
    "                      )\n",
    "\n",
    "data_loader = DataIO(folder_path = output_folder_path)\n",
    "search_metadata = data_loader.load_data(recommender_class.RECOMMENDER_NAME + \"_metadata.zip\")\n",
    "\n",
    "best_parameters_ItemKNNCBF = search_metadata[\"hyperparameters_best\"]\n",
    "best_parameters_ItemKNNCBF\n",
    "\n",
    "itemKNNCBF = ItemKNNCBFRecommender(URM_train, ICM_all)\n",
    "itemKNNCBF.fit(**best_parameters_ItemKNNCBF)\n",
    "\n",
    "urm_train\n",
    "\n",
    "\n",
    "MAP_itemKNNCF_per_group = []\n",
    "MAP_itemKNNCBF_per_group = []\n",
    "MAP_pureSVD_per_group = []\n",
    "MAP_topPop_per_group = []\n",
    "cutoff = 10\n",
    "\n",
    "for group_id in range(0, 10):\n",
    "    \n",
    "    start_pos = group_id*block_size\n",
    "    end_pos = min((group_id+1)*block_size, len(profile_length))\n",
    "    \n",
    "    users_in_group = sorted_users[start_pos:end_pos]\n",
    "    \n",
    "    users_in_group_p_len = profile_length[users_in_group]\n",
    "    \n",
    "    print(\"Group {}, average p.len {:.2f}, min {}, max {}\".format(group_id, \n",
    "        users_in_group_p_len.mean(), users_in_group_p_len.min(), users_in_group_p_len.max()))\n",
    "    \n",
    "    \n",
    "    users_not_in_group_flag = np.isin(sorted_users, users_in_group, invert = True)\n",
    "    users_not_in_group = sorted_users[users_not_in_group_flag]\n",
    "    \n",
    "    evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[cutoff], ignore_users = users_not_in_group)\n",
    "    \n",
    "    \n",
    "    results, _ = evaluator_test.evaluateRecommender(itemKNNCF)\n",
    "    MAP_itemKNNCF_per_group.append(results[cutoff][\"MAP\"])\n",
    " \n",
    "    results, _ = evaluator_test.evaluateRecommender(pureSVD)\n",
    "    MAP_pureSVD_per_group.append(results[cutoff][\"MAP\"])\n",
    "\n",
    "    results, _ = evaluator_test.evaluateRecommender(itemKNNCBF)\n",
    "    MAP_itemKNNCBF_per_group.append(results[cutoff][\"MAP\"])\n",
    "\n",
    "    results, _ = evaluator_test.evaluateRecommender(topPop)\n",
    "    MAP_topPop_per_group.append(results[cutoff][\"MAP\"])\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline  \n",
    "\n",
    "pyplot.plot(MAP_itemKNNCF_per_group, label=\"itemKNNCF\")\n",
    "pyplot.plot(MAP_itemKNNCBF_per_group, label=\"itemKNNCBF\")\n",
    "pyplot.plot(MAP_pureSVD_per_group, label=\"pureSVD\")\n",
    "pyplot.plot(MAP_topPop_per_group, label=\"topPop\")\n",
    "pyplot.ylabel('MAP')\n",
    "pyplot.xlabel('User Group')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "### The recommendation quality of the three algorithms changes depending on the user profile length\n",
    "\n",
    "## Tip:\n",
    "### If an algorithm works best on average, it does not imply it will work best for ALL user types\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemKNNCBF.W_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Vi-dduXaj46"
   },
   "source": [
    "**Submission to competition**\n",
    "\n",
    "This step serves as a similar step that you will perform when preparing a submission to the competition. Specially after you have chosen and trained your recommender.\n",
    "\n",
    "For this step the best suggestion is to select the most-performing configuration obtained in the hyperparameter tuning step and to train the recommender using both the train and validation set. Remember that in the competition you do not have access to the test set.\n",
    "\n",
    "Another consideration is that, due to easier and faster calculations, we replaced the user/item identifiers with new ones in the preprocessing step. For the competition, you are required to generate recommendations using the dataset's original identifiers. Due to this, this step also reverts back the newer identifiers with the ones originally found in the dataset.\n",
    "\n",
    "Last, this step creates a function that writes the recommendations for each user in the same file in a tabular format following this format:\n",
    "\n",
    "csv\n",
    "<user_id>,<item_id_1> <item_id_2> <item_id_3> <item_id_4> <item_id_5> <item_id_6> <item_id_7> <item_id_8> <item_id_9> <item_id_10>\n",
    "Always verify the competitions' submission file model as it might vary from the one we presented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qKzBZQxRap1c"
   },
   "outputs": [],
   "source": [
    "urm_train_validation = urm_train + urm_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xm-SGXoVaude"
   },
   "outputs": [],
   "source": [
    "best_recommender = CFItemKNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete in in 24.12 seconds, loss is 9.863E-01. Samples per second 3756.45\n",
      "Epoch 2 complete in in 23.45 seconds, loss is 9.608E-01. Samples per second 3864.56\n",
      "Epoch 3 complete in in 23.32 seconds, loss is 9.369E-01. Samples per second 3885.43\n",
      "Epoch 4 complete in in 22.71 seconds, loss is 9.159E-01. Samples per second 3989.77\n",
      "Epoch 5 complete in in 23.88 seconds, loss is 8.962E-01. Samples per second 3794.99\n",
      "Epoch 6 complete in in 23.66 seconds, loss is 8.776E-01. Samples per second 3829.90\n",
      "Epoch 7 complete in in 23.95 seconds, loss is 8.614E-01. Samples per second 3783.68\n",
      "Epoch 8 complete in in 23.40 seconds, loss is 8.472E-01. Samples per second 3871.96\n",
      "Epoch 9 complete in in 23.28 seconds, loss is 8.326E-01. Samples per second 3892.54\n",
      "Epoch 10 complete in in 22.69 seconds, loss is 8.187E-01. Samples per second 3993.34\n"
     ]
    }
   ],
   "source": [
    "best_recommender.fit(urm_train_validation,1e-4,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_precision, accum_recall, accum_map, num_user_evaluated, num_users_skipped = evaluator(best_recommender, \n",
    "                                                                                            urm_train_validation, \n",
    "                                                                                            urm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.027385597729690892, 0.09178342490649899, 0.04209122439326914, 5638, 2309)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum_precision, accum_recall, accum_map, num_user_evaluated, num_users_skipped  #trust MAP (indicatively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "EcSDk9aMtW4k"
   },
   "outputs": [],
   "source": [
    "def load_goodguys():\n",
    "  return pd.read_csv(\"./data_target_users_test.csv\")\n",
    "goodguys=load_goodguys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "eHzsuFiqtW4k",
    "outputId": "bc36c459-1cc6-460a-b403-95482cf1508d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7939</th>\n",
       "      <td>7942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>7943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7941</th>\n",
       "      <td>7944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7942</th>\n",
       "      <td>7945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7943</th>\n",
       "      <td>7946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7944 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id\n",
       "0           0\n",
       "1           1\n",
       "2           2\n",
       "3           3\n",
       "4           4\n",
       "...       ...\n",
       "7939     7942\n",
       "7940     7943\n",
       "7941     7944\n",
       "7942     7945\n",
       "7943     7946\n",
       "\n",
       "[7944 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodguys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "0b3DwuXrayTA",
    "outputId": "27c6d557-b304-427c-bf2c-8fdc090efe64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3867, 6701, 2385, ..., 6327, 4324, 4004], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_to_recommend = np.random.choice(goodguys.user_id,size=goodguys.size, replace=False)\n",
    "users_to_recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "gzOneO7sa1N9"
   },
   "outputs": [],
   "source": [
    "mapping_to_item_id = dict(zip(ratings.mapped_item_id, ratings.item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "aUd6VsfPa4I7",
    "outputId": "7438e193-183d-40f2-c196-628d900aadce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 10080,\n",
       " 1: 19467,\n",
       " 2: 2665,\n",
       " 3: 7494,\n",
       " 4: 17068,\n",
       " 5: 17723,\n",
       " 6: 18131,\n",
       " 7: 20146,\n",
       " 8: 19337,\n",
       " 9: 21181,\n",
       " 10: 18736,\n",
       " 11: 23037,\n",
       " 12: 477,\n",
       " 13: 6927,\n",
       " 14: 10204,\n",
       " 15: 13707,\n",
       " 16: 18999,\n",
       " 17: 19838,\n",
       " 18: 19851,\n",
       " 19: 814,\n",
       " 20: 2754,\n",
       " 21: 3907,\n",
       " 22: 4481,\n",
       " 23: 5581,\n",
       " 24: 6549,\n",
       " 25: 7583,\n",
       " 26: 8849,\n",
       " 27: 9014,\n",
       " 28: 9658,\n",
       " 29: 12914,\n",
       " 30: 13439,\n",
       " 31: 16587,\n",
       " 32: 20127,\n",
       " 33: 20345,\n",
       " 34: 21663,\n",
       " 35: 23895,\n",
       " 36: 24008,\n",
       " 37: 24577,\n",
       " 38: 4649,\n",
       " 39: 11189,\n",
       " 40: 13703,\n",
       " 41: 22592,\n",
       " 42: 1957,\n",
       " 43: 3606,\n",
       " 44: 4102,\n",
       " 45: 6770,\n",
       " 46: 7059,\n",
       " 47: 10716,\n",
       " 48: 12304,\n",
       " 49: 14405,\n",
       " 50: 14846,\n",
       " 51: 16685,\n",
       " 52: 21319,\n",
       " 53: 21950,\n",
       " 54: 22181,\n",
       " 55: 24783,\n",
       " 56: 9427,\n",
       " 57: 10908,\n",
       " 58: 19750,\n",
       " 59: 1199,\n",
       " 60: 7589,\n",
       " 61: 8059,\n",
       " 62: 21260,\n",
       " 63: 21267,\n",
       " 64: 24865,\n",
       " 65: 1920,\n",
       " 66: 6380,\n",
       " 67: 12816,\n",
       " 68: 14100,\n",
       " 69: 17509,\n",
       " 70: 21184,\n",
       " 71: 2154,\n",
       " 72: 3025,\n",
       " 73: 3041,\n",
       " 74: 4532,\n",
       " 75: 5200,\n",
       " 76: 5208,\n",
       " 77: 5998,\n",
       " 78: 6141,\n",
       " 79: 6817,\n",
       " 80: 7409,\n",
       " 81: 7753,\n",
       " 82: 8589,\n",
       " 83: 9163,\n",
       " 84: 11152,\n",
       " 85: 11405,\n",
       " 86: 13274,\n",
       " 87: 14105,\n",
       " 88: 14880,\n",
       " 89: 14961,\n",
       " 90: 17791,\n",
       " 91: 18969,\n",
       " 92: 19427,\n",
       " 93: 19505,\n",
       " 94: 19868,\n",
       " 95: 19998,\n",
       " 96: 21807,\n",
       " 97: 21830,\n",
       " 98: 22418,\n",
       " 99: 23383,\n",
       " 100: 23959,\n",
       " 101: 24647,\n",
       " 102: 25191,\n",
       " 103: 25716,\n",
       " 104: 10428,\n",
       " 105: 11339,\n",
       " 106: 19708,\n",
       " 107: 1242,\n",
       " 108: 3812,\n",
       " 109: 9155,\n",
       " 110: 11169,\n",
       " 111: 22286,\n",
       " 112: 3177,\n",
       " 113: 4805,\n",
       " 114: 7028,\n",
       " 115: 8687,\n",
       " 116: 14035,\n",
       " 117: 14104,\n",
       " 118: 14300,\n",
       " 119: 14506,\n",
       " 120: 16011,\n",
       " 121: 19007,\n",
       " 122: 20191,\n",
       " 123: 20276,\n",
       " 124: 24199,\n",
       " 125: 24415,\n",
       " 126: 12402,\n",
       " 127: 13410,\n",
       " 128: 63,\n",
       " 129: 121,\n",
       " 130: 1769,\n",
       " 131: 1905,\n",
       " 132: 2667,\n",
       " 133: 3165,\n",
       " 134: 3644,\n",
       " 135: 4792,\n",
       " 136: 4821,\n",
       " 137: 5025,\n",
       " 138: 7768,\n",
       " 139: 7779,\n",
       " 140: 8207,\n",
       " 141: 8638,\n",
       " 142: 9996,\n",
       " 143: 10011,\n",
       " 144: 10269,\n",
       " 145: 10919,\n",
       " 146: 13294,\n",
       " 147: 15002,\n",
       " 148: 15034,\n",
       " 149: 16098,\n",
       " 150: 16135,\n",
       " 151: 16278,\n",
       " 152: 16301,\n",
       " 153: 17740,\n",
       " 154: 17994,\n",
       " 155: 18479,\n",
       " 156: 18481,\n",
       " 157: 18775,\n",
       " 158: 19655,\n",
       " 159: 20626,\n",
       " 160: 20883,\n",
       " 161: 20919,\n",
       " 162: 20982,\n",
       " 163: 21954,\n",
       " 164: 22517,\n",
       " 165: 23647,\n",
       " 166: 23849,\n",
       " 167: 24075,\n",
       " 168: 24287,\n",
       " 169: 24725,\n",
       " 170: 25310,\n",
       " 171: 25312,\n",
       " 172: 25800,\n",
       " 173: 497,\n",
       " 174: 1287,\n",
       " 175: 3037,\n",
       " 176: 4495,\n",
       " 177: 7611,\n",
       " 178: 8709,\n",
       " 179: 9716,\n",
       " 180: 11078,\n",
       " 181: 15559,\n",
       " 182: 17333,\n",
       " 183: 22240,\n",
       " 184: 22835,\n",
       " 185: 23141,\n",
       " 186: 25407,\n",
       " 187: 1929,\n",
       " 188: 6208,\n",
       " 189: 7733,\n",
       " 190: 13444,\n",
       " 191: 15579,\n",
       " 192: 16885,\n",
       " 193: 20375,\n",
       " 194: 2489,\n",
       " 195: 3325,\n",
       " 196: 5610,\n",
       " 197: 7613,\n",
       " 198: 7942,\n",
       " 199: 13597,\n",
       " 200: 14225,\n",
       " 201: 14875,\n",
       " 202: 15329,\n",
       " 203: 18234,\n",
       " 204: 22861,\n",
       " 205: 23072,\n",
       " 206: 23204,\n",
       " 207: 24967,\n",
       " 208: 1196,\n",
       " 209: 6928,\n",
       " 210: 7370,\n",
       " 211: 8532,\n",
       " 212: 10513,\n",
       " 213: 10700,\n",
       " 214: 12525,\n",
       " 215: 12740,\n",
       " 216: 13662,\n",
       " 217: 14060,\n",
       " 218: 15905,\n",
       " 219: 18611,\n",
       " 220: 19126,\n",
       " 221: 20591,\n",
       " 222: 21282,\n",
       " 223: 21707,\n",
       " 224: 21802,\n",
       " 225: 22342,\n",
       " 226: 24675,\n",
       " 227: 5568,\n",
       " 228: 7002,\n",
       " 229: 9443,\n",
       " 230: 11122,\n",
       " 231: 16150,\n",
       " 232: 16225,\n",
       " 233: 21608,\n",
       " 234: 23251,\n",
       " 235: 17760,\n",
       " 236: 22668,\n",
       " 237: 24784,\n",
       " 238: 1457,\n",
       " 239: 3548,\n",
       " 240: 4126,\n",
       " 241: 5966,\n",
       " 242: 9620,\n",
       " 243: 25255,\n",
       " 244: 8599,\n",
       " 245: 9243,\n",
       " 246: 11001,\n",
       " 247: 21365,\n",
       " 248: 24374,\n",
       " 249: 2408,\n",
       " 250: 4517,\n",
       " 251: 6239,\n",
       " 252: 8145,\n",
       " 253: 11220,\n",
       " 254: 13845,\n",
       " 255: 15234,\n",
       " 256: 24109,\n",
       " 257: 5989,\n",
       " 258: 7687,\n",
       " 259: 10185,\n",
       " 260: 16362,\n",
       " 261: 17629,\n",
       " 262: 22730,\n",
       " 263: 23634,\n",
       " 264: 359,\n",
       " 265: 4353,\n",
       " 266: 7142,\n",
       " 267: 11075,\n",
       " 268: 11085,\n",
       " 269: 13574,\n",
       " 270: 19754,\n",
       " 271: 20308,\n",
       " 272: 21893,\n",
       " 273: 22925,\n",
       " 274: 2383,\n",
       " 275: 9162,\n",
       " 276: 10530,\n",
       " 277: 11452,\n",
       " 278: 17168,\n",
       " 279: 20148,\n",
       " 280: 20560,\n",
       " 281: 20692,\n",
       " 282: 484,\n",
       " 283: 13077,\n",
       " 284: 20688,\n",
       " 285: 3630,\n",
       " 286: 12844,\n",
       " 287: 51,\n",
       " 288: 5783,\n",
       " 289: 23046,\n",
       " 290: 7839,\n",
       " 291: 8539,\n",
       " 292: 9752,\n",
       " 293: 4674,\n",
       " 294: 6619,\n",
       " 295: 7115,\n",
       " 296: 1011,\n",
       " 297: 1770,\n",
       " 298: 3700,\n",
       " 299: 6266,\n",
       " 300: 7991,\n",
       " 301: 9555,\n",
       " 302: 9992,\n",
       " 303: 10594,\n",
       " 304: 10834,\n",
       " 305: 13891,\n",
       " 306: 16577,\n",
       " 307: 23154,\n",
       " 308: 25631,\n",
       " 309: 1987,\n",
       " 310: 4361,\n",
       " 311: 4947,\n",
       " 312: 5327,\n",
       " 313: 8822,\n",
       " 314: 9410,\n",
       " 315: 12438,\n",
       " 316: 14978,\n",
       " 317: 15315,\n",
       " 318: 15507,\n",
       " 319: 17990,\n",
       " 320: 23779,\n",
       " 321: 1113,\n",
       " 322: 6639,\n",
       " 323: 9591,\n",
       " 324: 18344,\n",
       " 325: 20582,\n",
       " 326: 22645,\n",
       " 327: 16361,\n",
       " 328: 18330,\n",
       " 329: 1240,\n",
       " 330: 5803,\n",
       " 331: 6215,\n",
       " 332: 12602,\n",
       " 333: 21161,\n",
       " 334: 23382,\n",
       " 335: 25675,\n",
       " 336: 1124,\n",
       " 337: 1467,\n",
       " 338: 4209,\n",
       " 339: 6752,\n",
       " 340: 7238,\n",
       " 341: 7646,\n",
       " 342: 14106,\n",
       " 343: 17527,\n",
       " 344: 17958,\n",
       " 345: 23757,\n",
       " 346: 6691,\n",
       " 347: 7150,\n",
       " 348: 7392,\n",
       " 349: 10129,\n",
       " 350: 14158,\n",
       " 351: 18341,\n",
       " 352: 18984,\n",
       " 353: 19780,\n",
       " 354: 22801,\n",
       " 355: 25013,\n",
       " 356: 387,\n",
       " 357: 430,\n",
       " 358: 434,\n",
       " 359: 1359,\n",
       " 360: 1422,\n",
       " 361: 1706,\n",
       " 362: 1820,\n",
       " 363: 2481,\n",
       " 364: 2641,\n",
       " 365: 3218,\n",
       " 366: 3323,\n",
       " 367: 3610,\n",
       " 368: 3776,\n",
       " 369: 3804,\n",
       " 370: 4322,\n",
       " 371: 4401,\n",
       " 372: 4520,\n",
       " 373: 4743,\n",
       " 374: 5276,\n",
       " 375: 5569,\n",
       " 376: 5993,\n",
       " 377: 6012,\n",
       " 378: 6330,\n",
       " 379: 6888,\n",
       " 380: 6950,\n",
       " 381: 7143,\n",
       " 382: 7351,\n",
       " 383: 7802,\n",
       " 384: 8733,\n",
       " 385: 9273,\n",
       " 386: 9368,\n",
       " 387: 10148,\n",
       " 388: 10751,\n",
       " 389: 12439,\n",
       " 390: 12469,\n",
       " 391: 12806,\n",
       " 392: 12809,\n",
       " 393: 13007,\n",
       " 394: 13566,\n",
       " 395: 13898,\n",
       " 396: 14022,\n",
       " 397: 14278,\n",
       " 398: 15026,\n",
       " 399: 15351,\n",
       " 400: 15447,\n",
       " 401: 15582,\n",
       " 402: 15787,\n",
       " 403: 15938,\n",
       " 404: 17082,\n",
       " 405: 18387,\n",
       " 406: 19117,\n",
       " 407: 19597,\n",
       " 408: 19609,\n",
       " 409: 20477,\n",
       " 410: 20525,\n",
       " 411: 21670,\n",
       " 412: 21984,\n",
       " 413: 22365,\n",
       " 414: 23110,\n",
       " 415: 23367,\n",
       " 416: 23584,\n",
       " 417: 23813,\n",
       " 418: 24019,\n",
       " 419: 25056,\n",
       " 420: 25928,\n",
       " 421: 1632,\n",
       " 422: 7663,\n",
       " 423: 23975,\n",
       " 424: 11900,\n",
       " 425: 18653,\n",
       " 426: 21381,\n",
       " 427: 23577,\n",
       " 428: 109,\n",
       " 429: 750,\n",
       " 430: 811,\n",
       " 431: 867,\n",
       " 432: 1106,\n",
       " 433: 1378,\n",
       " 434: 1446,\n",
       " 435: 1776,\n",
       " 436: 2006,\n",
       " 437: 2196,\n",
       " 438: 2333,\n",
       " 439: 2360,\n",
       " 440: 2682,\n",
       " 441: 2857,\n",
       " 442: 2865,\n",
       " 443: 2868,\n",
       " 444: 2968,\n",
       " 445: 2986,\n",
       " 446: 3078,\n",
       " 447: 3856,\n",
       " 448: 4055,\n",
       " 449: 5279,\n",
       " 450: 5717,\n",
       " 451: 5746,\n",
       " 452: 6537,\n",
       " 453: 7235,\n",
       " 454: 7396,\n",
       " 455: 8832,\n",
       " 456: 8935,\n",
       " 457: 9412,\n",
       " 458: 9578,\n",
       " 459: 10142,\n",
       " 460: 10273,\n",
       " 461: 11109,\n",
       " 462: 11476,\n",
       " 463: 11744,\n",
       " 464: 11796,\n",
       " 465: 13190,\n",
       " 466: 13613,\n",
       " 467: 13753,\n",
       " 468: 14478,\n",
       " 469: 14770,\n",
       " 470: 15046,\n",
       " 471: 15060,\n",
       " 472: 15327,\n",
       " 473: 15463,\n",
       " 474: 15518,\n",
       " 475: 15731,\n",
       " 476: 15840,\n",
       " 477: 15894,\n",
       " 478: 16034,\n",
       " 479: 16145,\n",
       " 480: 16375,\n",
       " 481: 17712,\n",
       " 482: 18229,\n",
       " 483: 18239,\n",
       " 484: 18380,\n",
       " 485: 18528,\n",
       " 486: 18670,\n",
       " 487: 18692,\n",
       " 488: 18965,\n",
       " 489: 19201,\n",
       " 490: 19833,\n",
       " 491: 19898,\n",
       " 492: 20027,\n",
       " 493: 20039,\n",
       " 494: 20138,\n",
       " 495: 20856,\n",
       " 496: 20916,\n",
       " 497: 20933,\n",
       " 498: 21044,\n",
       " 499: 21291,\n",
       " 500: 21340,\n",
       " 501: 21752,\n",
       " 502: 21762,\n",
       " 503: 21854,\n",
       " 504: 22297,\n",
       " 505: 23599,\n",
       " 506: 23671,\n",
       " 507: 24050,\n",
       " 508: 24224,\n",
       " 509: 24834,\n",
       " 510: 25262,\n",
       " 511: 25804,\n",
       " 512: 96,\n",
       " 513: 304,\n",
       " 514: 8475,\n",
       " 515: 10449,\n",
       " 516: 14442,\n",
       " 517: 22313,\n",
       " 518: 22951,\n",
       " 519: 341,\n",
       " 520: 913,\n",
       " 521: 1517,\n",
       " 522: 1745,\n",
       " 523: 2422,\n",
       " 524: 2486,\n",
       " 525: 2861,\n",
       " 526: 3589,\n",
       " 527: 3716,\n",
       " 528: 4113,\n",
       " 529: 4502,\n",
       " 530: 6278,\n",
       " 531: 7323,\n",
       " 532: 7883,\n",
       " 533: 8712,\n",
       " 534: 11201,\n",
       " 535: 11903,\n",
       " 536: 12597,\n",
       " 537: 13469,\n",
       " 538: 13777,\n",
       " 539: 14188,\n",
       " 540: 21085,\n",
       " 541: 22338,\n",
       " 542: 23067,\n",
       " 543: 23534,\n",
       " 544: 24033,\n",
       " 545: 24348,\n",
       " 546: 25811,\n",
       " 547: 8576,\n",
       " 548: 14432,\n",
       " 549: 16447,\n",
       " 550: 17654,\n",
       " 551: 15691,\n",
       " 552: 16928,\n",
       " 553: 24421,\n",
       " 554: 334,\n",
       " 555: 524,\n",
       " 556: 2736,\n",
       " 557: 5307,\n",
       " 558: 7499,\n",
       " 559: 8114,\n",
       " 560: 9375,\n",
       " 561: 9438,\n",
       " 562: 14433,\n",
       " 563: 15437,\n",
       " 564: 17163,\n",
       " 565: 19332,\n",
       " 566: 23471,\n",
       " 567: 24295,\n",
       " 568: 53,\n",
       " 569: 6612,\n",
       " 570: 17174,\n",
       " 571: 21855,\n",
       " 572: 22332,\n",
       " 573: 24733,\n",
       " 574: 7215,\n",
       " 575: 11848,\n",
       " 576: 13757,\n",
       " 577: 16490,\n",
       " 578: 19065,\n",
       " 579: 20882,\n",
       " 580: 22039,\n",
       " 581: 25151,\n",
       " 582: 4512,\n",
       " 583: 10421,\n",
       " 584: 120,\n",
       " 585: 5664,\n",
       " 586: 152,\n",
       " 587: 6674,\n",
       " 588: 17064,\n",
       " 589: 22300,\n",
       " 590: 84,\n",
       " 591: 1065,\n",
       " 592: 1514,\n",
       " 593: 3999,\n",
       " 594: 4111,\n",
       " 595: 8336,\n",
       " 596: 8425,\n",
       " 597: 8631,\n",
       " 598: 16336,\n",
       " 599: 17716,\n",
       " 600: 19696,\n",
       " 601: 20257,\n",
       " 602: 20794,\n",
       " 603: 21995,\n",
       " 604: 22155,\n",
       " 605: 23439,\n",
       " 606: 23517,\n",
       " 607: 11354,\n",
       " 608: 21042,\n",
       " 609: 3719,\n",
       " 610: 11960,\n",
       " 611: 12237,\n",
       " 612: 644,\n",
       " 613: 8077,\n",
       " 614: 9135,\n",
       " 615: 13450,\n",
       " 616: 18986,\n",
       " 617: 21784,\n",
       " 618: 1710,\n",
       " 619: 6018,\n",
       " 620: 9352,\n",
       " 621: 16519,\n",
       " 622: 20161,\n",
       " 623: 25330,\n",
       " 624: 25550,\n",
       " 625: 522,\n",
       " 626: 1423,\n",
       " 627: 3962,\n",
       " 628: 4257,\n",
       " 629: 4366,\n",
       " 630: 6227,\n",
       " 631: 7006,\n",
       " 632: 7069,\n",
       " 633: 8791,\n",
       " 634: 8951,\n",
       " 635: 11003,\n",
       " 636: 11450,\n",
       " 637: 12162,\n",
       " 638: 12165,\n",
       " 639: 12198,\n",
       " 640: 14485,\n",
       " 641: 15147,\n",
       " 642: 15844,\n",
       " 643: 17719,\n",
       " 644: 17819,\n",
       " 645: 19823,\n",
       " 646: 20501,\n",
       " 647: 21053,\n",
       " 648: 21074,\n",
       " 649: 21373,\n",
       " 650: 22108,\n",
       " 651: 23086,\n",
       " 652: 23311,\n",
       " 653: 23763,\n",
       " 654: 25834,\n",
       " 655: 1885,\n",
       " 656: 7391,\n",
       " 657: 8357,\n",
       " 658: 13024,\n",
       " 659: 13055,\n",
       " 660: 21216,\n",
       " 661: 21353,\n",
       " 662: 23433,\n",
       " 663: 2364,\n",
       " 664: 3457,\n",
       " 665: 6069,\n",
       " 666: 8948,\n",
       " 667: 9285,\n",
       " 668: 14451,\n",
       " 669: 23401,\n",
       " 670: 23803,\n",
       " 671: 3024,\n",
       " 672: 11557,\n",
       " 673: 15262,\n",
       " 674: 21433,\n",
       " 675: 21769,\n",
       " 676: 180,\n",
       " 677: 1459,\n",
       " 678: 6478,\n",
       " 679: 6717,\n",
       " 680: 10186,\n",
       " 681: 16005,\n",
       " 682: 17933,\n",
       " 683: 23481,\n",
       " 684: 14564,\n",
       " 685: 20209,\n",
       " 686: 919,\n",
       " 687: 1714,\n",
       " 688: 2302,\n",
       " 689: 5693,\n",
       " 690: 5873,\n",
       " 691: 6599,\n",
       " 692: 6784,\n",
       " 693: 8920,\n",
       " 694: 9900,\n",
       " 695: 10450,\n",
       " 696: 11236,\n",
       " 697: 12158,\n",
       " 698: 12341,\n",
       " 699: 12835,\n",
       " 700: 13541,\n",
       " 701: 15459,\n",
       " 702: 16103,\n",
       " 703: 16236,\n",
       " 704: 17724,\n",
       " 705: 18872,\n",
       " 706: 19312,\n",
       " 707: 19819,\n",
       " 708: 22144,\n",
       " 709: 22646,\n",
       " 710: 22653,\n",
       " 711: 23536,\n",
       " 712: 23836,\n",
       " 713: 12363,\n",
       " 714: 13706,\n",
       " 715: 6446,\n",
       " 716: 6557,\n",
       " 717: 1449,\n",
       " 718: 5261,\n",
       " 719: 16131,\n",
       " 720: 2041,\n",
       " 721: 4966,\n",
       " 722: 5052,\n",
       " 723: 5965,\n",
       " 724: 6265,\n",
       " 725: 9629,\n",
       " 726: 12801,\n",
       " 727: 12890,\n",
       " 728: 14385,\n",
       " 729: 17705,\n",
       " 730: 17975,\n",
       " 731: 19346,\n",
       " 732: 21799,\n",
       " 733: 22262,\n",
       " 734: 22511,\n",
       " 735: 24712,\n",
       " 736: 25491,\n",
       " 737: 551,\n",
       " 738: 4093,\n",
       " 739: 4314,\n",
       " 740: 5094,\n",
       " 741: 6699,\n",
       " 742: 6990,\n",
       " 743: 11546,\n",
       " 744: 12035,\n",
       " 745: 14626,\n",
       " 746: 16659,\n",
       " 747: 17480,\n",
       " 748: 19303,\n",
       " 749: 21516,\n",
       " 750: 24092,\n",
       " 751: 24230,\n",
       " 752: 24978,\n",
       " 753: 25573,\n",
       " 754: 25832,\n",
       " 755: 235,\n",
       " 756: 1047,\n",
       " 757: 1454,\n",
       " 758: 3285,\n",
       " 759: 3966,\n",
       " 760: 6964,\n",
       " 761: 7545,\n",
       " 762: 7560,\n",
       " 763: 7818,\n",
       " 764: 8644,\n",
       " 765: 9874,\n",
       " 766: 10159,\n",
       " 767: 11996,\n",
       " 768: 13631,\n",
       " 769: 13824,\n",
       " 770: 14024,\n",
       " 771: 15942,\n",
       " 772: 16287,\n",
       " 773: 16480,\n",
       " 774: 16742,\n",
       " 775: 16971,\n",
       " 776: 17134,\n",
       " 777: 19390,\n",
       " 778: 19744,\n",
       " 779: 21293,\n",
       " 780: 22402,\n",
       " 781: 24438,\n",
       " 782: 24848,\n",
       " 783: 25595,\n",
       " 784: 476,\n",
       " 785: 525,\n",
       " 786: 3169,\n",
       " 787: 4205,\n",
       " 788: 5294,\n",
       " 789: 7601,\n",
       " 790: 8158,\n",
       " 791: 9445,\n",
       " 792: 10887,\n",
       " 793: 10979,\n",
       " 794: 11076,\n",
       " 795: 13427,\n",
       " 796: 16179,\n",
       " 797: 17522,\n",
       " 798: 18098,\n",
       " 799: 18126,\n",
       " 800: 20109,\n",
       " 801: 22657,\n",
       " 802: 23909,\n",
       " 803: 24788,\n",
       " 804: 4056,\n",
       " 805: 7710,\n",
       " 806: 9370,\n",
       " 807: 11182,\n",
       " 808: 12214,\n",
       " 809: 14554,\n",
       " 810: 16394,\n",
       " 811: 17456,\n",
       " 812: 18392,\n",
       " 813: 19551,\n",
       " 814: 20410,\n",
       " 815: 21812,\n",
       " 816: 23216,\n",
       " 817: 25433,\n",
       " 818: 388,\n",
       " 819: 660,\n",
       " 820: 696,\n",
       " 821: 935,\n",
       " 822: 2244,\n",
       " 823: 2977,\n",
       " 824: 2998,\n",
       " 825: 3109,\n",
       " 826: 3418,\n",
       " 827: 4355,\n",
       " 828: 4764,\n",
       " 829: 4873,\n",
       " 830: 4986,\n",
       " 831: 4995,\n",
       " 832: 5155,\n",
       " 833: 5181,\n",
       " 834: 5990,\n",
       " 835: 6013,\n",
       " 836: 6534,\n",
       " 837: 7094,\n",
       " 838: 7543,\n",
       " 839: 7984,\n",
       " 840: 8447,\n",
       " 841: 8870,\n",
       " 842: 9367,\n",
       " 843: 9482,\n",
       " 844: 10475,\n",
       " 845: 10630,\n",
       " 846: 10710,\n",
       " 847: 11674,\n",
       " 848: 11822,\n",
       " 849: 11899,\n",
       " 850: 11979,\n",
       " 851: 13154,\n",
       " 852: 13441,\n",
       " 853: 14248,\n",
       " 854: 14333,\n",
       " 855: 14735,\n",
       " 856: 14970,\n",
       " 857: 15154,\n",
       " 858: 15371,\n",
       " 859: 15959,\n",
       " 860: 16259,\n",
       " 861: 16798,\n",
       " 862: 16864,\n",
       " 863: 17825,\n",
       " 864: 18698,\n",
       " 865: 19255,\n",
       " 866: 21827,\n",
       " 867: 23186,\n",
       " 868: 23741,\n",
       " 869: 23868,\n",
       " 870: 24355,\n",
       " 871: 24548,\n",
       " 872: 24593,\n",
       " 873: 25966,\n",
       " 874: 10638,\n",
       " 875: 20341,\n",
       " 876: 13552,\n",
       " 877: 23563,\n",
       " 878: 10613,\n",
       " 879: 14584,\n",
       " 880: 1075,\n",
       " 881: 1458,\n",
       " 882: 1757,\n",
       " 883: 2247,\n",
       " 884: 2468,\n",
       " 885: 3338,\n",
       " 886: 3659,\n",
       " 887: 4587,\n",
       " 888: 4850,\n",
       " 889: 5137,\n",
       " 890: 6064,\n",
       " 891: 8560,\n",
       " 892: 9284,\n",
       " 893: 10099,\n",
       " 894: 10665,\n",
       " 895: 11567,\n",
       " 896: 12560,\n",
       " 897: 13220,\n",
       " 898: 13610,\n",
       " 899: 13855,\n",
       " 900: 14139,\n",
       " 901: 15886,\n",
       " 902: 16420,\n",
       " 903: 16623,\n",
       " 904: 16837,\n",
       " 905: 17100,\n",
       " 906: 17471,\n",
       " 907: 17496,\n",
       " 908: 17966,\n",
       " 909: 18785,\n",
       " 910: 18811,\n",
       " 911: 18947,\n",
       " 912: 19206,\n",
       " 913: 21689,\n",
       " 914: 21793,\n",
       " 915: 21981,\n",
       " 916: 22465,\n",
       " 917: 22821,\n",
       " 918: 23257,\n",
       " 919: 23609,\n",
       " 920: 24916,\n",
       " 921: 25163,\n",
       " 922: 342,\n",
       " 923: 771,\n",
       " 924: 1224,\n",
       " 925: 3924,\n",
       " 926: 3942,\n",
       " 927: 4472,\n",
       " 928: 6065,\n",
       " 929: 13836,\n",
       " 930: 13873,\n",
       " 931: 15583,\n",
       " 932: 16711,\n",
       " 933: 16828,\n",
       " 934: 17030,\n",
       " 935: 18082,\n",
       " 936: 19404,\n",
       " 937: 19405,\n",
       " 938: 20378,\n",
       " 939: 23071,\n",
       " 940: 23177,\n",
       " 941: 25354,\n",
       " 942: 2742,\n",
       " 943: 5149,\n",
       " 944: 12818,\n",
       " 945: 25138,\n",
       " 946: 3511,\n",
       " 947: 4399,\n",
       " 948: 8544,\n",
       " 949: 9353,\n",
       " 950: 11198,\n",
       " 951: 11792,\n",
       " 952: 12056,\n",
       " 953: 12365,\n",
       " 954: 13432,\n",
       " 955: 14023,\n",
       " 956: 15875,\n",
       " 957: 18176,\n",
       " 958: 20108,\n",
       " 959: 20391,\n",
       " 960: 2118,\n",
       " 961: 25080,\n",
       " 962: 4390,\n",
       " 963: 18533,\n",
       " 964: 194,\n",
       " 965: 2204,\n",
       " 966: 3572,\n",
       " 967: 5760,\n",
       " 968: 7292,\n",
       " 969: 7363,\n",
       " 970: 8903,\n",
       " 971: 9090,\n",
       " 972: 9819,\n",
       " 973: 9854,\n",
       " 974: 10075,\n",
       " 975: 10162,\n",
       " 976: 10426,\n",
       " 977: 10653,\n",
       " 978: 11121,\n",
       " 979: 12601,\n",
       " 980: 13226,\n",
       " 981: 13257,\n",
       " 982: 13962,\n",
       " 983: 15196,\n",
       " 984: 17013,\n",
       " 985: 18095,\n",
       " 986: 18453,\n",
       " 987: 20890,\n",
       " 988: 22226,\n",
       " 989: 22763,\n",
       " 990: 22918,\n",
       " 991: 23399,\n",
       " 992: 308,\n",
       " 993: 1081,\n",
       " 994: 1775,\n",
       " 995: 2654,\n",
       " 996: 2911,\n",
       " 997: 3008,\n",
       " 998: 3609,\n",
       " 999: 5743,\n",
       " ...}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_to_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "RurxNTttbI-i"
   },
   "outputs": [],
   "source": [
    "def prepare_submission(ratings: pd.DataFrame, users_to_recommend: np.array, urm_train: sp.csr_matrix, recommender: object):\n",
    "    users_ids_and_mappings = ratings[ratings.user_id.isin(users_to_recommend)][[\"user_id\", \"mapped_user_id\"]].drop_duplicates()\n",
    "    items_ids_and_mappings = ratings[[\"item_id\", \"mapped_item_id\"]].drop_duplicates()\n",
    "    \n",
    "    mapping_to_item_id = dict(zip(ratings.mapped_item_id, ratings.item_id))\n",
    "    \n",
    "    \n",
    "    recommendation_length = 10\n",
    "    submission = []\n",
    "    for idx, row in users_ids_and_mappings.iterrows():\n",
    "        user_id = row.user_id\n",
    "        mapped_user_id = row.mapped_user_id\n",
    "        \n",
    "        recommendations = recommender.recommend(user_id=mapped_user_id,\n",
    "                                                at=recommendation_length,\n",
    "                                                urm_train = urm_train,\n",
    "                                                remove_seen=True)\n",
    "        \n",
    "        submission.append((user_id, [mapping_to_item_id[item_id] for item_id in recommendations]))\n",
    "        \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "5KYlvMDVbLxo"
   },
   "outputs": [],
   "source": [
    "submission = prepare_submission(ratings, users_to_recommend, urm_train_validation, best_recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "sJZEjE3CbQTp",
    "outputId": "8e2faf6b-144c-4ba3-ee1a-692290e15d3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [5085, 1447, 23700, 1560, 10444, 25878, 21866, 637, 8887, 13144]),\n",
       " (4342, [12061, 5717, 8544, 23127, 13363, 19114, 25071, 24908, 25491, 4620]),\n",
       " (5526, [24075, 12061, 9851, 20496, 5717, 4927, 10786, 25693, 773, 9007]),\n",
       " (5923, [5717, 19114, 25693, 23127, 24075, 9007, 9851, 25491, 3668, 10428]),\n",
       " (149, [12061, 10269, 10786, 21552, 5717, 25675, 9438, 9007, 12056, 25693]),\n",
       " (4072, [24075, 12061, 10786, 19114, 4927, 9851, 4811, 23127, 19255, 22359]),\n",
       " (6193, [18190, 8544, 13541, 23127, 23536, 11792, 9284, 15145, 12061, 2300]),\n",
       " (7105, [3804, 24075, 25491, 19114, 23127, 23457, 3668, 13837, 3469, 9556]),\n",
       " (1, [19089, 23600, 19709, 16630, 12409, 19480, 24075, 22121, 8431, 17257]),\n",
       " (150, [17723, 20146, 19089, 7494, 19709, 16630, 23189, 8431, 20982, 23600]),\n",
       " (183, [19709, 7494, 23481, 23600, 12409, 20146, 24075, 22121, 14895, 11658]),\n",
       " (249, [19089, 7494, 11658, 18984, 2533, 8431, 8894, 16630, 20146, 22121]),\n",
       " (296, [19089, 25407, 7494, 8894, 16630, 11295, 8097, 23600, 15691, 19709]),\n",
       " (436, [22632, 7466, 6010, 4945, 9555, 25001, 16773, 6890, 24577, 3557]),\n",
       " (487, [8894, 22121, 13928, 16630, 2236, 19089, 7063, 7908, 25407, 22445]),\n",
       " (722, [16630, 7494, 20146, 19709, 12409, 19480, 2426, 22121, 15691, 23600]),\n",
       " (776, [2426, 15691, 9555, 16630, 23154, 19089, 8097, 2236, 10834, 10594]),\n",
       " (880, [17723, 19480, 19709, 7494, 19089, 23600, 16630, 14291, 23481, 20146]),\n",
       " (962, [19089, 7494, 16630, 22121, 23481, 2533, 24075, 18984, 8431, 15691]),\n",
       " (1020, [9438, 10269, 19089, 5942, 20146, 19480, 25675, 9851, 1700, 17760]),\n",
       " (1099, [20146, 17723, 19089, 16630, 23600, 19480, 19709, 24075, 22121, 9438]),\n",
       " (1292, [19114, 12061, 8544, 18190, 10786, 2300, 13541, 11792, 18528, 12056]),\n",
       " (1368, [18317, 16630, 20146, 22445, 19089, 8894, 2236, 13928, 2426, 17723]),\n",
       " (1514, [7494, 19089, 24546, 20146, 19480, 24355, 10269, 23481, 8894, 14684]),\n",
       " (1590, [16630, 19089, 15691, 25407, 8097, 7494, 22121, 8431, 23481, 19709]),\n",
       " (1760, [19089, 16630, 7494, 22121, 24075, 20146, 11658, 18317, 17723, 8431]),\n",
       " (1789, [15691, 6734, 10834, 1583, 21920, 2492, 23141, 18452, 17156, 7991]),\n",
       " (1863, [19332, 25407, 7494, 2426, 18984, 10269, 15691, 18317, 7908, 8431]),\n",
       " (1894, [22121, 8894, 20146, 22445, 19709, 6076, 8431, 18317, 9090, 5044]),\n",
       " (1898, [24075, 19089, 10834, 16630, 22121, 8894, 10594, 20146, 7494, 6734]),\n",
       " (1935, [17723, 19089, 20146, 7494, 16630, 23189, 19709, 20982, 23600, 22853]),\n",
       " (1949, [19089, 12409, 20146, 17723, 19709, 19480, 7494, 22121, 16630, 8894]),\n",
       " (2007, [19089, 7494, 9438, 20146, 22121, 12409, 16630, 23481, 19332, 25675]),\n",
       " (2059, [7494, 19709, 16630, 19480, 20146, 23600, 12409, 17723, 22121, 2426]),\n",
       " (2100, [19089, 24075, 7494, 20146, 8894, 9438, 17723, 19332, 17257, 2426]),\n",
       " (2107, [8097, 5952, 16630, 19709, 25407, 7494, 11533, 20146, 15691, 2426]),\n",
       " (2387, [24075, 10786, 19114, 9851, 25693, 25071, 21854, 23536, 2300, 2468]),\n",
       " (2776, [19089, 7494, 16630, 18984, 8097, 20146, 15691, 22121, 8431, 5522]),\n",
       " (3044, [20146, 19089, 8894, 17723, 23600, 2533, 16630, 22121, 8431, 19709]),\n",
       " (3184, [23600, 19480, 16630, 7494, 19709, 23481, 17760, 19089, 14291, 9339]),\n",
       " (3284, [19089, 17723, 7494, 20146, 12409, 16630, 19480, 19709, 22121, 18984]),\n",
       " (3321, [25675, 7494, 5942, 2426, 19480, 25407, 12061, 22554, 22121, 8894]),\n",
       " (3442, [8894, 24075, 23600, 19709, 16630, 9438, 19480, 18984, 11658, 16005]),\n",
       " (3461, [20146, 7494, 19089, 17723, 23600, 16630, 8894, 18317, 23189, 3971]),\n",
       " (3544, [9683, 16394, 5436, 23004, 5581, 2426, 20363, 5838, 25763, 15903]),\n",
       " (3705, [7494, 20146, 17723, 19089, 24355, 4502, 19480, 16630, 22853, 23189]),\n",
       " (3757, [7494, 20146, 24075, 8894, 19480, 12409, 17723, 22121, 9438, 23481]),\n",
       " (3805, [7494, 19089, 19709, 23600, 23481, 19480, 12409, 24075, 2533, 17257]),\n",
       " (3899, [19089, 20146, 19709, 24075, 23600, 19480, 12409, 22121, 2533, 23481]),\n",
       " (4138, [17723, 23600, 19480, 8894, 22121, 12409, 24075, 2533, 18984, 9438]),\n",
       " (4163, [19480, 19089, 19709, 7494, 23481, 20146, 3165, 24075, 11730, 2533]),\n",
       " (4380, [19089, 17723, 20146, 19480, 7494, 19709, 22853, 16630, 22121, 17257]),\n",
       " (4412, [19089, 8431, 7494, 16630, 20146, 18984, 22121, 23600, 24209, 17723]),\n",
       " (5425, [19089, 19709, 7494, 17723, 20146, 23600, 16630, 3165, 22121, 14895]),\n",
       " (5670, [8894, 22121, 19709, 2533, 24075, 17257, 19480, 8431, 23481, 11295]),\n",
       " (5740, [7494, 19709, 22121, 23600, 12409, 23481, 8894, 24075, 17723, 11658]),\n",
       " (6042, [19089, 24075, 20146, 19709, 23600, 25407, 9438, 2426, 20095, 8097]),\n",
       " (6096, [7494, 20146, 19709, 23600, 12409, 19089, 20982, 19480, 16630, 3165]),\n",
       " (6114, [17723, 20146, 7494, 14488, 19089, 16630, 13231, 23189, 19709, 20982]),\n",
       " (6167, [15691, 20146, 6734, 5044, 9438, 19480, 2533, 10269, 25675, 20095]),\n",
       " (6311, [19089, 16630, 24075, 8894, 2533, 19480, 19709, 12409, 17723, 9438]),\n",
       " (6316, [25407, 15691, 9555, 6734, 10834, 22010, 18392, 17156, 22848, 1583]),\n",
       " (6340, [8894, 12409, 19089, 13944, 19480, 18317, 19332, 24075, 14951, 11133]),\n",
       " (6426, [24075, 23536, 12061, 23127, 18190, 10786, 4620, 13541, 21552, 2300]),\n",
       " (6432, [23600, 19480, 16630, 20146, 7494, 17723, 12409, 23481, 2665, 8894]),\n",
       " (6688, [23536, 13541, 5717, 15459, 2868, 18190, 11792, 3983, 18528, 10450]),\n",
       " (6710, [10269, 9438, 25675, 19089, 10786, 12061, 22121, 9851, 5942, 7494]),\n",
       " (6809, [17723, 7494, 8894, 19089, 8431, 25873, 20146, 24075, 23481, 16630]),\n",
       " (7088, [20146, 7494, 19089, 16630, 15691, 2236, 22121, 8894, 17723, 18984]),\n",
       " (7293, [20146, 19089, 7494, 11658, 16630, 23481, 17723, 12466, 23189, 22121]),\n",
       " (7342, [24075, 7494, 20146, 23481, 16630, 17723, 12409, 22121, 25675, 25693]),\n",
       " (7514, [19089, 7494, 19480, 12409, 16630, 3165, 23481, 14895, 24075, 17257]),\n",
       " (7515, [17723, 20146, 7494, 19089, 19709, 16630, 23189, 18317, 8431, 23600]),\n",
       " (7542, [8894, 19089, 20146, 18984, 13928, 8431, 2426, 2533, 7908, 24075]),\n",
       " (7797, [19089, 20146, 19480, 7494, 23600, 12409, 3165, 14895, 24075, 23481]),\n",
       " (17, [9438, 25675, 20146, 19089, 12061, 5942, 10786, 19480, 16630, 17723]),\n",
       " (139, [24075, 2426, 21064, 13928, 19089, 9438, 5469, 681, 20146, 7012]),\n",
       " (142, [10269, 9851, 19480, 25675, 7494, 21552, 13118, 5717, 8538, 23600]),\n",
       " (177, [25407, 9555, 6734, 15691, 10594, 10834, 18392, 19089, 22848, 21920]),\n",
       " (201, [20146, 19480, 24075, 16630, 19089, 23600, 24355, 17257, 9438, 17723]),\n",
       " (301, [7494, 19709, 12409, 22121, 19480, 16630, 8894, 17723, 20095, 23481]),\n",
       " (526, [19089, 22121, 16630, 23600, 2426, 15691, 24075, 9438, 19480, 25407]),\n",
       " (592, [24075, 19874, 23600, 16630, 22121, 19709, 19480, 14684, 10269, 8894]),\n",
       " (665, [7494, 23600, 19709, 8894, 16630, 19480, 23481, 22121, 17723, 24075]),\n",
       " (796, [20146, 19089, 16630, 23600, 17723, 19709, 24075, 8894, 9438, 23481]),\n",
       " (1068, [24075, 14684, 4502, 13118, 9438, 10269, 10786, 16195, 7494, 19089]),\n",
       " (1331, [20146, 17723, 16630, 19089, 23600, 24075, 9438, 19480, 8894, 2665]),\n",
       " (1389,\n",
       "  [19089, 20146, 24075, 17723, 19332, 16630, 14951, 19709, 23600, 12409]),\n",
       " (1413, [20146, 23600, 16630, 19480, 17723, 9438, 19089, 24075, 23481, 8894]),\n",
       " (1568, [2426, 25407, 19089, 18392, 15691, 23154, 9555, 23600, 6878, 16630]),\n",
       " (1599, [24075, 13837, 23127, 3668, 23568, 2641, 19114, 25693, 12494, 10428]),\n",
       " (1624, [10269, 9438, 25675, 20146, 10786, 12061, 19089, 9851, 13118, 17723]),\n",
       " (1801, [25407, 15691, 9555, 23154, 10594, 25675, 10834, 5044, 10269, 8097]),\n",
       " (1815, [8709, 18793, 9662, 3037, 497, 22356, 12048, 22385, 4936, 9769]),\n",
       " (1999, [25407, 22121, 19089, 7494, 9555, 16630, 9438, 18984, 23154, 23600]),\n",
       " (2077, [19089, 16630, 18984, 23600, 22121, 19709, 8431, 19480, 8894, 17723]),\n",
       " (2119, [24075, 19089, 10269, 5942, 23600, 17723, 8894, 25675, 19480, 8431]),\n",
       " (2190, [21552, 20146, 19480, 9591, 24075, 25675, 9438, 8544, 364, 19089]),\n",
       " (2215, [20146, 23600, 16630, 17723, 19089, 8894, 19332, 24075, 19525, 9438]),\n",
       " (2823, [25407, 24075, 9555, 23154, 2492, 11533, 22801, 25596, 8097, 2236]),\n",
       " (2843, [19089, 20146, 8894, 17723, 22121, 23600, 16630, 12409, 2665, 2533]),\n",
       " (2852, [24075, 25407, 20146, 5952, 20308, 19089, 10418, 2426, 12214, 9769]),\n",
       " (2860, [24075, 9438, 10269, 25675, 20146, 19089, 22554, 10786, 2426, 13118]),\n",
       " (2870, [2533, 5717, 19089, 24075, 13541, 20146, 4620, 17723, 23481, 8431]),\n",
       " (2981, [19089, 8097, 25407, 23600, 16630, 8894, 5044, 2426, 22121, 24075]),\n",
       " (3001, [10269, 9438, 25675, 12061, 9851, 20146, 19089, 16630, 5942, 22121]),\n",
       " (3220, [10269, 9438, 25675, 20146, 25407, 19089, 10786, 22121, 5942, 12061]),\n",
       " (3235, [20146, 19089, 19709, 19480, 12409, 24075, 3165, 16630, 14895, 8894]),\n",
       " (3238, [24075, 23536, 12061, 19114, 5717, 13541, 11792, 21854, 2300, 19480]),\n",
       " (3239, [23600, 19709, 16630, 12409, 19480, 23481, 2665, 22121, 8894, 24075]),\n",
       " (3252, [24075, 12061, 10786, 23600, 25675, 19089, 9438, 19480, 25046, 17858]),\n",
       " (3280, [20146, 16630, 17723, 19089, 23600, 19480, 24075, 9438, 8894, 23481]),\n",
       " (3294, [16630, 19709, 23600, 20146, 24075, 22121, 2533, 17723, 23481, 8431]),\n",
       " (3339, [20146, 16630, 17723, 19089, 23600, 19480, 24075, 9438, 8894, 23481]),\n",
       " (3477, [24075, 19089, 19480, 20146, 9438, 12409, 11658, 17723, 12061, 22121]),\n",
       " (3627, [19089, 8894, 20146, 16630, 24075, 22121, 18984, 17723, 23600, 12409]),\n",
       " (3650, [24075, 20146, 19089, 12061, 10269, 9438, 2426, 23600, 13118, 25675]),\n",
       " (3788, [24075, 2426, 19089, 22121, 10269, 2533, 10786, 9555, 16630, 17257]),\n",
       " (3896, [10269, 12061, 9438, 10786, 9851, 21552, 19480, 19089, 25693, 773]),\n",
       " (4006, [20146, 19089, 22121, 8894, 19709, 12409, 24075, 4502, 19480, 16630]),\n",
       " (4010, [7494, 24075, 16630, 19709, 22121, 20146, 12409, 9438, 15691, 23600]),\n",
       " (4078, [25407, 8709, 2426, 20146, 4936, 24075, 15778, 5044, 19089, 15691]),\n",
       " (4389, [21552, 19480, 24075, 15830, 23481, 8544, 13797, 9851, 7639, 364]),\n",
       " (4456, [19089, 9438, 10269, 19709, 22121, 17723, 16630, 25675, 2533, 3165]),\n",
       " (4515, [24075, 19089, 23600, 19709, 5942, 25675, 12061, 19480, 10269, 25693]),\n",
       " (4722,\n",
       "  [20146, 19089, 24075, 19480, 23600, 18984, 19709, 23481, 17723, 22121]),\n",
       " (4957, [11979, 6329, 19089, 7341, 9438, 11900, 17525, 6534, 16773, 2427]),\n",
       " (4961, [20146, 17723, 25013, 19089, 24075, 24355, 9438, 19480, 4502, 16630]),\n",
       " (5009, [24075, 19089, 23600, 17723, 9438, 16630, 10269, 12409, 17257, 12061]),\n",
       " (5066, [24075, 9438, 12061, 25675, 20146, 13118, 19089, 19480, 10786, 23600]),\n",
       " (5141, [20146, 19089, 14684, 24355, 17723, 16630, 24075, 19709, 9438, 23600]),\n",
       " (5233, [24355, 7883, 20308, 24075, 18419, 18512, 4257, 1714, 20146, 9438]),\n",
       " (5237, [9438, 19089, 19709, 20146, 10269, 24355, 12061, 2426, 25407, 16630]),\n",
       " (5309, [19089, 20146, 19709, 12409, 24075, 23481, 8894, 8431, 2533, 18984]),\n",
       " (5557, [19089, 19709, 22121, 7494, 16630, 8894, 23600, 25407, 24355, 23481]),\n",
       " (5636, [19089, 4502, 24075, 14684, 9438, 24355, 19709, 10418, 23481, 16630]),\n",
       " (5806, [19089, 23600, 17723, 16630, 9438, 20095, 22121, 19709, 19480, 23481]),\n",
       " (5992, [20146, 16630, 19709, 19480, 12409, 23600, 22121, 8894, 23481, 24075]),\n",
       " (5998, [23600, 20146, 19709, 16630, 19480, 8894, 2665, 24075, 22121, 8431]),\n",
       " (6202, [25407, 20146, 23481, 19709, 10269, 23600, 25675, 17723, 8097, 20095]),\n",
       " (6203, [19089, 22121, 24075, 8894, 16630, 19709, 19480, 7494, 20146, 23600]),\n",
       " (6245, [20146, 19089, 23600, 17723, 16630, 19480, 8431, 2533, 24075, 23481]),\n",
       " (6248, [19089, 24075, 17723, 9438, 12409, 2533, 22121, 19709, 8431, 9637]),\n",
       " (6269, [20308, 14684, 24355, 7494, 11900, 19874, 6329, 19089, 24075, 21629]),\n",
       " (6300, [20146, 19089, 12409, 24075, 19480, 17723, 9438, 19709, 8894, 16630]),\n",
       " (6386, [15691, 9555, 23154, 6734, 10594, 24075, 10834, 20146, 19089, 16630]),\n",
       " (6505, [19089, 23600, 22121, 24075, 16630, 2426, 8894, 19480, 9438, 17723]),\n",
       " (6522, [22121, 19089, 20146, 8894, 16630, 22445, 12409, 24075, 2236, 681]),\n",
       " (6592, [10269, 9438, 12061, 19480, 10786, 7494, 5717, 9851, 25693, 19709]),\n",
       " (6603, [24075, 20146, 19089, 25675, 10269, 25693, 12061, 9851, 10786, 21552]),\n",
       " (6605, [24075, 10269, 20146, 5942, 25675, 19089, 19480, 22554, 10786, 25693]),\n",
       " (6700, [24075, 20146, 17820, 23600, 10269, 24093, 16630, 8064, 17723, 19089]),\n",
       " (6732, [19089, 8894, 8431, 20146, 22121, 19709, 25675, 11658, 17723, 23600]),\n",
       " (6734, [24075, 25675, 12061, 19089, 10269, 20146, 19480, 5942, 7964, 8894]),\n",
       " (6806, [2426, 4502, 19874, 24075, 24355, 15691, 9555, 20308, 23154, 10834]),\n",
       " (6901, [24075, 16630, 20146, 22121, 19709, 9438, 23600, 8894, 19480, 12409]),\n",
       " (6909, [24075, 10786, 5942, 19089, 25407, 20146, 13118, 19480, 3803, 15691]),\n",
       " (7089, [23600, 16630, 19709, 17723, 19480, 22121, 23481, 8894, 9438, 24075]),\n",
       " (7135, [2426, 19089, 9438, 19709, 24075, 15691, 17723, 8894, 9555, 23600]),\n",
       " (7178, [21552, 23481, 4927, 19089, 5717, 13797, 8544, 1863, 9851, 24908]),\n",
       " (7181, [19089, 22121, 2533, 8894, 10269, 20146, 23481, 9438, 19480, 20095]),\n",
       " (7238, [10269, 25675, 9438, 12061, 10786, 9851, 5942, 22554, 15034, 23799]),\n",
       " (7458, [19874, 24075, 24355, 19089, 4502, 22121, 5044, 23600, 17723, 2426]),\n",
       " (7782, [19709, 7494, 23600, 20146, 8431, 12409, 2533, 19480, 24075, 19089]),\n",
       " (7816, [20146, 19089, 24075, 8431, 2533, 8894, 19480, 22121, 9438, 16630]),\n",
       " (7846, [2533, 23481, 24075, 8894, 19089, 17723, 11658, 11295, 7494, 10269]),\n",
       " (651, [9438, 2426, 25675, 15691, 19480, 19709, 9555, 7494, 5942, 16630]),\n",
       " (697, [19089, 23600, 7494, 12409, 20146, 19709, 18317, 24075, 8894, 19480]),\n",
       " (956, [19089, 22121, 19709, 8894, 20146, 23600, 18984, 2533, 19480, 7494]),\n",
       " (1087, [19709, 7494, 19480, 23600, 12409, 19089, 20146, 24075, 2665, 2533]),\n",
       " (1608, [19709, 23600, 7494, 12409, 20146, 2665, 19480, 24075, 20982, 3165]),\n",
       " (1759, [10269, 19089, 12061, 7494, 19709, 10786, 9851, 5942, 20146, 22121]),\n",
       " (1891, [20146, 19709, 7494, 23600, 12409, 5032, 2665, 24075, 8097, 9662]),\n",
       " (2178, [10269, 9438, 25675, 10786, 12061, 9851, 5942, 7494, 19709, 23600]),\n",
       " (2698, [19709, 24075, 7494, 19089, 24355, 23600, 19874, 12409, 3165, 23481]),\n",
       " (2756, [19709, 7494, 20146, 16630, 8894, 17723, 24075, 9438, 14895, 23481]),\n",
       " (3337, [24075, 23536, 20496, 23127, 23711, 21552, 9284, 12056, 25675, 19114]),\n",
       " (3480, [10269, 9438, 25675, 10786, 12061, 9851, 19709, 5942, 7494, 23600]),\n",
       " (3762, [19089, 24075, 19709, 7494, 23600, 20146, 8431, 12409, 18984, 2533]),\n",
       " (4185, [24075, 25675, 10786, 7494, 9851, 19480, 19709, 13118, 12409, 22554]),\n",
       " (4256, [19089, 23600, 16630, 7494, 22121, 19709, 20146, 2665, 12409, 24075]),\n",
       " (4278, [24546, 9438, 24075, 23600, 5802, 21248, 23108, 9976, 4127, 5251]),\n",
       " (4994, [18984, 19089, 11658, 23481, 24075, 2533, 16630, 7494, 18930, 20146]),\n",
       " (5132, [20173, 24355, 7494, 18645, 16412, 13444, 6329, 1255, 25013, 11900]),\n",
       " (5660, [2426, 15691, 9555, 5044, 23154, 10594, 10834, 20146, 6734, 7991]),\n",
       " (5966, [2426, 25407, 9555, 6734, 15691, 10834, 1583, 18392, 17156, 19709]),\n",
       " (6216, [24075, 19089, 9438, 7494, 10269, 20146, 10786, 25675, 13118, 16630]),\n",
       " (6458, [19709, 7494, 20146, 8894, 16630, 22121, 24075, 14895, 23481, 18317]),\n",
       " (6467, [19089, 20146, 19709, 7494, 19480, 22121, 16630, 8894, 24075, 25407]),\n",
       " (6787, [7494, 5562, 19709, 23628, 9438, 24075, 19089, 23743, 20146, 19451]),\n",
       " (6819, [19709, 23600, 7494, 12409, 20146, 2665, 19480, 24075, 20982, 3165]),\n",
       " (6986, [24075, 7494, 20146, 23600, 2533, 12409, 19709, 19480, 19089, 773]),\n",
       " (7177, [24075, 19089, 19709, 19480, 12409, 22359, 20146, 7494, 16630, 8811]),\n",
       " (7719, [19089, 23600, 23154, 7494, 25407, 20146, 2426, 8894, 19480, 12409]),\n",
       " (1698, [19114, 5717, 18190, 23127, 21854, 2333, 15145, 23457, 11792, 13541]),\n",
       " (1787, [23600, 3858, 17257, 7494, 3053, 2448, 947, 10829, 17525, 24300]),\n",
       " (1857, [11900, 24075, 16773, 1255, 4063, 7494, 25013, 4502, 19089, 17525]),\n",
       " (2703, [7494, 19089, 19332, 19709, 8894, 23600, 20146, 2665, 17257, 23481]),\n",
       " (3485, [4502, 16394, 10491, 15844, 24355, 19874, 14684, 10418, 7494, 18419]),\n",
       " (5664, [18793, 20300, 23318, 3037, 22385, 23600, 17257, 22835, 15778, 13188]),\n",
       " (5, [7494, 19089, 8097, 25407, 19709, 19874, 5044, 12914, 23600, 22121]),\n",
       " (50, [2426, 9555, 15691, 10594, 6734, 10834, 1583, 23141, 7494, 18392]),\n",
       " (169, [25407, 2426, 15691, 7494, 23154, 19089, 19709, 10834, 5044, 8097]),\n",
       " (510, [2426, 15691, 9555, 10594, 23154, 10834, 6734, 5044, 23141, 24075]),\n",
       " (525, [7494, 19089, 8894, 24075, 9438, 17723, 19709, 2533, 19480, 16630]),\n",
       " (1080, [2426, 19089, 9555, 5044, 7494, 22121, 8894, 19709, 18984, 24075]),\n",
       " (1135, [16630, 8894, 20146, 7494, 2533, 25407, 15691, 8431, 2426, 10269]),\n",
       " (1351, [25675, 7494, 12061, 19089, 10786, 13118, 9851, 25693, 22121, 15564]),\n",
       " (1369, [7494, 19089, 24075, 9438, 19709, 23600, 10269, 25407, 22121, 24355]),\n",
       " (1394, [24075, 7494, 23600, 16630, 9438, 17723, 8894, 12409, 9851, 5717]),\n",
       " (1722, [7494, 19089, 23600, 19709, 5044, 22121, 12409, 17723, 23481, 16630]),\n",
       " (1731, [10269, 9438, 7494, 19089, 25675, 10786, 12061, 24355, 5942, 4502]),\n",
       " (1991, [2426, 15691, 24075, 19089, 22121, 10594, 6734, 20146, 23141, 1240]),\n",
       " (2022, [19709, 16630, 23600, 7494, 12409, 20146, 23481, 14895, 8894, 24075]),\n",
       " (2351, [22500, 23068, 24075, 11900, 11658, 5942, 6612, 8371, 10788, 19089]),\n",
       " (2556, [25407, 7494, 19089, 19709, 5044, 22121, 1240, 20095, 15691, 3037]),\n",
       " (2859, [7494, 25407, 19089, 8097, 2426, 1240, 5044, 19709, 23141, 15691]),\n",
       " (2935, [7494, 19089, 19709, 16630, 25407, 23600, 23481, 8894, 15691, 8097]),\n",
       " (3172, [24075, 9438, 7494, 19089, 14684, 25407, 5044, 5942, 23600, 19480]),\n",
       " (3223, [25407, 19089, 8097, 22121, 2426, 7494, 16630, 5044, 19480, 18984]),\n",
       " (3375, [2426, 19089, 15691, 7494, 8097, 8894, 24075, 23154, 9555, 18984]),\n",
       " (3563, [7494, 19089, 19709, 23600, 12409, 22121, 16630, 23481, 11295, 5044]),\n",
       " (3694, [7494, 19709, 12409, 19480, 16630, 22121, 17723, 8894, 5044, 23481]),\n",
       " (4273, [2426, 7494, 15691, 9555, 5044, 8097, 23154, 19089, 10594, 6734]),\n",
       " (4484, [10269, 9438, 22554, 10786, 12061, 7494, 5942, 9851, 19089, 13118]),\n",
       " (4560, [19089, 25407, 7494, 9555, 8097, 2426, 19480, 16630, 15691, 8894]),\n",
       " (5060, [9555, 23154, 10594, 8097, 10834, 19089, 6734, 7494, 1583, 1240]),\n",
       " (5119, [7494, 19089, 23600, 19709, 5044, 22121, 12409, 17723, 16630, 23481]),\n",
       " (5123, [7494, 19480, 23600, 12409, 23481, 16630, 17723, 8894, 14895, 5044]),\n",
       " (5332, [7494, 19089, 25407, 8097, 5044, 19709, 20095, 8894, 23600, 16630]),\n",
       " (5356, [22548, 497, 9769, 25407, 15182, 7494, 22385, 19089, 11975, 7267]),\n",
       " (5368, [7494, 19089, 23600, 19709, 17723, 5044, 22121, 12409, 23481, 16630]),\n",
       " (5371, [7494, 19089, 23600, 19709, 25407, 5044, 22121, 12409, 17723, 8097]),\n",
       " (5513, [22121, 25407, 7494, 8894, 19480, 23600, 2426, 24075, 2533, 8431]),\n",
       " (5801, [9438, 7494, 24075, 12061, 5942, 17723, 19089, 10786, 17257, 10269]),\n",
       " (6013, [7494, 19089, 23600, 19709, 22121, 24355, 17723, 12409, 23481, 16630]),\n",
       " (6279, [18190, 2333, 23536, 4620, 18528, 23711, 2868, 19114, 12061, 21854]),\n",
       " (6544, [19089, 7494, 22121, 23600, 25407, 19709, 8097, 8894, 19480, 12409]),\n",
       " (6622, [7494, 19089, 23600, 19709, 12409, 17723, 16630, 5044, 2665, 22121]),\n",
       " (6793, [9438, 19089, 19709, 24546, 7494, 17723, 21505, 5284, 12230, 7839]),\n",
       " (7113, [20308, 7494, 5581, 20553, 24075, 1714, 17668, 11737, 19089, 15234]),\n",
       " (7509, [15691, 9555, 19089, 10834, 23154, 8894, 7494, 8097, 16630, 10594]),\n",
       " (7687, [7494, 19089, 8894, 24075, 2533, 23600, 19709, 17723, 16630, 23481]),\n",
       " (2, [25953, 23701, 25670, 1928, 3550, 24655, 20479, 10405, 2379, 13197]),\n",
       " (2257, [4927, 9851, 5119, 15830, 23568, 19114, 25693, 24075, 9007, 17115]),\n",
       " (4293, [13541, 19114, 23127, 4620, 2300, 23711, 21854, 23457, 12061, 15145]),\n",
       " (4496, [23711, 2868, 18528, 9284, 15459, 23127, 12061, 11792, 9029, 18114]),\n",
       " (5758, [3176, 23127, 19114, 5119, 3804, 3668, 25491, 9556, 10428, 25693]),\n",
       " (6867, [18122, 18790, 16901, 4528, 9591, 5546, 10428, 7327, 2300, 6915]),\n",
       " (7508, [23127, 19114, 4620, 18190, 23536, 12061, 8544, 13541, 2333, 11792]),\n",
       " (3, [11681, 12473, 17578, 14446, 19572, 25953, 9577, 3550, 24655, 20479]),\n",
       " (1803, [14657, 11329, 20825, 1578, 18146, 7507, 16957, 10117, 18132, 387]),\n",
       " (3112, [10269, 9851, 10786, 8811, 25675, 9438, 18122, 17820, 13118, 25068]),\n",
       " (6848, [19089, 18984, 11658, 24075, 22121, 7494, 19525, 23965, 5522, 19388]),\n",
       " (5014, [8304, 24484, 17820, 15764, 8064, 6897, 18122, 12110, 11153, 5825]),\n",
       " (5796, [10269, 25675, 9438, 12061, 10786, 9851, 5942, 22554, 13118, 22121]),\n",
       " (6049, [1863, 18122, 8304, 12061, 24075, 8544, 15764, 8064, 9851, 24484]),\n",
       " (4, [1611, 9007, 18692, 19114, 9243, 9851, 19704, 21552, 25491, 12474]),\n",
       " (786, [23127, 4620, 23536, 13541, 11792, 2300, 9007, 9851, 10786, 23711]),\n",
       " (837, [5717, 10786, 9851, 20496, 18190, 24075, 9007, 18528, 2333, 19114]),\n",
       " (1357, [12061, 23127, 4620, 9029, 10786, 19114, 9007, 24075, 8544, 23711]),\n",
       " (1363, [23127, 13837, 5717, 25491, 19114, 19079, 3469, 3804, 4528, 11987]),\n",
       " (1447, [12061, 25071, 773, 5119, 24850, 25046, 16503, 25675, 19114, 24075]),\n",
       " (1771, [24075, 21552, 19480, 25675, 10269, 9851, 12061, 25693, 10786, 8544]),\n",
       " (1956, [21552, 23127, 8544, 13837, 5119, 9851, 5717, 15830, 3804, 7639]),\n",
       " (2282, [5717, 2333, 10786, 11792, 23711, 24075, 2300, 21552, 25675, 4620]),\n",
       " (2970, [23536, 5717, 21854, 13541, 18528, 23127, 19114, 12061, 18190, 2868]),\n",
       " (3594, [24075, 12061, 5717, 9851, 25693, 25491, 867, 25675, 8544, 2300]),\n",
       " (5115, [19079, 867, 1611, 19114, 24908, 25491, 22722, 5717, 11792, 13707]),\n",
       " (5157, [5717, 23127, 25071, 23536, 18528, 25693, 8544, 10269, 13541, 20496]),\n",
       " (5628, [5717, 18528, 2333, 4528, 4620, 12061, 867, 21854, 2868, 3835]),\n",
       " (5872, [21552, 7639, 25491, 15830, 19480, 8544, 3835, 9851, 4927, 25693]),\n",
       " (5880, [21552, 8544, 4620, 25491, 19114, 5717, 11384, 11792, 867, 11452]),\n",
       " (6160, [5717, 23127, 8544, 3668, 19114, 13837, 9851, 2300, 10786, 12061]),\n",
       " (6206, [9851, 21552, 9007, 12474, 4620, 23536, 5717, 1526, 11452, 8544]),\n",
       " (6712, [5717, 13541, 12061, 19114, 21854, 23457, 2300, 15327, 9284, 13030]),\n",
       " (6841, [5717, 23127, 867, 8544, 9007, 11792, 24908, 3668, 25491, 9243]),\n",
       " (7139, [6088, 5717, 23536, 18190, 4620, 15459, 18528, 2333, 2868, 23711]),\n",
       " (7347, [12061, 10269, 9851, 5717, 10786, 23127, 25675, 21552, 2333, 19114]),\n",
       " (7382, [23127, 10786, 9851, 8544, 13541, 21552, 12056, 23711, 25675, 773]),\n",
       " (7500, [24075, 5717, 10786, 25675, 18528, 25693, 17858, 21552, 11792, 8811]),\n",
       " (7637, [1611, 12474, 4294, 9243, 18176, 1526, 10649, 10887, 12543, 25071]),\n",
       " (7756, [23536, 4620, 10428, 3835, 21552, 5717, 25491, 11792, 19114, 3668]),\n",
       " (7926, [19704, 23127, 21552, 1526, 13837, 9007, 4620, 14012, 19079, 8544]),\n",
       " (1839, [5717, 11792, 13707, 867, 6767, 9029, 24224, 11067, 20027, 5212]),\n",
       " (4173, [21552, 20496, 23536, 9851, 13363, 12742, 11384, 1863, 12710, 4209]),\n",
       " (4285, [8894, 7494, 6994, 2533, 22121, 20146, 19089, 24075, 11295, 16005]),\n",
       " (4959, [24075, 13552, 3527, 1745, 9438, 13319, 24415, 17093, 11623, 23799]),\n",
       " (281, [2333, 12061, 23536, 13541, 18190, 10786, 19114, 2300, 23711, 25675]),\n",
       " (1209, [23536, 2333, 18528, 11792, 4620, 6088, 15327, 23127, 9284, 21854]),\n",
       " (2071, [5717, 23536, 23127, 18190, 18528, 2300, 11792, 23457, 23711, 12061]),\n",
       " (2305, [11859, 19781, 18692, 11518, 12742, 9007, 19114, 3835, 11384, 20729]),\n",
       " (2403, [21552, 4502, 14684, 5717, 8544, 1863, 11452, 11384, 19114, 9851]),\n",
       " (2472, [5717, 18190, 23536, 9284, 6088, 12341, 15327, 23711, 12061, 2333]),\n",
       " (3505, [25491, 11792, 5717, 19781, 11067, 3835, 19114, 21552, 21365, 11384]),\n",
       " (3807, [5717, 19114, 867, 10786, 12061, 23127, 9851, 25675, 21552, 24075]),\n",
       " (4538, [19114, 23536, 4620, 18190, 2333, 12061, 23711, 25491, 21854, 9029]),\n",
       " (4913, [11731, 9243, 19781, 23127, 3185, 19114, 11792, 12983, 4620, 3668]),\n",
       " (4933, [19114, 23536, 2333, 13541, 18190, 867, 17858, 4620, 25675, 20496]),\n",
       " (5873, [5717, 10786, 2333, 19114, 18190, 11792, 23127, 2300, 9029, 2868]),\n",
       " (5978, [12061, 10786, 9438, 19114, 10269, 21552, 9851, 11792, 23127, 867]),\n",
       " (6555, [9243, 19781, 4927, 18692, 21552, 11792, 19704, 19114, 3337, 5717]),\n",
       " (6701, [5717, 24075, 19114, 15830, 9243, 9438, 19781, 12061, 9851, 21552]),\n",
       " (7096, [19114, 24075, 9851, 5717, 15830, 13797, 3176, 9438, 25491, 22359]),\n",
       " (2115, [19089, 23481, 16630, 12409, 14895, 7494, 8894, 24075, 3165, 20146]),\n",
       " (2951, [12791, 6980, 733, 20331, 9609, 23677, 9851, 9152, 6950, 23679]),\n",
       " (4452, [9438, 10786, 9851, 24175, 6950, 25718, 24075, 9295, 733, 21647]),\n",
       " (5810, [24175, 25693, 9438, 23677, 23679, 9851, 19792, 10786, 12791, 1376]),\n",
       " (75, [19910, 21552, 15830, 23481, 22511, 20108, 19114, 19480, 9339, 23666]),\n",
       " (369, [19089, 8431, 7494, 2533, 18984, 5522, 19480, 23481, 12409, 23600]),\n",
       " (1143, [23536, 5717, 18190, 2333, 12061, 23711, 4620, 18528, 6088, 15459]),\n",
       " (1237, [12742, 25675, 11384, 21552, 5717, 3835, 24075, 12061, 25491, 14220]),\n",
       " (5524, [4620, 18190, 21552, 9851, 12061, 24075, 8544, 23127, 19114, 15327]),\n",
       " (6429, [19874, 14684, 24355, 21552, 11452, 4502, 24075, 17668, 19480, 10418]),\n",
       " (7615, [3348, 878, 7122, 21552, 10887, 19922, 16270, 12710, 9797, 11716]),\n",
       " (1221, [23127, 2300, 23536, 25491, 13837, 18528, 25928, 15145, 11792, 4620]),\n",
       " (6382, [4927, 8544, 25491, 21552, 14311, 5746, 14012, 18692, 15830, 5717]),\n",
       " (1750, [5717, 24075, 21552, 15830, 23536, 2333, 9851, 13541, 8544, 11384]),\n",
       " (2779, [18399, 16241, 24573, 10796, 24216, 10073, 23481, 23220, 4257, 18419]),\n",
       " (5453, [8544, 5717, 24075, 9851, 773, 15830, 10786, 23481, 12061, 19089]),\n",
       " (5741, [24075, 12061, 25693, 8431, 20146, 2533, 9637, 18512, 13955, 19709]),\n",
       " (6647, [19874, 4502, 24075, 10418, 17668, 7494, 9438, 20146, 5581, 19089]),\n",
       " (7212, [18419, 20308, 14684, 24355, 4502, 10796, 19874, 24070, 24216, 23481]),\n",
       " (7689, [17668, 18419, 20308, 25193, 15124, 18512, 17305, 16241, 20553, 2459]),\n",
       " (3809, [2426, 15691, 13663, 19875, 10792, 13928, 15169, 25596, 1840, 22010]),\n",
       " (4208, [25407, 2426, 25596, 19875, 2236, 15691, 1085, 15169, 12050, 349]),\n",
       " (6845, [4257, 16394, 10753, 4502, 12162, 17951, 20308, 1056, 24138, 19627]),\n",
       " (6956, [5952, 12050, 22801, 2426, 1056, 11533, 25407, 22798, 15169, 3447]),\n",
       " (1072, [2426, 25407, 23154, 10834, 22121, 18392, 16394, 10594, 9555, 15691]),\n",
       " (4100, [10834, 2426, 17156, 23154, 25407, 19874, 18392, 10594, 25693, 9555]),\n",
       " (4611, [2426, 23154, 15691, 8709, 9555, 15778, 8097, 5032, 6734, 7267]),\n",
       " (1512, [25407, 12914, 2426, 16394, 12214, 7583, 5952, 10753, 8322, 15691]),\n",
       " (1800, [2426, 23154, 15691, 10834, 22010, 6734, 21920, 1583, 13136, 8097]),\n",
       " (3229, [4502, 14684, 24075, 10418, 24355, 20308, 25407, 18419, 7494, 17070]),\n",
       " (5412, [16394, 25407, 8097, 2426, 24577, 22121, 24075, 3744, 19089, 2236]),\n",
       " (68, [13541, 2333, 5717, 6088, 23711, 18190, 10450, 3983, 4620, 9029]),\n",
       " (257, [14684, 4502, 25407, 10418, 2426, 9555, 7883, 4257, 24355, 23154]),\n",
       " (284, [19874, 14684, 4502, 12214, 2236, 25407, 7883, 1714, 19189, 18419]),\n",
       " (467, [10269, 12061, 25675, 9438, 10786, 13118, 22554, 4927, 5942, 773]),\n",
       " (947, [2426, 25407, 22010, 9555, 15691, 10269, 18392, 25675, 6734, 12050]),\n",
       " (1052, [14684, 19874, 4502, 19189, 4966, 21552, 7883, 15754, 10418, 12214]),\n",
       " (1119, [19089, 19874, 24075, 20146, 7494, 19709, 16630, 14684, 18984, 19480]),\n",
       " (1215, [22121, 8894, 16630, 20146, 19089, 22445, 13928, 24075, 15691, 7494]),\n",
       " (1284, [6088, 2333, 13541, 23536, 12061, 24075, 15459, 9591, 2868, 11792]),\n",
       " (1431, [4502, 19874, 8544, 14684, 10418, 11089, 20496, 18419, 22181, 1714]),\n",
       " (1442, [19874, 10418, 4502, 14684, 7883, 18419, 11737, 19189, 15363, 25924]),\n",
       " (1710, [4502, 14684, 10418, 7883, 24355, 18419, 12214, 1714, 4257, 20308]),\n",
       " (1728, [5952, 19874, 2426, 4257, 23086, 25407, 21373, 10792, 11533, 4502]),\n",
       " (1984, [8544, 24410, 4209, 8704, 6782, 17739, 15562, 20496, 5717, 3668]),\n",
       " (1989, [19874, 14684, 4502, 10418, 19189, 7883, 3525, 12214, 15234, 5078]),\n",
       " (2212, [4502, 24355, 10418, 20308, 18419, 5078, 24075, 17668, 9438, 20553]),\n",
       " (2591, [19874, 14684, 4502, 19089, 24075, 24355, 1714, 10269, 20308, 17668]),\n",
       " (2743, [2426, 15691, 9555, 10594, 6734, 10834, 23154, 1583, 23141, 8097]),\n",
       " (2965, [25407, 23154, 10834, 25675, 13711, 9438, 17156, 13928, 10908, 23141]),\n",
       " (3188, [19874, 4502, 18419, 14684, 19089, 12214, 2236, 1714, 7883, 25763]),\n",
       " (3331, [21552, 12061, 9591, 24075, 25675, 2996, 8811, 4966, 8920, 9851]),\n",
       " (3639, [19874, 4502, 14684, 19189, 12214, 7883, 1714, 25924, 10418, 18419]),\n",
       " (3928, [19874, 24355, 24075, 7494, 12061, 19480, 9438, 10418, 20308, 7883]),\n",
       " (4164, [14684, 19874, 10418, 20308, 24075, 7494, 7883, 9438, 4257, 16394]),\n",
       " (4168, [19874, 4502, 24355, 18419, 10418, 2426, 18392, 20308, 25407, 9555]),\n",
       " (4387, [19874, 24355, 10418, 20308, 18419, 4257, 5581, 10753, 7883, 8712]),\n",
       " (4413, [19874, 24355, 10418, 18419, 5581, 20308, 4257, 7883, 20553, 24075]),\n",
       " (4696, [19874, 4502, 14684, 7883, 1714, 18293, 16394, 11089, 25046, 22128]),\n",
       " (5327, [25407, 4502, 19874, 23154, 2426, 14684, 10594, 10792, 18392, 10834]),\n",
       " (5475, [14684, 4502, 10418, 18419, 24355, 7883, 1714, 20308, 4257, 12214]),\n",
       " (5753, [8395, 14684, 19874, 2835, 11089, 18419, 20345, 16324, 4502, 10722]),\n",
       " (5949, [2426, 25407, 6708, 15169, 22010, 19874, 12050, 2492, 16394, 19089]),\n",
       " (6310, [4502, 24355, 10786, 867, 8544, 5717, 10418, 14012, 4209, 18419]),\n",
       " (6407, [4502, 19874, 14684, 7883, 1714, 18419, 19189, 15754, 12214, 19089]),\n",
       " (6564, [25407, 2426, 4502, 9555, 16394, 19874, 15691, 23154, 6734, 14684]),\n",
       " (6640, [19874, 4502, 14684, 7883, 1714, 18419, 19189, 15754, 12214, 2236]),\n",
       " (7019, [19709, 16630, 7494, 19480, 20146, 23600, 8894, 24075, 22121, 18984]),\n",
       " (7121, [19874, 14684, 24075, 7883, 10418, 16394, 25675, 24355, 4257, 18419]),\n",
       " (7241, [4257, 17668, 6612, 11737, 8712, 19189, 24070, 18512, 15234, 7494]),\n",
       " (7537, [4502, 14684, 10418, 7883, 24355, 18419, 1714, 12214, 4257, 20308]),\n",
       " (7685, [12061, 25675, 5717, 9851, 21552, 18528, 9438, 11792, 9007, 23536]),\n",
       " (7813, [25407, 13928, 2426, 2236, 8894, 8097, 15691, 16630, 10834, 22445]),\n",
       " (715, [19089, 20146, 22121, 18984, 7494, 12409, 19709, 8894, 19480, 2236]),\n",
       " (2716, [5952, 13503, 4366, 8860, 8551, 8984, 4541, 22801, 19092, 13663]),\n",
       " (3015, [15524, 2765, 14564, 23763, 7006, 22752, 22649, 18696, 7829, 23004]),\n",
       " (4523, [3037, 16112, 19123, 14706, 10788, 11902, 21468, 19473, 5067, 2815]),\n",
       " (62, [16394, 8097, 5952, 19948, 24070, 4502, 12759, 3775, 25407, 15749]),\n",
       " (807, [19948, 16394, 8150, 4257, 24577, 16577, 9555, 23086, 8097, 18525]),\n",
       " (869, [7742, 19948, 17819, 16394, 16587, 23086, 25675, 25407, 13136, 5838]),\n",
       " (1401, [11533, 16394, 25407, 24075, 10834, 2426, 9438, 23086, 15691, 13928]),\n",
       " (1639, [2426, 9555, 10834, 18392, 23154, 22010, 10594, 8860, 16630, 13928]),\n",
       " (1692, [7742, 19948, 16394, 16587, 23086, 2269, 17819, 13136, 25407, 4366]),\n",
       " (2030, [18293, 12061, 25675, 24075, 1863, 9851, 4966, 9591, 8544, 8811]),\n",
       " (2095, [16394, 15196, 10269, 25407, 12214, 7742, 18392, 19948, 15642, 17546]),\n",
       " (2805, [8097, 12914, 7742, 25407, 19948, 10269, 15691, 9555, 5952, 2426]),\n",
       " (3052, [8990, 17229, 25407, 1583, 15691, 16577, 8097, 9555, 2236, 24243]),\n",
       " (3158, [16394, 4257, 23086, 19948, 8097, 25407, 4366, 19627, 2269, 16587]),\n",
       " (3166, [2426, 15691, 23154, 10594, 10834, 6734, 23141, 1583, 8097, 7991]),\n",
       " (3170, [24075, 12061, 9438, 22554, 25046, 19480, 19089, 942, 1863, 8544]),\n",
       " (3277, [23154, 10594, 1583, 23141, 8316, 7991, 22848, 2492, 21920, 10908]),\n",
       " (3283, [25407, 7642, 14141, 4257, 24075, 25675, 25046, 12214, 8097, 1064]),\n",
       " (3455, [16394, 16587, 23086, 3264, 19948, 19875, 2426, 736, 12759, 5952]),\n",
       " (3842, [4502, 19874, 20308, 14684, 16394, 24355, 10418, 24070, 23086, 20553]),\n",
       " (4045, [5952, 25596, 2426, 6708, 25407, 13663, 1056, 22010, 12050, 3737]),\n",
       " (4095, [16394, 12759, 16577, 14319, 22010, 3737, 15169, 22348, 12050, 19875]),\n",
       " (4099, [7583, 6294, 18293, 23299, 17707, 23164, 1865, 21552, 4257, 3309]),\n",
       " (4582, [2426, 23154, 24075, 17156, 10792, 22848, 17209, 13136, 12050, 9701]),\n",
       " (4928, [2426, 15691, 9555, 10594, 5044, 23154, 19089, 8097, 20146, 10834]),\n",
       " (5826, [25407, 16394, 2426, 15691, 11533, 9555, 5952, 10834, 18392, 23154]),\n",
       " (5888, [24075, 14684, 9438, 4502, 20308, 24355, 5581, 7494, 25407, 12061]),\n",
       " (6076, [2426, 25407, 5952, 16394, 10792, 12050, 13928, 15691, 8097, 18392]),\n",
       " (6374, [24577, 25407, 1240, 20095, 11535, 5044, 15691, 19089, 9555, 5952]),\n",
       " (6614, [20308, 19948, 19874, 7742, 6612, 24197, 7494, 16394, 10269, 17819]),\n",
       " (6783, [4257, 16577, 12214, 4502, 24075, 2426, 20308, 7583, 25407, 10834]),\n",
       " (6858, [12214, 24075, 8097, 19874, 25675, 25407, 10269, 19089, 22798, 4257]),\n",
       " (7711, [15691, 23154, 10834, 6734, 10594, 1583, 23141, 21920, 17156, 2492]),\n",
       " (1524, [4620, 11792, 19114, 24075, 10786, 9851, 2300, 12341, 8544, 10788]),\n",
       " (1602, [4620, 12061, 11792, 2868, 6088, 15459, 10786, 9315, 3983, 23457]),\n",
       " (1520, [24075, 25675, 25407, 2426, 19089, 5942, 7494, 8894, 9555, 22121]),\n",
       " (2405, [5475, 10776, 22350, 286, 21072, 17511, 10961, 5530, 25638, 8909]),\n",
       " (558, [19709, 1825, 19010, 8097, 21552, 20345, 19089, 24059, 1863, 12466]),\n",
       " (1125, [5084, 17517, 13763, 16775, 17586, 16489, 24355, 20308, 17558, 14684]),\n",
       " (1299, [8097, 16394, 25407, 20878, 19709, 24577, 14684, 24355, 10834, 7494]),\n",
       " (1826, [1863, 2996, 6088, 8544, 11792, 12061, 25675, 19480, 3337, 18122]),\n",
       " (2166, [12061, 9591, 20496, 9851, 23536, 5717, 11452, 4966, 8920, 24410]),\n",
       " (2415, [19874, 14684, 24355, 10418, 7883, 16394, 8097, 20308, 24075, 24070]),\n",
       " (3027, [19480, 21552, 23481, 15830, 9339, 12968, 364, 16179, 8704, 11384]),\n",
       " (3036, [5044, 25407, 19709, 1825, 19010, 8097, 21552, 17229, 20345, 14684]),\n",
       " (4341, [25407, 15691, 2426, 16630, 20146, 24075, 20095, 23600, 7494, 8894]),\n",
       " (4416, [24075, 21505, 23108, 18547, 17093, 9976, 6386, 20857, 5802, 19709]),\n",
       " (4647, [17156, 1918, 11030, 25953, 13197, 25200, 25670, 1928, 3550, 24655]),\n",
       " (5536, [8097, 19326, 7657, 24210, 24577, 13371, 16626, 12720, 19709, 1230]),\n",
       " (5669, [8544, 20496, 21552, 24410, 8704, 3804, 14023, 18114, 20711, 1863]),\n",
       " (5726, [24075, 12061, 10269, 21552, 10786, 9438, 8811, 19480, 21998, 7964]),\n",
       " (5803, [24355, 14684, 19874, 17668, 18399, 4502, 20553, 10418, 18419, 4257]),\n",
       " (6068, [8097, 2426, 25407, 20345, 23154, 1240, 19709, 1825, 5044, 16770]),\n",
       " (6907, [24075, 10786, 12061, 10269, 9851, 21552, 9438, 773, 17858, 2468]),\n",
       " (6919, [25407, 23154, 9555, 10594, 15691, 6734, 18392, 10834, 25138, 1583]),\n",
       " (6942, [21552, 5119, 19480, 8544, 11792, 1863, 14291, 773, 25675, 18293]),\n",
       " (7234, [19089, 20146, 19480, 8097, 25407, 9555, 8894, 17723, 5044, 20095]),\n",
       " (164, [25407, 8322, 1240, 20095, 15691, 5044, 11535, 19709, 5952, 9555]),\n",
       " (870, [8097, 8322, 11535, 25407, 7013, 19709, 2533, 4257, 9555, 15691]),\n",
       " (976, [8097, 2426, 25407, 24577, 15691, 16577, 22121, 9555, 9370, 3803]),\n",
       " (1259, [8097, 25407, 19709, 9555, 1240, 20146, 8322, 2426, 15691, 19089]),\n",
       " (1744, [25407, 19709, 20095, 1240, 19480, 15691, 8322, 5044, 11535, 20146]),\n",
       " (1786, [2426, 8097, 19089, 15691, 9555, 5044, 22121, 20146, 8894, 24075]),\n",
       " (2044, [8097, 24577, 25407, 15691, 2236, 7013, 11535, 8322, 12214, 2533]),\n",
       " (2116, [25407, 24577, 1240, 5044, 20095, 19709, 2426, 15691, 9555, 20146]),\n",
       " (2594, [15691, 2426, 19089, 9555, 16630, 22121, 13928, 8894, 10834, 20146]),\n",
       " (2700, [8097, 15234, 24577, 4502, 19874, 7450, 16394, 24355, 8322, 15844]),\n",
       " (3071, [25407, 15691, 2426, 19089, 19709, 20146, 24075, 1240, 23154, 10834]),\n",
       " (3191, [24577, 25407, 1240, 20095, 5044, 19709, 15691, 11535, 9555, 4878]),\n",
       " (3459, [25407, 2426, 24577, 9555, 22010, 2492, 16630, 15691, 2236, 19089]),\n",
       " (4068, [5032, 9769, 8097, 3037, 18793, 8709, 4936, 9662, 19875, 15778]),\n",
       " (4535, [16630, 8431, 2533, 23481, 7494, 5522, 19089, 24075, 11091, 20095]),\n",
       " (4553, [2426, 8097, 15691, 9555, 20146, 19709, 23154, 16630, 10834, 22121]),\n",
       " (4659, [25407, 2426, 8097, 9555, 8990, 25675, 15691, 22121, 9438, 24075]),\n",
       " (5516, [20146, 25407, 15691, 19480, 16630, 7494, 20095, 22121, 23600, 2426]),\n",
       " (6195, [8097, 24577, 7013, 11535, 25407, 2236, 12214, 4257, 2533, 1240]),\n",
       " (6649, [24577, 23481, 19709, 25407, 20095, 19089, 19480, 8251, 14291, 11658]),\n",
       " (6805, [8097, 10418, 24577, 4502, 4257, 19874, 2236, 12214, 11535, 1240]),\n",
       " (6898, [25407, 24577, 9555, 12914, 2426, 20095, 5044, 1240, 5952, 16772]),\n",
       " (7694, [8097, 24577, 2236, 3037, 11535, 20095, 1240, 25407, 15691, 19480]),\n",
       " (93, [10269, 25675, 9438, 10786, 12061, 9851, 5942, 22554, 13118, 22121]),\n",
       " (3302, [5032, 7267, 23318, 8709, 4495, 9769, 22356, 20300, 8097, 13993]),\n",
       " (3897, [19874, 24355, 10269, 9438, 25407, 5581, 16394, 20308, 10418, 25675]),\n",
       " (4629, [22548, 9662, 11975, 24421, 15559, 9716, 5032, 8709, 9769, 17333]),\n",
       " (4810, [25407, 18392, 6734, 10594, 24075, 5044, 17156, 22848, 10908, 21920]),\n",
       " (6079, [14684, 2426, 19874, 24355, 20308, 11362, 12061, 18939, 4502, 8675]),\n",
       " (6280, [24075, 4257, 18793, 15778, 3037, 22835, 20553, 9662, 20202, 21085]),\n",
       " (7677, [8675, 23086, 7583, 19823, 19948, 10792, 16394, 12759, 4257, 24138]),\n",
       " (7691, [24075, 25675, 10269, 5942, 22554, 12061, 10786, 7494, 25693, 17093]),\n",
       " (3583, [22010, 19875, 16394, 7583, 21747, 19089, 22121, 8097, 16854, 12050]),\n",
       " (4259, [2426, 9555, 15691, 6734, 10834, 10594, 8097, 1583, 18392, 23141]),\n",
       " (2216, [3190, 17741, 10714, 25144, 25240, 18655, 20909, 926, 5540, 23792]),\n",
       " (141, [20553, 8395, 20308, 14684, 19874, 24355, 9438, 5078, 4502, 2533]),\n",
       " (340, [19874, 15363, 5581, 6612, 20544, 11832, 4502, 5044, 14137, 24600]),\n",
       " (399, [5952, 12050, 13663, 2426, 10792, 25407, 22798, 11533, 15169, 9769]),\n",
       " (522, [10364, 25857, 25289, 20711, 25693, 18902, 8285, 20634, 22633, 20112]),\n",
       " (532, [5078, 14684, 8395, 19874, 2459, 18419, 16324, 24711, 4502, 25407]),\n",
       " (2154, [14684, 4502, 25407, 8097, 20146, 4257, 15691, 24355, 20308, 12214]),\n",
       " (2325, [5078, 8395, 2459, 2304, 18512, 19874, 22485, 10722, 359, 3916]),\n",
       " (2473, [19874, 14684, 20308, 2459, 24355, 21085, 8769, 5078, 17668, 8430]),\n",
       " (2597, [2426, 10792, 14684, 8395, 1056, 19874, 4502, 5952, 23154, 22801]),\n",
       " (2788, [21920, 10792, 1056, 12050, 25407, 22801, 2426, 5952, 18392, 25138]),\n",
       " (3322, [14684, 4502, 5078, 18512, 20308, 4257, 5581, 24355, 18419, 17637]),\n",
       " (4375, [2459, 2868, 13541, 13663, 2426, 13918, 9555, 25675, 1834, 3037]),\n",
       " (4881, [22485, 8395, 18512, 19655, 5078, 3916, 16324, 22655, 18939, 14386]),\n",
       " (5069, [5078, 14684, 19874, 16324, 10722, 20308, 21085, 19344, 8769, 24355]),\n",
       " (5401, [2459, 8395, 17637, 359, 2835, 21920, 19874, 19655, 24711, 16324]),\n",
       " (6230, [22485, 8395, 18512, 19655, 5078, 3916, 16324, 22655, 18939, 14386]),\n",
       " (6677, [5078, 20345, 22485, 18512, 3916, 17637, 20553, 16324, 22499, 14386]),\n",
       " (7456, [15691, 23154, 10269, 6734, 12061, 22554, 1583, 19089, 21920, 9851]),\n",
       " (1127, [9007, 23127, 12313, 3469, 180, 16379, 16878, 9556, 6517, 454]),\n",
       " (676, [22121, 8894, 19709, 20146, 24075, 16630, 19480, 7494, 25407, 2426]),\n",
       " (1714, [7583, 14319, 2426, 13136, 23086, 5436, 24075, 19875, 25407, 23154]),\n",
       " (2054, [25675, 24075, 3803, 2426, 7202, 9438, 25260, 15564, 15691, 19089]),\n",
       " (2919, [16394, 5760, 5952, 7583, 12759, 10792, 12165, 21373, 23086, 13928]),\n",
       " (3326, [3373, 15957, 4982, 19633, 16516, 10792, 2236, 22801, 25834, 3497]),\n",
       " (3586, [3373, 15957, 4982, 19633, 16516, 10792, 2236, 22801, 25834, 3497]),\n",
       " (3636, [2426, 24075, 25407, 12759, 22121, 17877, 9607, 15691, 23154, 22348]),\n",
       " (4204, [2426, 25407, 6734, 9555, 13711, 10834, 15691, 9701, 10594, 23154]),\n",
       " (4270, [16394, 25407, 16577, 5581, 17070, 19874, 23895, 23991, 22010, 3215]),\n",
       " (5138, [18984, 2533, 19089, 16630, 7494, 22121, 23481, 8894, 2236, 24075]),\n",
       " (6189, [12050, 2426, 1056, 2492, 25407, 9555, 21920, 18392, 1619, 13928]),\n",
       " (2493, [3037, 18793, 5032, 4936, 8709, 15778, 9716, 9662, 8097, 22835]),\n",
       " (3589, [8097, 25407, 4878, 20146, 8894, 23141, 13928, 15691, 5044, 2426]),\n",
       " (3997, [18793, 5032, 8709, 8097, 9769, 15778, 20919, 12158, 22548, 16301]),\n",
       " (5256, [16315, 13597, 12312, 4277, 7942, 25422, 51, 6298, 19870, 22349]),\n",
       " (5849, [18793, 22548, 9716, 5032, 22356, 23318, 9662, 4936, 8709, 8097]),\n",
       " (6830, [14488, 13231, 12158, 13502, 3456, 8709, 21492, 20226, 5032, 5259]),\n",
       " (7314, [8097, 3037, 2426, 15691, 7494, 17877, 18793, 11991, 25407, 5952]),\n",
       " (494, [23154, 10834, 2426, 17156, 18392, 9701, 10594, 25407, 9555, 6878]),\n",
       " (699, [11533, 8097, 12914, 25407, 15169, 12214, 13928, 15691, 7583, 13503]),\n",
       " (1627, [25407, 12914, 7583, 2426, 23670, 16394, 3264, 23086, 8322, 10753]),\n",
       " (1675, [8097, 12914, 25407, 9673, 2426, 17877, 4017, 22121, 19089, 13711]),\n",
       " (1702, [25407, 12914, 19089, 22121, 5952, 2426, 23600, 4147, 21061, 5044]),\n",
       " (2122, [806, 23481, 6717, 14720, 5115, 16282, 6620, 9647, 19874, 5473]),\n",
       " (2284, [11533, 25407, 5952, 20095, 15691, 24577, 2426, 22801, 12914, 5044]),\n",
       " (2874, [12914, 25407, 2426, 9555, 4257, 5044, 8322, 1240, 5952, 20095]),\n",
       " (2920, [25407, 23154, 24075, 15691, 8097, 9555, 22121, 9438, 6734, 10834]),\n",
       " (2921, [8097, 12914, 8322, 11535, 22121, 25407, 6971, 7742, 5952, 7013]),\n",
       " (3018, [2426, 15691, 9555, 1583, 10834, 23154, 23141, 22121, 10594, 1240]),\n",
       " (3384, [12061, 10786, 24075, 8544, 13363, 5717, 25675, 25071, 12056, 4620]),\n",
       " (3429, [12914, 25407, 15691, 5044, 22121, 2426, 5952, 20095, 8322, 1240]),\n",
       " (3523, [25407, 15691, 6734, 9555, 10594, 10834, 8097, 16577, 1583, 8990]),\n",
       " (4240, [8097, 25407, 22121, 2426, 19089, 16630, 12914, 15691, 23600, 20095]),\n",
       " (4367, [8097, 5032, 12914, 3037, 9662, 8322, 25407, 20146, 2426, 1573]),\n",
       " (4486, [8097, 12914, 16577, 22121, 25407, 2426, 7002, 1005, 6454, 22906]),\n",
       " (4572, [8097, 12914, 8322, 22121, 25407, 6971, 7742, 5952, 7013, 20345]),\n",
       " (4574, [8097, 12914, 25407, 5044, 22121, 24075, 19089, 9555, 8322, 16394]),\n",
       " (4614, [25407, 2426, 22801, 12914, 8860, 11533, 19089, 25596, 19875, 15169]),\n",
       " (4646, [25407, 2426, 8097, 15691, 24075, 6734, 11295, 9555, 19089, 23154]),\n",
       " (4692, [2426, 15691, 23154, 9555, 10594, 8097, 10834, 18392, 1583, 10792]),\n",
       " (4893, [8097, 12914, 7013, 25407, 11535, 24075, 5952, 22121, 10753, 12214]),\n",
       " (5019, [44, 24881, 12257, 3656, 18404, 4241, 12839, 14684, 14551, 20800]),\n",
       " (5250, [8097, 12914, 8322, 16502, 1983, 22121, 25013, 4706, 25532, 6075]),\n",
       " (5402, [25407, 23154, 6734, 10594, 22010, 8316, 1583, 18452, 13928, 13711]),\n",
       " (5916, [3037, 12914, 25407, 18793, 20202, 19089, 22121, 8709, 4936, 15691]),\n",
       " (5955, [2426, 9555, 23154, 5044, 1583, 1240, 10834, 10594, 19089, 23141]),\n",
       " (6559, [25407, 15691, 6734, 10594, 10834, 18392, 7991, 22848, 13711, 16928]),\n",
       " (7191, [8097, 20146, 25407, 8894, 19089, 2426, 22445, 19709, 15691, 23600]),\n",
       " (6, [22121, 681, 2426, 24383, 3926, 4824, 19237, 16110, 10433, 22494]),\n",
       " (1462, [11189, 16654, 19315, 25675, 5195, 20713, 22286, 24994, 8529, 14871]),\n",
       " (2346, [25407, 25675, 6446, 15691, 14155, 14285, 16758, 4632, 11848, 19332]),\n",
       " (1295, [25407, 2426, 15691, 9555, 23154, 8990, 25675, 22121, 6734, 18392]),\n",
       " (1392, [23713, 22121, 25675, 11295, 25407, 25044, 12466, 11337, 20773, 6446]),\n",
       " (4775, [8990, 20800, 8716, 14551, 12108, 18404, 21772, 7011, 22811, 17625]),\n",
       " (7794, [22121, 8894, 2492, 11295, 22445, 25407, 18317, 15691, 7908, 2236]),\n",
       " (91, [8529, 19315, 14155, 22121, 25675, 14285, 16654, 16758, 6014, 6319]),\n",
       " (322, [2426, 11295, 25675, 17877, 7908, 25121, 681, 12943, 10433, 6076]),\n",
       " (881, [16577, 22121, 4351, 12601, 17877, 16772, 2426, 13393, 13102, 19033]),\n",
       " (1161, [22121, 3926, 15595, 16110, 10743, 25421, 18880, 7356, 2426, 24075]),\n",
       " (1276, [5717, 10786, 23127, 13541, 18528, 23536, 24075, 25693, 4620, 2333]),\n",
       " (1647, [25407, 15691, 9555, 22121, 23141, 23154, 1583, 18392, 10594, 10834]),\n",
       " (1788, [25407, 9438, 8894, 23154, 9555, 10269, 7494, 20146, 16630, 6734]),\n",
       " (3297, [2426, 22121, 6446, 13102, 8990, 14356, 9580, 7991, 25121, 23141]),\n",
       " (4157, [6446, 22121, 24994, 25407, 8990, 13102, 2426, 24383, 7049, 25635]),\n",
       " (6254, [25407, 23154, 15691, 16577, 24075, 6734, 9555, 19089, 9090, 10834]),\n",
       " (1092, [19709, 22121, 13928, 16630, 20146, 19089, 7494, 15691, 2533, 12409]),\n",
       " (4541, [15691, 9555, 23154, 10594, 6734, 10834, 1583, 18392, 23141, 7991]),\n",
       " (5541, [2426, 9580, 13102, 21577, 8990, 4824, 7991, 23141, 5044, 16732]),\n",
       " (7, [25693, 9769, 23155, 9081, 17168, 5665, 5976, 23687, 10363, 22862]),\n",
       " (1613, [12061, 4209, 24075, 9438, 14684, 23568, 13541, 10786, 24410, 8544]),\n",
       " (917, [2426, 25407, 8097, 19709, 22801, 24075, 20095, 14684, 9438, 19480]),\n",
       " (3124, [12061, 21552, 25071, 24075, 25675, 773, 8811, 9851, 5717, 10786]),\n",
       " (4026, [19189, 11363, 16116, 11384, 17366, 525, 22617, 12367, 11284, 25005]),\n",
       " (4388, [11089, 17305, 19189, 8430, 20982, 18512, 9769, 1358, 4521, 23788]),\n",
       " (1274, [806, 19874, 25013, 17907, 21241, 3447, 20804, 23172, 11490, 9769]),\n",
       " (4062, [23687, 9769, 12556, 17168, 489, 5976, 9081, 16257, 5563, 2956]),\n",
       " (6036, [20308, 24355, 7494, 6612, 15691, 19874, 14684, 10418, 23064, 8984]),\n",
       " (7909, [21552, 23536, 18190, 5717, 2333, 9591, 11452, 13541, 12061, 8920]),\n",
       " (4291, [25740, 17668, 14002, 6760, 6633, 13244, 3481, 5860, 17539, 25670]),\n",
       " (6455, [10418, 18107, 2697, 9438, 23004, 4417, 10722, 11436, 9018, 14879]),\n",
       " (48, [19874, 14684, 10418, 7913, 24075, 24355, 14137, 5581, 9438, 4257]),\n",
       " (4372, [6196, 6239, 929, 11521, 16818, 24224, 15296, 1321, 12018, 14283]),\n",
       " (4697, [13225, 1714, 3606, 1957, 7946, 6952, 11737, 14846, 8675, 19970]),\n",
       " (1261, [11384, 3176, 8544, 24621, 20496, 8920, 20725, 3318, 2333, 23417]),\n",
       " (41, [4209, 7639, 17322, 25693, 13541, 1158, 4620, 6812, 9842, 12056]),\n",
       " (1740, [4528, 11987, 5717, 23536, 3668, 10428, 23127, 14220, 25491, 15447]),\n",
       " (3012, [12061, 24075, 8544, 9007, 4620, 9029, 24908, 25071, 25675, 773]),\n",
       " (3193, [5717, 20496, 16083, 867, 9851, 14012, 19922, 12056, 17858, 21653]),\n",
       " (5236, [4502, 14684, 5581, 10418, 24355, 20308, 7883, 4257, 17668, 16394]),\n",
       " (6317, [2426, 15691, 9555, 23154, 10594, 1583, 10834, 6734, 23141, 18392]),\n",
       " (6451, [12061, 24075, 21552, 8811, 10269, 9438, 9851, 25693, 15034, 773]),\n",
       " (6513, [24075, 12061, 9851, 10269, 10786, 1863, 13118, 8544, 11452, 18293]),\n",
       " (6542, [8544, 12543, 4209, 12056, 4620, 25693, 10786, 9007, 477, 2468]),\n",
       " (6937, [8544, 20496, 21552, 4620, 14012, 9851, 9007, 12056, 15830, 477]),\n",
       " (7292, [5717, 18190, 23536, 8544, 9284, 19114, 23127, 10786, 2868, 15327]),\n",
       " (3024, [21747, 11378, 2283, 1231, 18544, 8336, 24791, 24002, 1514, 75]),\n",
       " (3974, [10269, 25675, 5942, 10786, 12061, 4502, 25693, 22554, 9851, 7494]),\n",
       " (5773, [8544, 11452, 25693, 12061, 10786, 14684, 2641, 7639, 24075, 24410]),\n",
       " (6272, [5717, 19114, 3668, 11792, 25491, 3176, 867, 477, 2300, 18190]),\n",
       " (7812, [20496, 21552, 4620, 25693, 5717, 141, 7639, 11384, 10009, 11452]),\n",
       " (7855, [12061, 5717, 8544, 9851, 4620, 23127, 9007, 21552, 25675, 24075]),\n",
       " (2608, [5717, 23536, 19114, 2868, 12061, 9284, 2333, 23127, 23711, 24075]),\n",
       " (6879, [19480, 20290, 22511, 20108, 12968, 15830, 23666, 10450, 3804, 10887]),\n",
       " (8, [10560, 19056, 15499, 13629, 14059, 13143, 25953, 3550, 20479, 10405]),\n",
       " (5165, [18350, 22940, 21552, 16972, 14918, 24577, 2507, 8544, 10862, 1574]),\n",
       " (514, [25407, 9555, 6734, 10594, 15691, 10834, 17156, 22848, 9701, 2492]),\n",
       " (1061, [25407, 23154, 6734, 9555, 10594, 15691, 18392, 10834, 1583, 10792]),\n",
       " (1978, [21552, 9591, 12061, 2333, 13541, 23536, 24075, 22003, 15459, 5717]),\n",
       " (1996, [2426, 25407, 9555, 10834, 15691, 17156, 18392, 1583, 21920, 22848]),\n",
       " (2144, [2426, 25407, 9555, 6734, 10834, 15691, 10594, 10792, 18452, 1583]),\n",
       " (2224, [18392, 25407, 23154, 2426, 9555, 15691, 6734, 10594, 10834, 6878]),\n",
       " (2333, [2426, 18392, 25407, 23154, 12050, 9555, 21920, 6734, 2492, 15691]),\n",
       " (2626, [2426, 25407, 6734, 9555, 10834, 15691, 1583, 17156, 18392, 21920]),\n",
       " (3251, [2426, 15691, 10594, 6734, 18392, 10834, 23141, 10908, 21920, 2492]),\n",
       " (3702, [21552, 6088, 12061, 25675, 23536, 9591, 5717, 9851, 13541, 15459]),\n",
       " (4823, [23154, 15691, 9555, 10594, 10834, 1583, 17156, 13711, 2492, 22010]),\n",
       " (4947, [2426, 25407, 9555, 15691, 6734, 10834, 18392, 10594, 21920, 1583]),\n",
       " (5054, [2426, 25407, 9555, 10594, 18392, 10834, 15691, 1583, 17156, 23141]),\n",
       " (5198, [2426, 15691, 10594, 13711, 23141, 7991, 17156, 22848, 2492, 10792]),\n",
       " (5246, [12050, 10834, 2426, 18392, 8316, 10908, 11991, 24670, 22848, 10792]),\n",
       " (5558, [18392, 2426, 23154, 15691, 25407, 8316, 13711, 24670, 22848, 10834]),\n",
       " (5678, [2426, 9555, 23154, 10594, 6734, 18392, 10834, 1583, 23141, 1240]),\n",
       " (6057, [2426, 15691, 1583, 23141, 17156, 13711, 21920, 18452, 8316, 10792]),\n",
       " (6222, [23154, 9555, 6734, 10834, 16630, 24075, 22121, 19709, 7494, 18392]),\n",
       " (6231, [25407, 6734, 9555, 15691, 18392, 10834, 1583, 17156, 9701, 7991]),\n",
       " (6525, [2426, 10594, 23154, 18392, 9555, 25407, 6734, 15691, 8316, 13711]),\n",
       " (6528, [18392, 23154, 6734, 2426, 10594, 25407, 6878, 25138, 24670, 8316]),\n",
       " (6709, [2426, 25407, 6734, 9555, 10834, 15691, 18392, 17156, 1583, 13711]),\n",
       " (6915, [18392, 23154, 6734, 2426, 25407, 10594, 6878, 15691, 10834, 25138]),\n",
       " (7051, [2426, 15691, 9555, 23154, 10594, 6734, 10834, 1583, 18392, 23141]),\n",
       " (7147, [25407, 23154, 10594, 18392, 9555, 15691, 10834, 23141, 21920, 17156]),\n",
       " (7322, [25407, 23154, 10594, 15691, 9555, 6734, 18392, 10834, 1583, 25138]),\n",
       " (1455, [13226, 8990, 14356, 25407, 15691, 10162, 2426, 5044, 22121, 2001]),\n",
       " (1652, [2426, 25407, 16772, 11295, 15691, 6446, 20146, 17877, 24075, 20410]),\n",
       " (1723, [2426, 15691, 25407, 9370, 22121, 15903, 1583, 6734, 23141, 5044]),\n",
       " (1946, [17517, 20146, 7144, 22121, 25407, 13135, 20173, 11533, 2551, 20460]),\n",
       " (1994, [9555, 15691, 23154, 10594, 6734, 1583, 18392, 8097, 22121, 1240]),\n",
       " (2398, [24075, 22554, 9438, 10786, 12061, 10269, 18293, 13118, 9851, 21552]),\n",
       " (2570, [23141, 15691, 25407, 9555, 6014, 10834, 19468, 2426, 11969, 7991]),\n",
       " (2693, [25407, 2426, 8097, 8990, 20146, 22121, 23141, 15691, 10834, 21747]),\n",
       " (2896, [2426, 9555, 15691, 23141, 8097, 23154, 5044, 10834, 10594, 6734]),\n",
       " (3342, [25407, 9555, 19089, 2426, 16630, 8894, 20095, 17723, 23154, 10834]),\n",
       " (3535, [2426, 9555, 15691, 23154, 10594, 5044, 6734, 23141, 1583, 1240]),\n",
       " (3815, [25407, 8990, 5044, 15691, 2426, 13183, 2879, 11820, 17229, 1577]),\n",
       " (3892, [2426, 15691, 9555, 10594, 23154, 10834, 23141, 6734, 1583, 5044]),\n",
       " (7197, [2426, 15691, 9555, 23154, 1583, 10834, 10594, 23141, 8097, 6734]),\n",
       " (7897, [25407, 23154, 2426, 10594, 10834, 1583, 15691, 18392, 9555, 21920]),\n",
       " (9, [9609, 11905, 6076, 19089, 19709, 23600, 2533, 13615, 10537, 8877]),\n",
       " (2603, [21552, 6088, 12061, 19480, 364, 22645, 11792, 18122, 24075, 8920]),\n",
       " (5520, [10269, 12061, 10786, 9851, 5119, 25675, 15034, 9438, 2468, 13074]),\n",
       " (3670, [10269, 23628, 6076, 867, 20933, 4927, 6088, 21552, 25675, 6239]),\n",
       " (4012, [19480, 22121, 19089, 19709, 9438, 24865, 6329, 21260, 18814, 23600]),\n",
       " (4160, [5717, 15327, 7885, 4927, 25693, 10979, 9284, 7639, 19114, 3835]),\n",
       " (4705, [22300, 2910, 4528, 10887, 3242, 12742, 11987, 2641, 10384, 21552]),\n",
       " (5318, [14684, 15368, 12103, 1803, 17525, 19484, 7839, 1787, 10444, 17938]),\n",
       " (7843, [19255, 10786, 3280, 23299, 2109, 7494, 13756, 4733, 15034, 18814]),\n",
       " (901, [8894, 19089, 8431, 18317, 23858, 10537, 11295, 2533, 24075, 3165]),\n",
       " (2740, [19089, 13615, 24075, 7494, 19480, 9438, 19709, 8894, 20146, 12409]),\n",
       " (2868, [19089, 20146, 19709, 8894, 15691, 25407, 16630, 7494, 12409, 8097]),\n",
       " (3338, [13308, 10273, 8059, 6239, 22359, 23324, 23628, 21291, 20509, 15060]),\n",
       " (3395, [19089, 8894, 23600, 153, 19480, 19709, 24075, 16630, 7494, 22121]),\n",
       " (5293, [2426, 9555, 10537, 25407, 19089, 23154, 22121, 6076, 18317, 23141]),\n",
       " (4400, [5717, 2333, 18190, 2300, 23536, 13541, 12061, 18528, 18114, 6088]),\n",
       " (46, [23536, 19114, 4620, 18190, 24075, 11792, 23711, 12061, 13541, 23127]),\n",
       " (677, [10269, 9438, 25675, 12061, 9851, 15709, 5942, 10786, 13118, 5562]),\n",
       " (2423, [12061, 5717, 24075, 23536, 4620, 10786, 9851, 2333, 2868, 1863]),\n",
       " (3786, [1959, 5284, 9520, 15677, 10159, 24075, 19007, 8094, 4452, 14035]),\n",
       " (3810, [12056, 15145, 11796, 9508, 8766, 25071, 23700, 14012, 21731, 20496]),\n",
       " (5146, [15709, 9851, 275, 8158, 8877, 18146, 24075, 7174, 19480, 10269]),\n",
       " (5301, [24075, 9851, 10786, 9438, 8811, 10269, 5717, 23711, 25071, 13118]),\n",
       " (6360, [10269, 12061, 25675, 9438, 10786, 19480, 5942, 7494, 23481, 8894]),\n",
       " (7824, [14684, 18512, 19792, 19874, 4502, 24355, 19089, 9438, 19709, 24075]),\n",
       " (10, [23026, 22923, 24896, 16921, 3070, 1920, 21278, 13426, 297, 5091]),\n",
       " (211, [10786, 153, 24075, 7494, 16195, 19089, 17257, 25675, 9637, 2448]),\n",
       " (563, [15562, 4502, 18987, 14291, 14023, 24075, 19874, 2638, 6366, 364]),\n",
       " (2559, [9934, 5664, 20308, 14023, 25868, 14291, 16218, 364, 12906, 773]),\n",
       " (4466, [15830, 8544, 11452, 19480, 24075, 11384, 525, 22511, 1863, 12061]),\n",
       " (2103, [16577, 16918, 12601, 679, 17994, 14319, 22731, 15451, 15331, 19875]),\n",
       " (4968, [4351, 5690, 22564, 2939, 11584, 7452, 6164, 14328, 9708, 12622]),\n",
       " (4979, [6446, 16577, 13226, 22121, 15903, 20410, 12601, 1583, 2426, 3812]),\n",
       " (5783, [22040, 20475, 11788, 16224, 15451, 10151, 11779, 4871, 13016, 6774]),\n",
       " (7563, [15196, 2426, 22121, 9438, 9992, 23141, 20146, 10834, 5044, 14356]),\n",
       " (2072, [25693, 24075, 12061, 7964, 13118, 6041, 10786, 9438, 15564, 23299]),\n",
       " (590, [10786, 153, 25693, 16195, 17257, 9438, 7494, 24075, 24896, 23600]),\n",
       " (4787, [11792, 5717, 23536, 23127, 12061, 24075, 18528, 13541, 18190, 2300]),\n",
       " (11, [15013, 22378, 12951, 20334, 23962, 14479, 16264, 8296, 9177, 1817]),\n",
       " (3230, [3025, 25191, 23959, 19427, 6141, 15013, 22378, 19868, 20334, 12951]),\n",
       " (4991, [2154, 25191, 23959, 19427, 6141, 23035, 19010, 19868, 18814, 5998]),\n",
       " (1886, [11533, 15169, 25407, 13503, 11421, 2236, 8860, 20974, 4837, 5952]),\n",
       " (2447, [14012, 4812, 25878, 3804, 23457, 1876, 25928, 20496, 5717, 9218]),\n",
       " (3042, [9438, 2705, 17467, 10786, 3805, 22500, 296, 13080, 1081, 24377]),\n",
       " (7644, [9438, 10786, 10363, 3497, 17741, 16195, 17093, 15877, 3432, 25693]),\n",
       " (3227, [25191, 2154, 3025, 23959, 19427, 6141, 19868, 5865, 21830, 22956]),\n",
       " (4371, [3025, 2154, 23959, 19427, 6141, 15013, 22378, 19868, 20334, 12951]),\n",
       " (3206, [20308, 24197, 19874, 18399, 7494, 11083, 14684, 24355, 20013, 21417]),\n",
       " (2654, [3037, 11855, 18793, 17724, 13954, 9747, 16871, 21492, 8709, 11519]),\n",
       " (789, [10792, 16738, 25407, 2426, 7291, 8860, 12050, 5952, 21920, 2492]),\n",
       " (2253, [19627, 21630, 11152, 9498, 4298, 14961, 21830, 19157, 21796, 17472]),\n",
       " (3434, [3025, 2154, 25191, 23959, 21830, 19427, 6141, 14961, 19868, 11405]),\n",
       " (5444, [13944, 18317, 19089, 8894, 23858, 14383, 19332, 22406, 16195, 18798]),\n",
       " (2125, [24075, 6294, 942, 3803, 25675, 12061, 25071, 22554, 21552, 11658]),\n",
       " (3273, [22128, 5380, 19620, 18293, 22991, 18804, 21552, 21773, 20749, 6632]),\n",
       " (2975, [16394, 9607, 1840, 23991, 11197, 20937, 12759, 15169, 8984, 12509]),\n",
       " (4960, [22835, 14961, 21830, 11405, 8589, 7753, 3041, 24538, 18793, 20202]),\n",
       " (955, [19874, 24355, 20308, 4502, 10418, 5581, 20553, 4257, 7494, 9438]),\n",
       " (1257, [20795, 23324, 19007, 8296, 20239, 5078, 4888, 16195, 5929, 24043]),\n",
       " (2781, [2426, 9555, 15691, 10594, 8097, 23141, 23154, 10834, 6734, 5044]),\n",
       " (4079, [3025, 25621, 16264, 3257, 1745, 2154, 14479, 25191, 23959, 20001]),\n",
       " (6926, [24075, 25675, 10269, 5942, 22554, 12061, 10786, 7494, 25693, 19089]),\n",
       " (7005, [8296, 13067, 16320, 20795, 13944, 24172, 16232, 25827, 7792, 20553]),\n",
       " (7052, [23004, 11083, 15504, 9769, 4785, 7714, 2236, 22801, 17668, 12338]),\n",
       " (3051, [19837, 2990, 4136, 12745, 20243, 741, 7374, 8017, 4340, 13826]),\n",
       " (2357, [477, 24015, 23127, 19451, 18132, 15709, 4620, 12543, 23568, 1611]),\n",
       " (3803, [11987, 5717, 21552, 12742, 13541, 23536, 25491, 18190, 23666, 3804]),\n",
       " (12, [19114, 20750, 21854, 3176, 3668, 12742, 2996, 2300, 9007, 12313]),\n",
       " (1204, [5717, 13541, 23536, 2333, 18190, 23711, 6088, 18528, 12061, 9029]),\n",
       " (1797, [19114, 23127, 4811, 5593, 3804, 22602, 21854, 2300, 25491, 23457]),\n",
       " (2611, [5717, 19114, 10786, 12061, 23457, 24075, 18190, 10428, 3804, 454]),\n",
       " (2662, [5717, 2333, 13541, 18190, 10786, 18528, 6088, 2868, 23711, 23127]),\n",
       " (2910, [19114, 25491, 11792, 10786, 18528, 3804, 867, 9556, 23536, 12061]),\n",
       " (2952, [5717, 13541, 2333, 23127, 18528, 18190, 23711, 19114, 24075, 11792]),\n",
       " (3180, [5717, 12061, 19114, 13541, 23711, 2300, 18190, 10786, 9284, 2868]),\n",
       " (3877, [5717, 13541, 12341, 18190, 18114, 20472, 20750, 9284, 23536, 8530]),\n",
       " (3930, [23536, 5717, 18190, 18528, 12061, 10450, 21854, 3983, 23711, 4620]),\n",
       " (5149, [5717, 23536, 2333, 18190, 12061, 6088, 21854, 23457, 2300, 23127]),\n",
       " (5354, [5717, 18190, 23536, 6088, 2333, 19114, 2300, 10786, 23457, 2868]),\n",
       " (5920, [22300, 5717, 23536, 10887, 23666, 21552, 10786, 23711, 23127, 14220]),\n",
       " (6391, [23127, 13541, 5717, 12061, 3668, 10786, 23457, 23536, 19079, 13837]),\n",
       " (7558, [19114, 23536, 11792, 5717, 25491, 12742, 21552, 24075, 23127, 780]),\n",
       " (7758, [23127, 2300, 3668, 24075, 5593, 19114, 9007, 3804, 25491, 9556]),\n",
       " (1441, [24546, 9526, 19061, 3780, 21505, 13433, 23132, 7820, 18468, 7839]),\n",
       " (3843, [19061, 21505, 24199, 23799, 24210, 23108, 5101, 7820, 5251, 21616]),\n",
       " (5828, [9438, 18343, 24377, 9976, 14528, 5802, 24075, 21248, 17093, 19709]),\n",
       " (6058, [24546, 19709, 9438, 20146, 4602, 24075, 24199, 19061, 9976, 23108]),\n",
       " (6821, [24546, 9526, 21505, 9438, 8854, 20857, 18547, 6386, 5447, 23108]),\n",
       " (5587, [9438, 24546, 11623, 20857, 17093, 18547, 9976, 8622, 25209, 24075]),\n",
       " (5820, [21552, 10786, 16083, 24075, 25071, 12056, 9851, 17858, 13363, 12061]),\n",
       " (7818, [24075, 9438, 19089, 18528, 19114, 12061, 5942, 23799, 25675, 19480]),\n",
       " (13, [2426, 17229, 12601, 15691, 6446, 16772, 25407, 23154, 20969, 22121]),\n",
       " (36, [2426, 25407, 15691, 6734, 10834, 10594, 23141, 1583, 18392, 22121]),\n",
       " (828, [2426, 11533, 25407, 13928, 15691, 22121, 15169, 12050, 23154, 24075]),\n",
       " (2682, [25407, 2426, 9555, 10594, 18392, 15691, 10792, 2492, 21920, 1583]),\n",
       " (3107, [19089, 11366, 19332, 6266, 11900, 22010, 2354, 7094, 13928, 13944]),\n",
       " (5230, [7583, 16394, 14319, 24379, 13136, 24075, 25596, 16577, 18899, 8315]),\n",
       " (6724, [6708, 2236, 25596, 13503, 11533, 3737, 5952, 12050, 1056, 13928]),\n",
       " (7809, [2426, 25407, 17229, 12601, 15691, 6446, 16772, 23154, 20969, 22121]),\n",
       " (160, [16577, 22121, 12601, 22731, 5930, 11197, 1076, 679, 681, 1022]),\n",
       " (375, [2426, 9555, 10594, 10834, 22121, 1583, 5044, 23141, 17156, 18392]),\n",
       " (601, [7494, 20146, 24075, 19480, 23600, 25407, 17723, 2426, 9438, 2533]),\n",
       " (921, [2426, 15691, 16772, 25407, 22121, 11533, 7363, 8097, 17229, 12601]),\n",
       " (1383, [25407, 22121, 2426, 8894, 15691, 16630, 13928, 24075, 681, 21920]),\n",
       " (1518, [2426, 17229, 12601, 16772, 6446, 5044, 25407, 22121, 8990, 23141]),\n",
       " (1733, [2426, 15691, 9555, 23154, 10594, 8097, 25596, 10834, 6734, 24075]),\n",
       " (1988, [2426, 12601, 16577, 15691, 17229, 6446, 16772, 25407, 20969, 22121]),\n",
       " (2506, [2426, 23154, 19468, 12601, 16772, 20969, 15691, 25407, 17229, 6446]),\n",
       " (2989, [2426, 17229, 12601, 15691, 6446, 16772, 25407, 20969, 22121, 19468]),\n",
       " (3498, [25407, 2426, 22121, 5044, 9555, 23154, 8097, 1583, 10834, 23141]),\n",
       " (3571, [2426, 16772, 6734, 17229, 12601, 22121, 15691, 6446, 25407, 20969]),\n",
       " (4037, [6076, 2492, 15595, 25407, 10792, 5469, 16738, 10269, 12050, 2426]),\n",
       " (4297, [25675, 24075, 21552, 3803, 22128, 19564, 25071, 25260, 12061, 18804]),\n",
       " (4471, [2426, 23154, 15691, 6734, 9555, 10594, 10834, 23141, 1583, 8097]),\n",
       " (4679, [2426, 15691, 9555, 6734, 23154, 10594, 10834, 24075, 8894, 5044]),\n",
       " (4739, [25675, 22554, 24075, 22121, 561, 25260, 19564, 15564, 4241, 25407]),\n",
       " (4780, [2426, 22121, 15691, 17229, 12601, 6446, 16772, 25407, 20969, 14356]),\n",
       " (5197, [10269, 9438, 22554, 10786, 12061, 9851, 2426, 5942, 13118, 25407]),\n",
       " (5559, [25407, 15691, 2426, 8990, 9555, 16772, 22121, 5044, 6734, 12601]),\n",
       " (5685, [22121, 2426, 6734, 20969, 17229, 12601, 15691, 6446, 16772, 25407]),\n",
       " (5799, [25407, 23154, 15691, 10834, 1583, 18392, 7991, 23141, 21920, 16906]),\n",
       " (6033, [25407, 2426, 9555, 16772, 23154, 8990, 8097, 22121, 10834, 1240]),\n",
       " (6061, [25407, 22121, 16577, 15691, 8097, 20146, 2426, 16772, 6446, 8990]),\n",
       " (6350, [11295, 2426, 2236, 25407, 15691, 16630, 25675, 20146, 8894, 19332]),\n",
       " (6613, [15691, 2426, 25407, 23141, 23154, 6446, 16772, 17229, 7991, 9555]),\n",
       " (6617, [25407, 2426, 12050, 5952, 11533, 4541, 5044, 22121, 21747, 16577]),\n",
       " (6619, [15196, 3469, 13837, 3835, 10269, 3668, 15642, 22645, 17546, 12319]),\n",
       " (6795, [2426, 9555, 15691, 10834, 1583, 17156, 18392, 10792, 10908, 23141]),\n",
       " (6990, [22121, 25407, 17229, 16772, 6446, 12601, 2426, 15691, 20969, 12700]),\n",
       " (7352, [2426, 3812, 9992, 20999, 12601, 25407, 17229, 21747, 18798, 9673]),\n",
       " (7729, [25407, 15691, 23154, 9555, 10594, 22121, 6734, 24075, 7494, 10834]),\n",
       " (14, [18404, 18499, 9165, 12108, 11337, 20773, 20800, 23050, 6995, 3669]),\n",
       " (216, [5763, 14285, 19489, 16758, 6014, 25675, 16188, 18721, 1968, 6510]),\n",
       " (4556, [2426, 5763, 15691, 14141, 4147, 25675, 14155, 9555, 23154, 19332]),\n",
       " (1846, [18500, 21747, 10162, 22873, 8716, 25675, 3656, 20636, 19891, 21375]),\n",
       " (3244, [22286, 25675, 8716, 25407, 18404, 11848, 12108, 6868, 20800, 3479]),\n",
       " (3785, [11169, 23309, 21747, 2426, 7397, 21375, 22554, 24075, 681, 18499]),\n",
       " (4745, [9438, 25407, 10269, 23154, 9555, 15691, 10786, 22121, 12061, 10594]),\n",
       " (6473, [9438, 10269, 10786, 12061, 9851, 561, 13118, 5942, 18293, 2426]),\n",
       " (7550, [24075, 25675, 21747, 11730, 22554, 21375, 11363, 15748, 23850, 8716]),\n",
       " (577, [8990, 25407, 25675, 22121, 11169, 24075, 2426, 22554, 681, 25044]),\n",
       " (15, [24546, 1798, 25766, 17130, 20857, 1871, 12643, 13319, 21505, 21616]),\n",
       " (1672, [12061, 8544, 25046, 24075, 25071, 942, 1863, 10786, 4927, 6294]),\n",
       " (2598, [19007, 24546, 9438, 5915, 18547, 1798, 21248, 5889, 13552, 21505]),\n",
       " (4227, [7839, 4032, 304, 21505, 21248, 23481, 24154, 1244, 14114, 3527]),\n",
       " (4641, [1798, 18249, 3527, 4127, 377, 19709, 24546, 14528, 21616, 5802]),\n",
       " (7696, [9438, 24075, 19709, 14528, 20857, 5802, 5251, 9976, 24377, 23285]),\n",
       " (2280, [23285, 21248, 6386, 3527, 24075, 8854, 17823, 7839, 3288, 12230]),\n",
       " (5844, [21505, 24199, 10347, 377, 12087, 21616, 17093, 9526, 24377, 13810]),\n",
       " (5986, [9976, 3780, 19061, 18944, 23735, 25766, 10249, 10380, 24546, 21617]),\n",
       " (892, [9438, 24546, 10269, 19709, 5942, 25675, 12230, 20308, 11623, 13552]),\n",
       " (5219, [19007, 24546, 20857, 9438, 1798, 8622, 18343, 1205, 17374, 20276]),\n",
       " (253, [24075, 2533, 19007, 17723, 19709, 5756, 19089, 13615, 12409, 8431]),\n",
       " (959, [19007, 1745, 25766, 1798, 14035, 20212, 341, 16785, 17323, 762]),\n",
       " (1106, [19874, 14684, 10418, 11623, 7450, 1714, 8622, 17668, 6, 24945]),\n",
       " (1451, [7839, 21624, 19007, 158, 11931, 7993, 20212, 9135, 4032, 21505]),\n",
       " (2294, [19007, 5284, 18656, 24075, 20212, 9520, 13433, 17400, 25766, 3716]),\n",
       " (2525, [10269, 9438, 25675, 12061, 5942, 9851, 10786, 13118, 25407, 19709]),\n",
       " (3637, [24546, 20857, 5915, 19007, 1205, 21505, 12230, 18547, 21248, 9976]),\n",
       " (5768, [24546, 10335, 1959, 9135, 19007, 1798, 24710, 5915, 20212, 18547]),\n",
       " (6643, [19007, 25766, 8622, 5302, 15832, 24945, 7818, 11623, 20212, 16785]),\n",
       " (6822, [17723, 3288, 644, 377, 14528, 19445, 10218, 8854, 19709, 4343]),\n",
       " (6849, [10269, 9438, 25675, 14684, 4502, 10786, 9851, 12061, 5942, 19089]),\n",
       " (6920, [24546, 13552, 20857, 9438, 11702, 5284, 13433, 7212, 25001, 11623]),\n",
       " (119, [4502, 19874, 14684, 9438, 18419, 19189, 10418, 5581, 24355, 24014]),\n",
       " (1976, [13552, 24985, 24839, 25596, 23067, 17400, 8683, 11499, 341, 5284]),\n",
       " (4716, [12061, 24075, 19114, 9851, 10786, 5717, 4927, 12742, 21552, 10269]),\n",
       " (5485, [25407, 25675, 9555, 23154, 12061, 19089, 10786, 22554, 10834, 5942]),\n",
       " (7002, [9438, 13552, 17400, 18778, 17041, 15527, 19459, 1205, 19007, 11716]),\n",
       " (455, [9438, 25675, 12061, 9851, 13118, 19089, 10786, 19709, 15034, 13433]),\n",
       " (829, [24075, 9438, 15830, 20857, 9851, 13797, 24546, 17130, 11658, 5717]),\n",
       " (2542, [24075, 9438, 7494, 10269, 25675, 25407, 10786, 19480, 20146, 19709]),\n",
       " (4001, [24546, 11931, 18547, 12087, 17093, 6096, 13810, 19007, 6, 11623]),\n",
       " (74, [24546, 11710, 23600, 24945, 7212, 23285, 13433, 3927, 18343, 17093]),\n",
       " (811, [2426, 15691, 24075, 23154, 19709, 10834, 6734, 9438, 1583, 19089]),\n",
       " (1041, [3966, 9438, 7212, 7992, 24546, 9752, 3927, 7818, 6745, 13433]),\n",
       " (3590, [1798, 21616, 377, 17889, 20857, 9976, 17093, 14035, 14528, 5802]),\n",
       " (5100, [12087, 10573, 11702, 24199, 3527, 10335, 18249, 13319, 24075, 25494]),\n",
       " (6768, [24546, 13552, 19459, 4346, 8854, 17400, 20857, 11702, 3463, 24985]),\n",
       " (130, [24546, 20857, 7839, 12230, 1205, 21505, 1803, 13433, 1745, 20276]),\n",
       " (512, [20857, 1205, 12230, 21505, 5915, 10852, 3177, 5802, 18547, 7604]),\n",
       " (1088, [24075, 24355, 17668, 25675, 14684, 1798, 21417, 5942, 10269, 7494]),\n",
       " (2677, [20857, 9438, 1745, 12230, 18547, 24546, 18343, 21624, 1959, 1798]),\n",
       " (2725, [20857, 21624, 1798, 21671, 17130, 14506, 1205, 8805, 16124, 18343]),\n",
       " (4585, [24075, 25675, 12061, 9438, 10269, 2426, 10786, 15564, 15691, 8811]),\n",
       " (4721, [24546, 21248, 377, 18547, 11931, 5915, 5802, 1700, 14528, 21505]),\n",
       " (5110, [20857, 21624, 2509, 1798, 21671, 17130, 14506, 1205, 8805, 16124]),\n",
       " (5143, [24546, 21248, 20857, 22116, 5915, 1205, 1803, 20403, 12230, 7818]),\n",
       " (5406, [9438, 23127, 24075, 19089, 19709, 4535, 11452, 19480, 10269, 17093]),\n",
       " (5876, [1205, 7839, 1959, 24355, 1745, 13552, 1803, 25209, 9520, 5915]),\n",
       " (6075, [13552, 20857, 21624, 24355, 17130, 1745, 24415, 9438, 11623, 1798]),\n",
       " (6325, [1205, 1959, 19709, 12230, 25209, 18547, 8805, 8854, 9520, 7818]),\n",
       " (6812, [20857, 21624, 16005, 1798, 21671, 17130, 7604, 16503, 14373, 14506]),\n",
       " (7222, [5119, 8544, 25693, 773, 6239, 3804, 5717, 867, 11792, 7639]),\n",
       " (7832, [9976, 24546, 21505, 5889, 4127, 18459, 12230, 20276, 24154, 23108]),\n",
       " (348, [10418, 14684, 19874, 1714, 7450, 4502, 5581, 15363, 17668, 9769]),\n",
       " (358, [9851, 14012, 24075, 15830, 477, 12061, 8544, 12056, 19114, 773]),\n",
       " (456, [4502, 14684, 19874, 24355, 20308, 1714, 8304, 11737, 7883, 18419]),\n",
       " (3920, [19874, 8395, 14684, 5078, 4502, 10418, 20308, 8819, 5581, 17668]),\n",
       " (4926, [15234, 4502, 10418, 11459, 18949, 1918, 20325, 13194, 10017, 10722]),\n",
       " (6533, [14684, 4502, 18419, 6208, 25407, 10418, 19874, 7450, 16394, 15363]),\n",
       " (4660, [19874, 14684, 10418, 24355, 20308, 5581, 4257, 6612, 17668, 15363]),\n",
       " (6766, [14528, 5251, 24075, 21505, 19007, 1798, 5915, 6, 19709, 4127]),\n",
       " (297, [12087, 3527, 21505, 17323, 13552, 9135, 13319, 18547, 11931, 7839]),\n",
       " (567, [24546, 19709, 4602, 13810, 12087, 24075, 21616, 17723, 18547, 14528]),\n",
       " (1479, [3527, 377, 24075, 5915, 18547, 12087, 10335, 19709, 12230, 21248]),\n",
       " (1614, [9438, 10269, 21505, 9976, 6096, 13319, 25675, 23108, 11931, 5802]),\n",
       " (4728, [24546, 19007, 377, 9135, 1798, 24075, 21505, 18547, 6096, 5915]),\n",
       " (4824, [5546, 2641, 5119, 2468, 18872, 24075, 15145, 16189, 23127, 5906]),\n",
       " (4977, [24075, 9438, 22554, 12061, 10786, 10269, 9851, 5942, 13118, 18293]),\n",
       " (5620, [13541, 5717, 18190, 23457, 11764, 6088, 15459, 15335, 18528, 4620]),\n",
       " (7416, [24075, 9438, 22554, 10786, 12061, 10269, 13118, 5284, 5942, 18293]),\n",
       " (836, [24546, 11623, 1745, 6, 5284, 9438, 23285, 9520, 13552, 10159]),\n",
       " (4786, [9438, 24075, 24546, 19709, 5942, 19480, 5119, 10269, 20889, 7494]),\n",
       " (5208, [10269, 25675, 5942, 12061, 10786, 22554, 9851, 15564, 13118, 23799]),\n",
       " (5703, [24075, 10269, 5942, 22121, 25675, 23799, 19089, 20146, 12061, 10786]),\n",
       " (7138, [5284, 13433, 20013, 24075, 17668, 21624, 11726, 646, 21417, 24546]),\n",
       " (16, [14684, 9018, 4502, 7913, 13586, 5952, 3580, 18452, 11680, 9769]),\n",
       " (434, [4620, 15327, 11716, 878, 12341, 5717, 15335, 22300, 18190, 12742]),\n",
       " (227, [4502, 14684, 19874, 20308, 9769, 4257, 11832, 11737, 7883, 6612]),\n",
       " (311, [3037, 18793, 14684, 4936, 5952, 8709, 4502, 7267, 19874, 51]),\n",
       " (1889, [19874, 4502, 14684, 18512, 14137, 25693, 7883, 9769, 18597, 11411]),\n",
       " (2298, [19874, 14684, 7883, 10418, 5581, 24355, 9438, 24075, 19189, 7494]),\n",
       " (2328, [2426, 5581, 15691, 24075, 24355, 9555, 4257, 10418, 8097, 5044]),\n",
       " (2729, [14684, 19874, 7883, 8544, 10418, 24355, 24075, 5581, 14137, 19189]),\n",
       " (3354, [2426, 25407, 23154, 15691, 18392, 22010, 10792, 10594, 12050, 6734]),\n",
       " (5975, [22121, 8894, 13928, 19089, 18317, 2236, 18984, 2533, 15691, 5115]),\n",
       " (7599, [25407, 2426, 18392, 15691, 24075, 10418, 10834, 6734, 5952, 21920]),\n",
       " (1626, [12407, 18392, 15256, 4106, 8207, 20679, 1905, 25312, 4792, 3230]),\n",
       " (4222, [10019, 15001, 7779, 13294, 1334, 8207, 19980, 23084, 1773, 5612]),\n",
       " (898, [16301, 20919, 3037, 18793, 7030, 1863, 11855, 9293, 17168, 21533]),\n",
       " (2582, [14684, 24075, 4502, 19480, 25407, 24355, 19874, 21552, 4257, 11658]),\n",
       " (687, [19709, 19089, 24075, 7494, 17723, 23600, 21552, 12409, 15830, 17760]),\n",
       " (1036, [19709, 17723, 19480, 19089, 8431, 24075, 7494, 12409, 6076, 16630]),\n",
       " (1055, [9851, 23127, 25675, 18528, 773, 13541, 11792, 25071, 9007, 23536]),\n",
       " (2021, [24075, 25693, 17257, 9438, 2533, 8431, 12061, 19089, 10786, 17723]),\n",
       " (3558, [24075, 24908, 5717, 4205, 8251, 8544, 19480, 4927, 9851, 12061]),\n",
       " (3593, [2426, 9555, 8097, 22121, 20146, 23154, 16630, 19709, 24075, 13928]),\n",
       " (3962, [10269, 25675, 9438, 9851, 10786, 12061, 5942, 4927, 19480, 7494]),\n",
       " (4313, [24075, 19709, 9438, 19089, 17723, 10269, 7494, 21552, 12061, 23481]),\n",
       " (4370, [19089, 19709, 23600, 17723, 7494, 20146, 16630, 23481, 8894, 2533]),\n",
       " (4827, [19709, 8894, 12409, 2533, 19480, 19089, 24075, 7494, 23481, 23600]),\n",
       " (5244, [25407, 2426, 19089, 10834, 24075, 7494, 10594, 22121, 18392, 13928]),\n",
       " (5385, [2426, 9555, 15691, 23154, 10594, 25675, 10269, 16630, 18392, 1583]),\n",
       " (5531, [19089, 18984, 7494, 22121, 2533, 24075, 23481, 19709, 20146, 8431]),\n",
       " (5676, [12061, 23127, 19114, 23536, 23711, 2333, 18190, 4620, 9851, 9029]),\n",
       " (7227, [20146, 7494, 22121, 19089, 12409, 16630, 8894, 24075, 17723, 2533]),\n",
       " (7295, [19709, 24075, 20212, 9438, 7494, 17723, 16562, 2459, 19480, 23285]),\n",
       " (7532, [15691, 10594, 6734, 10834, 18392, 1583, 17156, 23141, 22848, 10792]),\n",
       " (1414, [19089, 16630, 7494, 22121, 2533, 19480, 23600, 23481, 17723, 8431]),\n",
       " (3853, [7494, 19089, 23600, 20146, 8894, 24075, 17723, 16630, 2533, 19480]),\n",
       " (4283, [24075, 9438, 22554, 10786, 10269, 12061, 2426, 25407, 18293, 19089]),\n",
       " (4927, [18984, 12409, 2533, 8431, 22121, 12466, 23481, 20146, 2665, 17723]),\n",
       " (21, [23778, 4821, 3875, 19135, 18788, 13460, 19249, 17586, 25224, 21030]),\n",
       " (946, [23204, 3325, 18234, 19875, 7613, 22861, 14875, 15329, 23072, 2274]),\n",
       " (3958, [10269, 9438, 25675, 10786, 5942, 12061, 22121, 9851, 25693, 22554]),\n",
       " (7133, [24075, 8984, 4945, 5952, 9438, 8860, 13663, 22801, 4535, 20863]),\n",
       " (519, [9438, 25675, 5942, 12061, 10786, 19089, 25407, 9851, 2426, 22554]),\n",
       " (1277, [18793, 5032, 15182, 9662, 8709, 22548, 9769, 15778, 8097, 4495]),\n",
       " (1505, [18793, 497, 8097, 9769, 4936, 22356, 15910, 15778, 6689, 21921]),\n",
       " (3380, [24421, 729, 16929, 17333, 9241, 1863, 9405, 22548, 15466, 25618]),\n",
       " (4350, [15182, 9662, 5032, 20339, 21921, 19426, 21321, 9675, 5338, 14488]),\n",
       " (5089, [3037, 18793, 22548, 4936, 8097, 497, 15778, 14488, 9716, 9769]),\n",
       " (7640, [3037, 5032, 9662, 8709, 51, 21921, 13993, 15910, 18793, 24235]),\n",
       " (7674, [8709, 3037, 9662, 13424, 18793, 15182, 8558, 497, 22548, 51]),\n",
       " (5509, [7851, 12847, 17741, 8511, 121, 10714, 25144, 25240, 3190, 15187]),\n",
       " (940, [19480, 12409, 19089, 23600, 19709, 17723, 6198, 2533, 8894, 16630]),\n",
       " (6747, [21954, 22121, 16651, 3744, 70, 8097, 24075, 4147, 9662, 24132]),\n",
       " (600, [11295, 8894, 19089, 20146, 18317, 16630, 24075, 23600, 18984, 2426]),\n",
       " (6331, [25407, 19089, 5044, 1240, 12914, 19709, 15691, 24577, 18984, 9555]),\n",
       " (7341, [20146, 22121, 8894, 12409, 19480, 16630, 19709, 7494, 18984, 24075]),\n",
       " (3858, [19874, 7494, 19089, 5952, 14684, 2426, 5032, 2236, 25407, 15169]),\n",
       " (146, [24075, 25675, 10269, 5942, 12061, 10786, 22554, 13118, 7494, 9851]),\n",
       " (254, [9438, 25675, 12061, 5942, 10786, 9851, 15034, 13118, 25407, 22554]),\n",
       " (383, [9438, 12061, 9851, 22554, 5942, 13118, 21552, 15564, 19401, 23799]),\n",
       " (488, [24075, 9438, 5942, 25675, 12061, 15034, 8811, 19089, 23799, 10786]),\n",
       " (497, [9438, 12061, 2426, 9851, 22554, 15691, 5942, 13118, 25260, 9555]),\n",
       " (702, [24075, 9438, 5942, 12061, 25675, 19089, 7494, 15034, 8811, 10786]),\n",
       " (709, [12061, 24075, 9851, 5717, 10786, 10269, 21552, 25071, 25693, 25675]),\n",
       " (710, [24075, 9438, 5942, 25675, 25303, 2126, 1286, 12061, 5733, 20986]),\n",
       " (741, [10269, 25675, 12061, 22554, 9851, 10786, 22121, 7494, 19089, 15564]),\n",
       " (784, [12061, 10786, 5942, 9851, 13118, 15564, 21552, 3803, 18293, 25260]),\n",
       " (809, [24075, 25675, 12061, 10786, 7494, 22554, 13118, 19089, 15564, 9851]),\n",
       " (832, [9438, 25675, 12061, 5942, 10786, 9851, 15034, 13118, 22554, 19089]),\n",
       " (970, [12061, 25675, 9438, 10786, 9851, 15034, 5717, 5942, 6088, 22359]),\n",
       " (1012, [9438, 12061, 10786, 22554, 9851, 5942, 13118, 25260, 21552, 15564]),\n",
       " (1123, [24075, 9438, 5942, 25675, 12061, 15034, 19089, 8811, 23799, 10786]),\n",
       " (1271, [24075, 9438, 5942, 25675, 12061, 15034, 19089, 8811, 23799, 10786]),\n",
       " (1342, [19874, 24355, 4502, 22121, 18419, 24075, 16394, 20308, 10418, 5581]),\n",
       " (1360, [24075, 9438, 25675, 5942, 12061, 13118, 25071, 9851, 15034, 19089]),\n",
       " (1366, [9438, 25407, 22554, 2426, 12061, 10786, 5942, 19089, 15691, 9851]),\n",
       " (1487, [24075, 9438, 5942, 25675, 12061, 15034, 19089, 8811, 23799, 10786]),\n",
       " (1548, [25675, 9438, 12061, 10786, 22554, 15564, 9851, 7202, 13118, 25071]),\n",
       " (1629, [9438, 25675, 12061, 5942, 10786, 9851, 19089, 15034, 13118, 22554]),\n",
       " (1695, [12061, 10786, 9851, 22554, 25693, 5942, 13118, 21552, 5717, 23127]),\n",
       " (1777, [10269, 25675, 12061, 10786, 5942, 22554, 9851, 13118, 19089, 7494]),\n",
       " (1817, [9438, 25675, 12061, 5942, 10786, 9851, 15034, 13118, 22554, 19089]),\n",
       " (1997, [24075, 9438, 5942, 12061, 25675, 8811, 10786, 15034, 1888, 7964]),\n",
       " (2001, [24075, 25675, 12061, 22554, 7494, 10786, 13118, 25693, 23799, 15564]),\n",
       " (2034, [25675, 9438, 12061, 10786, 3803, 22554, 5942, 9851, 7202, 15034]),\n",
       " (2043, [9438, 25675, 12061, 5942, 10786, 9851, 15034, 13118, 22554, 19089]),\n",
       " (2046, [9438, 25675, 12061, 5942, 10786, 9851, 15034, 13118, 22554, 19089]),\n",
       " (2085, [14315, 8558, 14488, 16521, 10489, 13089, 13182, 1928, 3550, 24655]),\n",
       " (2200, [24075, 9438, 5942, 25675, 12061, 8811, 15034, 23799, 7494, 9851]),\n",
       " (2326, [9438, 25675, 23600, 5942, 7494, 19480, 12061, 9851, 10786, 19709]),\n",
       " (2336, [24075, 9438, 25675, 3037, 5942, 8709, 12158, 19089, 17517, 8229]),\n",
       " (2337, [9438, 25675, 10786, 9851, 5942, 8811, 15034, 13118, 4927, 15564]),\n",
       " (2365, [9438, 25675, 19089, 5942, 9851, 7494, 12061, 19709, 10786, 13118]),\n",
       " (2592, [6239, 14181, 10444, 11687, 8544, 24908, 8704, 19062, 15490, 7639]),\n",
       " (2692, [24075, 9438, 5942, 25675, 12061, 15034, 8811, 23799, 19089, 10786]),\n",
       " (2730, [25675, 12061, 10786, 5942, 22554, 9851, 19089, 7494, 15564, 7964]),\n",
       " (2833, [24075, 773, 14291, 2720, 21552, 12061, 22411, 991, 13363, 13074]),\n",
       " (2836, [24075, 9438, 25407, 2426, 17209, 18392, 23154, 15691, 25260, 12061]),\n",
       " (2876, [9438, 25675, 12061, 10786, 9851, 13118, 22554, 15034, 15564, 19089]),\n",
       " (2962, [9438, 25675, 12061, 5942, 10786, 9851, 15034, 13118, 22554, 19089]),\n",
       " (2985, [2426, 25675, 23154, 9555, 15691, 6734, 9438, 19089, 10834, 1583]),\n",
       " (3053, [25407, 23154, 15691, 9555, 22121, 10594, 24075, 16630, 7494, 6734]),\n",
       " (3077, [12061, 24075, 9851, 25071, 25675, 17525, 8811, 18293, 5717, 10786]),\n",
       " (3278, [25675, 9851, 5942, 13118, 8811, 5717, 25693, 15034, 25071, 17858]),\n",
       " (3392, [24075, 9851, 25071, 15034, 25260, 22554, 7202, 3803, 4512, 17858]),\n",
       " (3401, [9438, 25675, 12061, 5942, 10786, 9851, 13118, 15034, 19089, 22554]),\n",
       " (3413, [24075, 9438, 8431, 5942, 18322, 6040, 25385, 1740, 15766, 10280]),\n",
       " (3510, [24075, 9438, 5942, 25675, 12061, 15034, 19089, 8811, 23799, 10786]),\n",
       " (3684, [24075, 25675, 5942, 12061, 19089, 10786, 22554, 7494, 23799, 25693]),\n",
       " (3704, [25675, 21552, 9438, 773, 13118, 7964, 13074, 4927, 15034, 25071]),\n",
       " (3711, [24075, 9438, 5942, 25675, 12061, 8811, 15034, 10786, 13118, 19089]),\n",
       " (3886, [25675, 10269, 12061, 10786, 9851, 13118, 19089, 3803, 25260, 21552]),\n",
       " (3942, [24075, 12061, 10786, 22554, 5942, 21552, 13118, 5717, 19480, 15564]),\n",
       " (3994, [18859, 21064, 5186, 8716, 859, 2012, 3744, 18508, 14155, 4094]),\n",
       " (4005, [13541, 23711, 18528, 2868, 9029, 10786, 21854, 10450, 19114, 12341]),\n",
       " (4115, [23536, 19114, 23127, 24075, 13541, 18190, 12061, 10786, 18528, 4620]),\n",
       " (4125, [24075, 9438, 25407, 5942, 18392, 19089, 25675, 15691, 23154, 7494]),\n",
       " (4150, [24075, 25675, 12061, 5942, 10786, 22554, 23799, 9851, 8811, 19089]),\n",
       " (4183, [10269, 25675, 9438, 19089, 12061, 19480, 22121, 11658, 22554, 10786]),\n",
       " (4190, [23127, 2300, 10786, 23536, 19114, 18528, 18190, 13837, 12061, 2333]),\n",
       " (4245, [24075, 25407, 15691, 9555, 6734, 9438, 10834, 25675, 1583, 22121]),\n",
       " (4315, [24075, 12061, 10786, 23666, 13363, 9851, 9438, 5717, 19089, 19480]),\n",
       " (4333, [24075, 9438, 5942, 25675, 12061, 15034, 19089, 8811, 23799, 10786]),\n",
       " (4351, [9438, 25675, 12061, 9851, 10786, 5942, 24484, 13118, 8811, 15764]),\n",
       " (4584, [24075, 9438, 22554, 12061, 5942, 10786, 13118, 9851, 25260, 15564]),\n",
       " (4665, [24075, 9438, 5942, 25675, 12061, 15034, 23799, 19089, 8811, 10786]),\n",
       " (4794, [5717, 25675, 9851, 9438, 13541, 23536, 4620, 2333, 18528, 21552]),\n",
       " (4805, [24075, 9438, 25675, 5942, 19089, 23799, 12061, 15034, 10786, 6076]),\n",
       " (4868, [9438, 9560, 25675, 3689, 17145, 381, 9197, 4844, 10513, 12061]),\n",
       " (4918, [25675, 9438, 12061, 10786, 5717, 9851, 5942, 15034, 2300, 13118]),\n",
       " (4942, [942, 12061, 9851, 19564, 25675, 773, 22356, 24075, 25046, 24472]),\n",
       " (5016, [24075, 9438, 5942, 25675, 12061, 7494, 15034, 19089, 8811, 23799]),\n",
       " (5021, [14684, 19874, 5581, 4502, 3525, 18399, 10418, 24070, 7883, 4257]),\n",
       " (5117, [23711, 12061, 4620, 21854, 9029, 6088, 15327, 10450, 9315, 10786]),\n",
       " (5175, [24075, 9438, 9851, 12061, 13118, 25675, 5942, 19480, 25071, 12550]),\n",
       " (5205, [25675, 9438, 12061, 5942, 10786, 9851, 22554, 15034, 13118, 19089]),\n",
       " (5395, [24075, 9438, 5942, 25675, 12061, 8811, 19089, 15034, 10786, 23799]),\n",
       " (5418, [24075, 9438, 5942, 25675, 12061, 15034, 19089, 10786, 8811, 23799]),\n",
       " (5427, [24075, 9438, 23628, 5942, 8877, 12061, 22359, 25693, 3835, 18132]),\n",
       " (5430, [24075, 22554, 9438, 10786, 12061, 10269, 21552, 18293, 15564, 23711]),\n",
       " (5464, [24075, 25675, 9438, 2426, 10269, 7494, 19480, 16630, 20146, 5942]),\n",
       " (5674, [24075, 9438, 22554, 10786, 12061, 5942, 25260, 9851, 13118, 25071]),\n",
       " (5728, [24075, 12061, 5942, 9851, 9438, 15034, 25675, 10786, 19114, 21552]),\n",
       " (5732, [10269, 9438, 25675, 12061, 9851, 10786, 16630, 24093, 17820, 5942]),\n",
       " (5856, [9438, 12061, 25407, 22554, 10786, 2426, 5942, 9851, 13118, 19089]),\n",
       " (5903, [8544, 5717, 9284, 13541, 18114, 23127, 19018, 4620, 15145, 12056]),\n",
       " (6152, [9438, 25675, 5942, 12061, 10786, 9851, 15034, 13118, 19089, 22554]),\n",
       " (6209, [24075, 9438, 5942, 25675, 12061, 15034, 19089, 8811, 23799, 10786]),\n",
       " (6299, [24075, 25675, 22554, 3803, 19401, 12061, 10269, 25260, 5942, 10786]),\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "6hCawP60bVm3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "csv_fname = './submission'\n",
    "csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "def write_submission(submissions):\n",
    "    with open(csv_fname, \"w\") as f:\n",
    "        f.write(f\"user_id,item_list\\n\")\n",
    "        for user_id, items in submissions:\n",
    "            f.write(f\"{user_id},{' '.join([str(item) for item in items])}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ov91al-UbXAQ"
   },
   "outputs": [],
   "source": [
    "write_submission(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmnDxjbObe32"
   },
   "source": [
    "In this lecture we saw the most simple version of Cosine Similarity, where it just includes a shrink factor. There are different optimizations that we can do to it.\n",
    "\n",
    "Implement TopK Neighbors\n",
    "When calculating the cosine similarity we used urm.T.dot(urm) to calculate the enumerator. However, depending of the dataset and the number of items, this matrix could not fit in memory. Implemenent a block version, faster than our vector version but that does not use urm.T.dot(urm) beforehand.\n",
    "\n",
    "Implement Adjusted Cosine \n",
    "\n",
    "Implement Dice Similarity\n",
    "\n",
    "Implement an implicit CF ItemKNN.\n",
    "\n",
    "Implement a CF UserKNN model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RecommenderChallenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
